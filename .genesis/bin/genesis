#!/usr/bin/env perl
{ # embedded JSON::PP {{{
package JSON::PP;

# JSON-2.0

use 5.005;
use strict;
use base qw(Exporter);
use overload ();

use Carp ();
use B ();
#use Devel::Peek;

$JSON::PP::VERSION = '2.27300';

@JSON::PP::EXPORT = qw(encode_json decode_json from_json to_json);

# instead of hash-access, i tried index-access for speed.
# but this method is not faster than what i expected. so it will be changed.

use constant P_ASCII                => 0;
use constant P_LATIN1               => 1;
use constant P_UTF8                 => 2;
use constant P_INDENT               => 3;
use constant P_CANONICAL            => 4;
use constant P_SPACE_BEFORE         => 5;
use constant P_SPACE_AFTER          => 6;
use constant P_ALLOW_NONREF         => 7;
use constant P_SHRINK               => 8;
use constant P_ALLOW_BLESSED        => 9;
use constant P_CONVERT_BLESSED      => 10;
use constant P_RELAXED              => 11;

use constant P_LOOSE                => 12;
use constant P_ALLOW_BIGNUM         => 13;
use constant P_ALLOW_BAREKEY        => 14;
use constant P_ALLOW_SINGLEQUOTE    => 15;
use constant P_ESCAPE_SLASH         => 16;
use constant P_AS_NONBLESSED        => 17;

use constant P_ALLOW_UNKNOWN        => 18;

use constant OLD_PERL => $] < 5.008 ? 1 : 0;

BEGIN {
    my @xs_compati_bit_properties = qw(
            latin1 ascii utf8 indent canonical space_before space_after allow_nonref shrink
            allow_blessed convert_blessed relaxed allow_unknown
    );
    my @pp_bit_properties = qw(
            allow_singlequote allow_bignum loose
            allow_barekey escape_slash as_nonblessed
    );

    # Perl version check, Unicode handling is enable?
    # Helper module sets @JSON::PP::_properties.
    if ($] < 5.008 ) {
        my $helper = $] >= 5.006 ? 'JSON::PP::Compat5006' : 'JSON::PP::Compat5005';
        eval qq| require $helper |;
        if ($@) { Carp::croak $@; }
    }

    for my $name (@xs_compati_bit_properties, @pp_bit_properties) {
        my $flag_name = 'P_' . uc($name);

        eval qq/
            sub $name {
                my \$enable = defined \$_[1] ? \$_[1] : 1;

                if (\$enable) {
                    \$_[0]->{PROPS}->[$flag_name] = 1;
                }
                else {
                    \$_[0]->{PROPS}->[$flag_name] = 0;
                }

                \$_[0];
            }

            sub get_$name {
                \$_[0]->{PROPS}->[$flag_name] ? 1 : '';
            }
        /;
    }

}



# Functions

my %encode_allow_method
     = map {($_ => 1)} qw/utf8 pretty allow_nonref latin1 self_encode escape_slash
                          allow_blessed convert_blessed indent indent_length allow_bignum
                          as_nonblessed
                        /;
my %decode_allow_method
     = map {($_ => 1)} qw/utf8 allow_nonref loose allow_singlequote allow_bignum
                          allow_barekey max_size relaxed/;


my $JSON; # cache

sub encode_json ($) { # encode
    ($JSON ||= __PACKAGE__->new->utf8)->encode(@_);
}


sub decode_json { # decode
    ($JSON ||= __PACKAGE__->new->utf8)->decode(@_);
}

# Obsoleted

sub to_json($) {
   Carp::croak ("JSON::PP::to_json has been renamed to encode_json.");
}


sub from_json($) {
   Carp::croak ("JSON::PP::from_json has been renamed to decode_json.");
}


# Methods

sub new {
    my $class = shift;
    my $self  = {
        max_depth   => 512,
        max_size    => 0,
        indent      => 0,
        FLAGS       => 0,
        fallback      => sub { encode_error('Invalid value. JSON can only reference.') },
        indent_length => 3,
    };

    bless $self, $class;
}


sub encode {
    return $_[0]->PP_encode_json($_[1]);
}


sub decode {
    return $_[0]->PP_decode_json($_[1], 0x00000000);
}


sub decode_prefix {
    return $_[0]->PP_decode_json($_[1], 0x00000001);
}


# accessor


# pretty printing

sub pretty {
    my ($self, $v) = @_;
    my $enable = defined $v ? $v : 1;

    if ($enable) { # indent_length(3) for JSON::XS compatibility
        $self->indent(1)->indent_length(3)->space_before(1)->space_after(1);
    }
    else {
        $self->indent(0)->space_before(0)->space_after(0);
    }

    $self;
}

# etc

sub max_depth {
    my $max  = defined $_[1] ? $_[1] : 0x80000000;
    $_[0]->{max_depth} = $max;
    $_[0];
}


sub get_max_depth { $_[0]->{max_depth}; }


sub max_size {
    my $max  = defined $_[1] ? $_[1] : 0;
    $_[0]->{max_size} = $max;
    $_[0];
}


sub get_max_size { $_[0]->{max_size}; }


sub filter_json_object {
    $_[0]->{cb_object} = defined $_[1] ? $_[1] : 0;
    $_[0]->{F_HOOK} = ($_[0]->{cb_object} or $_[0]->{cb_sk_object}) ? 1 : 0;
    $_[0];
}

sub filter_json_single_key_object {
    if (@_ > 1) {
        $_[0]->{cb_sk_object}->{$_[1]} = $_[2];
    }
    $_[0]->{F_HOOK} = ($_[0]->{cb_object} or $_[0]->{cb_sk_object}) ? 1 : 0;
    $_[0];
}

sub indent_length {
    if (!defined $_[1] or $_[1] > 15 or $_[1] < 0) {
        Carp::carp "The acceptable range of indent_length() is 0 to 15.";
    }
    else {
        $_[0]->{indent_length} = $_[1];
    }
    $_[0];
}

sub get_indent_length {
    $_[0]->{indent_length};
}

sub sort_by {
    $_[0]->{sort_by} = defined $_[1] ? $_[1] : 1;
    $_[0];
}

sub allow_bigint {
    Carp::carp("allow_bigint() is obsoleted. use allow_bignum() insted.");
}

###############################

###
### Perl => JSON
###


{ # Convert

    my $max_depth;
    my $indent;
    my $ascii;
    my $latin1;
    my $utf8;
    my $space_before;
    my $space_after;
    my $canonical;
    my $allow_blessed;
    my $convert_blessed;

    my $indent_length;
    my $escape_slash;
    my $bignum;
    my $as_nonblessed;

    my $depth;
    my $indent_count;
    my $keysort;


    sub PP_encode_json {
        my $self = shift;
        my $obj  = shift;

        $indent_count = 0;
        $depth        = 0;

        my $idx = $self->{PROPS};

        ($ascii, $latin1, $utf8, $indent, $canonical, $space_before, $space_after, $allow_blessed,
            $convert_blessed, $escape_slash, $bignum, $as_nonblessed)
         = @{$idx}[P_ASCII .. P_SPACE_AFTER, P_ALLOW_BLESSED, P_CONVERT_BLESSED,
                    P_ESCAPE_SLASH, P_ALLOW_BIGNUM, P_AS_NONBLESSED];

        ($max_depth, $indent_length) = @{$self}{qw/max_depth indent_length/};

        $keysort = $canonical ? sub { $a cmp $b } : undef;

        if ($self->{sort_by}) {
            $keysort = ref($self->{sort_by}) eq 'CODE' ? $self->{sort_by}
                     : $self->{sort_by} =~ /\D+/       ? $self->{sort_by}
                     : sub { $a cmp $b };
        }

        encode_error("hash- or arrayref expected (not a simple scalar, use allow_nonref to allow this)")
             if(!ref $obj and !$idx->[ P_ALLOW_NONREF ]);

        my $str  = $self->object_to_json($obj);

        $str .= "\n" if ( $indent ); # JSON::XS 2.26 compatible

        unless ($ascii or $latin1 or $utf8) {
            utf8::upgrade($str);
        }

        if ($idx->[ P_SHRINK ]) {
            utf8::downgrade($str, 1);
        }

        return $str;
    }


    sub object_to_json {
        my ($self, $obj) = @_;
        my $type = ref($obj);

        if($type eq 'HASH'){
            return $self->hash_to_json($obj);
        }
        elsif($type eq 'ARRAY'){
            return $self->array_to_json($obj);
        }
        elsif ($type) { # blessed object?
            if (blessed($obj)) {

                return $self->value_to_json($obj) if ( $obj->isa('JSON::PP::Boolean') );

                if ( $convert_blessed and $obj->can('TO_JSON') ) {
                    my $result = $obj->TO_JSON();
                    if ( defined $result and ref( $result ) ) {
                        if ( refaddr( $obj ) eq refaddr( $result ) ) {
                            encode_error( sprintf(
                                "%s::TO_JSON method returned same object as was passed instead of a new one",
                                ref $obj
                            ) );
                        }
                    }

                    return $self->object_to_json( $result );
                }

                return "$obj" if ( $bignum and _is_bignum($obj) );
                return $self->blessed_to_json($obj) if ($allow_blessed and $as_nonblessed); # will be removed.

                encode_error( sprintf("encountered object '%s', but neither allow_blessed "
                    . "nor convert_blessed settings are enabled", $obj)
                ) unless ($allow_blessed);

                return 'null';
            }
            else {
                return $self->value_to_json($obj);
            }
        }
        else{
            return $self->value_to_json($obj);
        }
    }


    sub hash_to_json {
        my ($self, $obj) = @_;
        my @res;

        encode_error("json text or perl structure exceeds maximum nesting level (max_depth set too low?)")
                                         if (++$depth > $max_depth);

        my ($pre, $post) = $indent ? $self->_up_indent() : ('', '');
        my $del = ($space_before ? ' ' : '') . ':' . ($space_after ? ' ' : '');

        for my $k ( _sort( $obj ) ) {
            if ( OLD_PERL ) { utf8::decode($k) } # key for Perl 5.6 / be optimized
            push @res, string_to_json( $self, $k )
                          .  $del
                          . ( $self->object_to_json( $obj->{$k} ) || $self->value_to_json( $obj->{$k} ) );
        }

        --$depth;
        $self->_down_indent() if ($indent);

        return   '{' . ( @res ? $pre : '' ) . ( @res ? join( ",$pre", @res ) . $post : '' )  . '}';
    }


    sub array_to_json {
        my ($self, $obj) = @_;
        my @res;

        encode_error("json text or perl structure exceeds maximum nesting level (max_depth set too low?)")
                                         if (++$depth > $max_depth);

        my ($pre, $post) = $indent ? $self->_up_indent() : ('', '');

        for my $v (@$obj){
            push @res, $self->object_to_json($v) || $self->value_to_json($v);
        }

        --$depth;
        $self->_down_indent() if ($indent);

        return '[' . ( @res ? $pre : '' ) . ( @res ? join( ",$pre", @res ) . $post : '' ) . ']';
    }


    sub value_to_json {
        my ($self, $value) = @_;

        return 'null' if(!defined $value);

        my $b_obj = B::svref_2object(\$value);  # for round trip problem
        my $flags = $b_obj->FLAGS;

        return $value # as is 
            if $flags & ( B::SVp_IOK | B::SVp_NOK ) and !( $flags & B::SVp_POK ); # SvTYPE is IV or NV?

        my $type = ref($value);

        if(!$type){
            return string_to_json($self, $value);
        }
        elsif( blessed($value) and  $value->isa('JSON::PP::Boolean') ){
            return $$value == 1 ? 'true' : 'false';
        }
        elsif ($type) {
            if ((overload::StrVal($value) =~ /=(\w+)/)[0]) {
                return $self->value_to_json("$value");
            }

            if ($type eq 'SCALAR' and defined $$value) {
                return   $$value eq '1' ? 'true'
                       : $$value eq '0' ? 'false'
                       : $self->{PROPS}->[ P_ALLOW_UNKNOWN ] ? 'null'
                       : encode_error("cannot encode reference to scalar");
            }

             if ( $self->{PROPS}->[ P_ALLOW_UNKNOWN ] ) {
                 return 'null';
             }
             else {
                 if ( $type eq 'SCALAR' or $type eq 'REF' ) {
                    encode_error("cannot encode reference to scalar");
                 }
                 else {
                    encode_error("encountered $value, but JSON can only represent references to arrays or hashes");
                 }
             }

        }
        else {
            return $self->{fallback}->($value)
                 if ($self->{fallback} and ref($self->{fallback}) eq 'CODE');
            return 'null';
        }

    }


    my %esc = (
        "\n" => '\n',
        "\r" => '\r',
        "\t" => '\t',
        "\f" => '\f',
        "\b" => '\b',
        "\"" => '\"',
        "\\" => '\\\\',
        "\'" => '\\\'',
    );


    sub string_to_json {
        my ($self, $arg) = @_;

        $arg =~ s/([\x22\x5c\n\r\t\f\b])/$esc{$1}/g;
        $arg =~ s/\//\\\//g if ($escape_slash);
        $arg =~ s/([\x00-\x08\x0b\x0e-\x1f])/'\\u00' . unpack('H2', $1)/eg;

        if ($ascii) {
            $arg = JSON_PP_encode_ascii($arg);
        }

        if ($latin1) {
            $arg = JSON_PP_encode_latin1($arg);
        }

        if ($utf8) {
            utf8::encode($arg);
        }

        return '"' . $arg . '"';
    }


    sub blessed_to_json {
        my $reftype = reftype($_[1]) || '';
        if ($reftype eq 'HASH') {
            return $_[0]->hash_to_json($_[1]);
        }
        elsif ($reftype eq 'ARRAY') {
            return $_[0]->array_to_json($_[1]);
        }
        else {
            return 'null';
        }
    }


    sub encode_error {
        my $error  = shift;
        Carp::croak "$error";
    }


    sub _sort {
        defined $keysort ? (sort $keysort (keys %{$_[0]})) : keys %{$_[0]};
    }


    sub _up_indent {
        my $self  = shift;
        my $space = ' ' x $indent_length;

        my ($pre,$post) = ('','');

        $post = "\n" . $space x $indent_count;

        $indent_count++;

        $pre = "\n" . $space x $indent_count;

        return ($pre,$post);
    }


    sub _down_indent { $indent_count--; }


    sub PP_encode_box {
        {
            depth        => $depth,
            indent_count => $indent_count,
        };
    }

} # Convert


sub _encode_ascii {
    join('',
        map {
            $_ <= 127 ?
                chr($_) :
            $_ <= 65535 ?
                sprintf('\u%04x', $_) : sprintf('\u%x\u%x', _encode_surrogates($_));
        } unpack('U*', $_[0])
    );
}


sub _encode_latin1 {
    join('',
        map {
            $_ <= 255 ?
                chr($_) :
            $_ <= 65535 ?
                sprintf('\u%04x', $_) : sprintf('\u%x\u%x', _encode_surrogates($_));
        } unpack('U*', $_[0])
    );
}


sub _encode_surrogates { # from perlunicode
    my $uni = $_[0] - 0x10000;
    return ($uni / 0x400 + 0xD800, $uni % 0x400 + 0xDC00);
}


sub _is_bignum {
    $_[0]->isa('Math::BigInt') or $_[0]->isa('Math::BigFloat');
}



#
# JSON => Perl
#

my $max_intsize;

BEGIN {
    my $checkint = 1111;
    for my $d (5..64) {
        $checkint .= 1;
        my $int   = eval qq| $checkint |;
        if ($int =~ /[eE]/) {
            $max_intsize = $d - 1;
            last;
        }
    }
}

{ # PARSE 

    my %escapes = ( #  by Jeremy Muhlich <jmuhlich [at] bitflood.org>
        b    => "\x8",
        t    => "\x9",
        n    => "\xA",
        f    => "\xC",
        r    => "\xD",
        '\\' => '\\',
        '"'  => '"',
        '/'  => '/',
    );

    my $text; # json data
    my $at;   # offset
    my $ch;   # 1chracter
    my $len;  # text length (changed according to UTF8 or NON UTF8)
    # INTERNAL
    my $depth;          # nest counter
    my $encoding;       # json text encoding
    my $is_valid_utf8;  # temp variable
    my $utf8_len;       # utf8 byte length
    # FLAGS
    my $utf8;           # must be utf8
    my $max_depth;      # max nest nubmer of objects and arrays
    my $max_size;
    my $relaxed;
    my $cb_object;
    my $cb_sk_object;

    my $F_HOOK;

    my $allow_bigint;   # using Math::BigInt
    my $singlequote;    # loosely quoting
    my $loose;          # 
    my $allow_barekey;  # bareKey

    # $opt flag
    # 0x00000001 .... decode_prefix
    # 0x10000000 .... incr_parse

    sub PP_decode_json {
        my ($self, $opt); # $opt is an effective flag during this decode_json.

        ($self, $text, $opt) = @_;

        ($at, $ch, $depth) = (0, '', 0);

        if ( !defined $text or ref $text ) {
            decode_error("malformed JSON string, neither array, object, number, string or atom");
        }

        my $idx = $self->{PROPS};

        ($utf8, $relaxed, $loose, $allow_bigint, $allow_barekey, $singlequote)
            = @{$idx}[P_UTF8, P_RELAXED, P_LOOSE .. P_ALLOW_SINGLEQUOTE];

        if ( $utf8 ) {
            utf8::downgrade( $text, 1 ) or Carp::croak("Wide character in subroutine entry");
        }
        else {
            utf8::upgrade( $text );
            utf8::encode( $text );
        }

        $len = length $text;

        ($max_depth, $max_size, $cb_object, $cb_sk_object, $F_HOOK)
             = @{$self}{qw/max_depth  max_size cb_object cb_sk_object F_HOOK/};

        if ($max_size > 1) {
            use bytes;
            my $bytes = length $text;
            decode_error(
                sprintf("attempted decode of JSON text of %s bytes size, but max_size is set to %s"
                    , $bytes, $max_size), 1
            ) if ($bytes > $max_size);
        }

        # Currently no effect
        # should use regexp
        my @octets = unpack('C4', $text);
        $encoding =   ( $octets[0] and  $octets[1]) ? 'UTF-8'
                    : (!$octets[0] and  $octets[1]) ? 'UTF-16BE'
                    : (!$octets[0] and !$octets[1]) ? 'UTF-32BE'
                    : ( $octets[2]                ) ? 'UTF-16LE'
                    : (!$octets[2]                ) ? 'UTF-32LE'
                    : 'unknown';

        white(); # remove head white space

        my $valid_start = defined $ch; # Is there a first character for JSON structure?

        my $result = value();

        return undef if ( !$result && ( $opt & 0x10000000 ) ); # for incr_parse

        decode_error("malformed JSON string, neither array, object, number, string or atom") unless $valid_start;

        if ( !$idx->[ P_ALLOW_NONREF ] and !ref $result ) {
                decode_error(
                'JSON text must be an object or array (but found number, string, true, false or null,'
                       . ' use allow_nonref to allow this)', 1);
        }

        Carp::croak('something wrong.') if $len < $at; # we won't arrive here.

        my $consumed = defined $ch ? $at - 1 : $at; # consumed JSON text length

        white(); # remove tail white space

        if ( $ch ) {
            return ( $result, $consumed ) if ($opt & 0x00000001); # all right if decode_prefix
            decode_error("garbage after JSON object");
        }

        ( $opt & 0x00000001 ) ? ( $result, $consumed ) : $result;
    }


    sub next_chr {
        return $ch = undef if($at >= $len);
        $ch = substr($text, $at++, 1);
    }


    sub value {
        white();
        return          if(!defined $ch);
        return object() if($ch eq '{');
        return array()  if($ch eq '[');
        return string() if($ch eq '"' or ($singlequote and $ch eq "'"));
        return number() if($ch =~ /[0-9]/ or $ch eq '-');
        return word();
    }

    sub string {
        my ($i, $s, $t, $u);
        my $utf16;
        my $is_utf8;

        ($is_valid_utf8, $utf8_len) = ('', 0);

        $s = ''; # basically UTF8 flag on

        if($ch eq '"' or ($singlequote and $ch eq "'")){
            my $boundChar = $ch;

            OUTER: while( defined(next_chr()) ){

                if($ch eq $boundChar){
                    next_chr();

                    if ($utf16) {
                        decode_error("missing low surrogate character in surrogate pair");
                    }

                    utf8::decode($s) if($is_utf8);

                    return $s;
                }
                elsif($ch eq '\\'){
                    next_chr();
                    if(exists $escapes{$ch}){
                        $s .= $escapes{$ch};
                    }
                    elsif($ch eq 'u'){ # UNICODE handling
                        my $u = '';

                        for(1..4){
                            $ch = next_chr();
                            last OUTER if($ch !~ /[0-9a-fA-F]/);
                            $u .= $ch;
                        }

                        # U+D800 - U+DBFF
                        if ($u =~ /^[dD][89abAB][0-9a-fA-F]{2}/) { # UTF-16 high surrogate?
                            $utf16 = $u;
                        }
                        # U+DC00 - U+DFFF
                        elsif ($u =~ /^[dD][c-fC-F][0-9a-fA-F]{2}/) { # UTF-16 low surrogate?
                            unless (defined $utf16) {
                                decode_error("missing high surrogate character in surrogate pair");
                            }
                            $is_utf8 = 1;
                            $s .= JSON_PP_decode_surrogates($utf16, $u) || next;
                            $utf16 = undef;
                        }
                        else {
                            if (defined $utf16) {
                                decode_error("surrogate pair expected");
                            }

                            if ( ( my $hex = hex( $u ) ) > 127 ) {
                                $is_utf8 = 1;
                                $s .= JSON_PP_decode_unicode($u) || next;
                            }
                            else {
                                $s .= chr $hex;
                            }
                        }

                    }
                    else{
                        unless ($loose) {
                            $at -= 2;
                            decode_error('illegal backslash escape sequence in string');
                        }
                        $s .= $ch;
                    }
                }
                else{

                    if ( ord $ch  > 127 ) {
                        unless( $ch = is_valid_utf8($ch) ) {
                            $at -= 1;
                            decode_error("malformed UTF-8 character in JSON string");
                        }
                        else {
                            $at += $utf8_len - 1;
                        }

                        $is_utf8 = 1;
                    }

                    if (!$loose) {
                        if ($ch =~ /[\x00-\x1f\x22\x5c]/)  { # '/' ok
                            $at--;
                            decode_error('invalid character encountered while parsing JSON string');
                        }
                    }

                    $s .= $ch;
                }
            }
        }

        decode_error("unexpected end of string while parsing JSON string");
    }


    sub white {
        while( defined $ch  ){
            if($ch le ' '){
                next_chr();
            }
            elsif($ch eq '/'){
                next_chr();
                if(defined $ch and $ch eq '/'){
                    1 while(defined(next_chr()) and $ch ne "\n" and $ch ne "\r");
                }
                elsif(defined $ch and $ch eq '*'){
                    next_chr();
                    while(1){
                        if(defined $ch){
                            if($ch eq '*'){
                                if(defined(next_chr()) and $ch eq '/'){
                                    next_chr();
                                    last;
                                }
                            }
                            else{
                                next_chr();
                            }
                        }
                        else{
                            decode_error("Unterminated comment");
                        }
                    }
                    next;
                }
                else{
                    $at--;
                    decode_error("malformed JSON string, neither array, object, number, string or atom");
                }
            }
            else{
                if ($relaxed and $ch eq '#') { # correctly?
                    pos($text) = $at;
                    $text =~ /\G([^\n]*(?:\r\n|\r|\n|$))/g;
                    $at = pos($text);
                    next_chr;
                    next;
                }

                last;
            }
        }
    }


    sub array {
        my $a  = $_[0] || []; # you can use this code to use another array ref object.

        decode_error('json text or perl structure exceeds maximum nesting level (max_depth set too low?)')
                                                    if (++$depth > $max_depth);

        next_chr();
        white();

        if(defined $ch and $ch eq ']'){
            --$depth;
            next_chr();
            return $a;
        }
        else {
            while(defined($ch)){
                push @$a, value();

                white();

                if (!defined $ch) {
                    last;
                }

                if($ch eq ']'){
                    --$depth;
                    next_chr();
                    return $a;
                }

                if($ch ne ','){
                    last;
                }

                next_chr();
                white();

                if ($relaxed and $ch eq ']') {
                    --$depth;
                    next_chr();
                    return $a;
                }

            }
        }

        decode_error(", or ] expected while parsing array");
    }


    sub object {
        my $o = $_[0] || {}; # you can use this code to use another hash ref object.
        my $k;

        decode_error('json text or perl structure exceeds maximum nesting level (max_depth set too low?)')
                                                if (++$depth > $max_depth);
        next_chr();
        white();

        if(defined $ch and $ch eq '}'){
            --$depth;
            next_chr();
            if ($F_HOOK) {
                return _json_object_hook($o);
            }
            return $o;
        }
        else {
            while (defined $ch) {
                $k = ($allow_barekey and $ch ne '"' and $ch ne "'") ? bareKey() : string();
                white();

                if(!defined $ch or $ch ne ':'){
                    $at--;
                    decode_error("':' expected");
                }

                next_chr();
                $o->{$k} = value();
                white();

                last if (!defined $ch);

                if($ch eq '}'){
                    --$depth;
                    next_chr();
                    if ($F_HOOK) {
                        return _json_object_hook($o);
                    }
                    return $o;
                }

                if($ch ne ','){
                    last;
                }

                next_chr();
                white();

                if ($relaxed and $ch eq '}') {
                    --$depth;
                    next_chr();
                    if ($F_HOOK) {
                        return _json_object_hook($o);
                    }
                    return $o;
                }

            }

        }

        $at--;
        decode_error(", or } expected while parsing object/hash");
    }


    sub bareKey { # doesn't strictly follow Standard ECMA-262 3rd Edition
        my $key;
        while($ch =~ /[^\x00-\x23\x25-\x2F\x3A-\x40\x5B-\x5E\x60\x7B-\x7F]/){
            $key .= $ch;
            next_chr();
        }
        return $key;
    }


    sub word {
        my $word =  substr($text,$at-1,4);

        if($word eq 'true'){
            $at += 3;
            next_chr;
            return $JSON::PP::true;
        }
        elsif($word eq 'null'){
            $at += 3;
            next_chr;
            return undef;
        }
        elsif($word eq 'fals'){
            $at += 3;
            if(substr($text,$at,1) eq 'e'){
                $at++;
                next_chr;
                return $JSON::PP::false;
            }
        }

        $at--; # for decode_error report

        decode_error("'null' expected")  if ($word =~ /^n/);
        decode_error("'true' expected")  if ($word =~ /^t/);
        decode_error("'false' expected") if ($word =~ /^f/);
        decode_error("malformed JSON string, neither array, object, number, string or atom");
    }


    sub number {
        my $n    = '';
        my $v;

        # According to RFC4627, hex or oct digts are invalid.
        if($ch eq '0'){
            my $peek = substr($text,$at,1);
            my $hex  = $peek =~ /[xX]/; # 0 or 1

            if($hex){
                decode_error("malformed number (leading zero must not be followed by another digit)");
                ($n) = ( substr($text, $at+1) =~ /^([0-9a-fA-F]+)/);
            }
            else{ # oct
                ($n) = ( substr($text, $at) =~ /^([0-7]+)/);
                if (defined $n and length $n > 1) {
                    decode_error("malformed number (leading zero must not be followed by another digit)");
                }
            }

            if(defined $n and length($n)){
                if (!$hex and length($n) == 1) {
                   decode_error("malformed number (leading zero must not be followed by another digit)");
                }
                $at += length($n) + $hex;
                next_chr;
                return $hex ? hex($n) : oct($n);
            }
        }

        if($ch eq '-'){
            $n = '-';
            next_chr;
            if (!defined $ch or $ch !~ /\d/) {
                decode_error("malformed number (no digits after initial minus)");
            }
        }

        while(defined $ch and $ch =~ /\d/){
            $n .= $ch;
            next_chr;
        }

        if(defined $ch and $ch eq '.'){
            $n .= '.';

            next_chr;
            if (!defined $ch or $ch !~ /\d/) {
                decode_error("malformed number (no digits after decimal point)");
            }
            else {
                $n .= $ch;
            }

            while(defined(next_chr) and $ch =~ /\d/){
                $n .= $ch;
            }
        }

        if(defined $ch and ($ch eq 'e' or $ch eq 'E')){
            $n .= $ch;
            next_chr;

            if(defined($ch) and ($ch eq '+' or $ch eq '-')){
                $n .= $ch;
                next_chr;
                if (!defined $ch or $ch =~ /\D/) {
                    decode_error("malformed number (no digits after exp sign)");
                }
                $n .= $ch;
            }
            elsif(defined($ch) and $ch =~ /\d/){
                $n .= $ch;
            }
            else {
                decode_error("malformed number (no digits after exp sign)");
            }

            while(defined(next_chr) and $ch =~ /\d/){
                $n .= $ch;
            }

        }

        $v .= $n;

        if ($v !~ /[.eE]/ and length $v > $max_intsize) {
            if ($allow_bigint) { # from Adam Sussman
                require Math::BigInt;
                return Math::BigInt->new($v);
            }
            else {
                return "$v";
            }
        }
        elsif ($allow_bigint) {
            require Math::BigFloat;
            return Math::BigFloat->new($v);
        }

        return 0+$v;
    }


    sub is_valid_utf8 {

        $utf8_len = $_[0] =~ /[\x00-\x7F]/  ? 1
                  : $_[0] =~ /[\xC2-\xDF]/  ? 2
                  : $_[0] =~ /[\xE0-\xEF]/  ? 3
                  : $_[0] =~ /[\xF0-\xF4]/  ? 4
                  : 0
                  ;

        return unless $utf8_len;

        my $is_valid_utf8 = substr($text, $at - 1, $utf8_len);

        return ( $is_valid_utf8 =~ /^(?:
             [\x00-\x7F]
            |[\xC2-\xDF][\x80-\xBF]
            |[\xE0][\xA0-\xBF][\x80-\xBF]
            |[\xE1-\xEC][\x80-\xBF][\x80-\xBF]
            |[\xED][\x80-\x9F][\x80-\xBF]
            |[\xEE-\xEF][\x80-\xBF][\x80-\xBF]
            |[\xF0][\x90-\xBF][\x80-\xBF][\x80-\xBF]
            |[\xF1-\xF3][\x80-\xBF][\x80-\xBF][\x80-\xBF]
            |[\xF4][\x80-\x8F][\x80-\xBF][\x80-\xBF]
        )$/x )  ? $is_valid_utf8 : '';
    }


    sub decode_error {
        my $error  = shift;
        my $no_rep = shift;
        my $str    = defined $text ? substr($text, $at) : '';
        my $mess   = '';
        my $type   = $] >= 5.008           ? 'U*'
                   : $] <  5.006           ? 'C*'
                   : utf8::is_utf8( $str ) ? 'U*' # 5.6
                   : 'C*'
                   ;

        for my $c ( unpack( $type, $str ) ) { # emulate pv_uni_display() ?
            $mess .=  $c == 0x07 ? '\a'
                    : $c == 0x09 ? '\t'
                    : $c == 0x0a ? '\n'
                    : $c == 0x0d ? '\r'
                    : $c == 0x0c ? '\f'
                    : $c <  0x20 ? sprintf('\x{%x}', $c)
                    : $c == 0x5c ? '\\\\'
                    : $c <  0x80 ? chr($c)
                    : sprintf('\x{%x}', $c)
                    ;
            if ( length $mess >= 20 ) {
                $mess .= '...';
                last;
            }
        }

        unless ( length $mess ) {
            $mess = '(end of string)';
        }

        Carp::croak (
            $no_rep ? "$error" : "$error, at character offset $at (before \"$mess\")"
        );

    }


    sub _json_object_hook {
        my $o    = $_[0];
        my @ks = keys %{$o};

        if ( $cb_sk_object and @ks == 1 and exists $cb_sk_object->{ $ks[0] } and ref $cb_sk_object->{ $ks[0] } ) {
            my @val = $cb_sk_object->{ $ks[0] }->( $o->{$ks[0]} );
            if (@val == 1) {
                return $val[0];
            }
        }

        my @val = $cb_object->($o) if ($cb_object);
        if (@val == 0 or @val > 1) {
            return $o;
        }
        else {
            return $val[0];
        }
    }


    sub PP_decode_box {
        {
            text    => $text,
            at      => $at,
            ch      => $ch,
            len     => $len,
            depth   => $depth,
            encoding      => $encoding,
            is_valid_utf8 => $is_valid_utf8,
        };
    }

} # PARSE


sub _decode_surrogates { # from perlunicode
    my $uni = 0x10000 + (hex($_[0]) - 0xD800) * 0x400 + (hex($_[1]) - 0xDC00);
    my $un  = pack('U*', $uni);
    utf8::encode( $un );
    return $un;
}


sub _decode_unicode {
    my $un = pack('U', hex shift);
    utf8::encode( $un );
    return $un;
}

#
# Setup for various Perl versions (the code from JSON::PP58)
#

BEGIN {

    unless ( defined &utf8::is_utf8 ) {
       require Encode;
       *utf8::is_utf8 = *Encode::is_utf8;
    }

    if ( $] >= 5.008 ) {
        *JSON::PP::JSON_PP_encode_ascii      = \&_encode_ascii;
        *JSON::PP::JSON_PP_encode_latin1     = \&_encode_latin1;
        *JSON::PP::JSON_PP_decode_surrogates = \&_decode_surrogates;
        *JSON::PP::JSON_PP_decode_unicode    = \&_decode_unicode;
    }

    if ($] >= 5.008 and $] < 5.008003) { # join() in 5.8.0 - 5.8.2 is broken.
        package JSON::PP;
        require subs;
        subs->import('join');
        eval q|
            sub join {
                return '' if (@_ < 2);
                my $j   = shift;
                my $str = shift;
                for (@_) { $str .= $j . $_; }
                return $str;
            }
        |;
    }


    sub JSON::PP::incr_parse {
        local $Carp::CarpLevel = 1;
        ( $_[0]->{_incr_parser} ||= JSON::PP::IncrParser->new )->incr_parse( @_ );
    }


    sub JSON::PP::incr_skip {
        ( $_[0]->{_incr_parser} ||= JSON::PP::IncrParser->new )->incr_skip;
    }


    sub JSON::PP::incr_reset {
        ( $_[0]->{_incr_parser} ||= JSON::PP::IncrParser->new )->incr_reset;
    }

    eval q{
        sub JSON::PP::incr_text : lvalue {
            $_[0]->{_incr_parser} ||= JSON::PP::IncrParser->new;

            if ( $_[0]->{_incr_parser}->{incr_parsing} ) {
                Carp::croak("incr_text can not be called when the incremental parser already started parsing");
            }
            $_[0]->{_incr_parser}->{incr_text};
        }
    } if ( $] >= 5.006 );

} # Setup for various Perl versions (the code from JSON::PP58)


###############################
# Utilities
#

BEGIN {
    eval 'require Scalar::Util';
    unless($@){
        *JSON::PP::blessed = \&Scalar::Util::blessed;
        *JSON::PP::reftype = \&Scalar::Util::reftype;
        *JSON::PP::refaddr = \&Scalar::Util::refaddr;
    }
    else{ # This code is from Sclar::Util.
        # warn $@;
        eval 'sub UNIVERSAL::a_sub_not_likely_to_be_here { ref($_[0]) }';
        *JSON::PP::blessed = sub {
            local($@, $SIG{__DIE__}, $SIG{__WARN__});
            ref($_[0]) ? eval { $_[0]->a_sub_not_likely_to_be_here } : undef;
        };
        my %tmap = qw(
            B::NULL   SCALAR
            B::HV     HASH
            B::AV     ARRAY
            B::CV     CODE
            B::IO     IO
            B::GV     GLOB
            B::REGEXP REGEXP
        );
        *JSON::PP::reftype = sub {
            my $r = shift;

            return undef unless length(ref($r));

            my $t = ref(B::svref_2object($r));

            return
                exists $tmap{$t} ? $tmap{$t}
              : length(ref($$r)) ? 'REF'
              :                    'SCALAR';
        };
        *JSON::PP::refaddr = sub {
          return undef unless length(ref($_[0]));

          my $addr;
          if(defined(my $pkg = blessed($_[0]))) {
            $addr .= bless $_[0], 'Scalar::Util::Fake';
            bless $_[0], $pkg;
          }
          else {
            $addr .= $_[0]
          }

          $addr =~ /0x(\w+)/;
          local $^W;
          #no warnings 'portable';
          hex($1);
        }
    }
}


# shamely copied and modified from JSON::XS code.

$JSON::PP::true  = do { bless \(my $dummy = 1), "JSON::PP::Boolean" };
$JSON::PP::false = do { bless \(my $dummy = 0), "JSON::PP::Boolean" };

sub is_bool { defined $_[0] and UNIVERSAL::isa($_[0], "JSON::PP::Boolean"); }

sub true  { $JSON::PP::true  }
sub false { $JSON::PP::false }
sub null  { undef; }

###############################

package JSON::PP::Boolean;

use overload (
   "0+"     => sub { ${$_[0]} },
   "++"     => sub { $_[0] = ${$_[0]} + 1 },
   "--"     => sub { $_[0] = ${$_[0]} - 1 },
   fallback => 1,
);


###############################

package JSON::PP::IncrParser;

use strict;

use constant INCR_M_WS   => 0; # initial whitespace skipping
use constant INCR_M_STR  => 1; # inside string
use constant INCR_M_BS   => 2; # inside backslash
use constant INCR_M_JSON => 3; # outside anything, count nesting
use constant INCR_M_C0   => 4;
use constant INCR_M_C1   => 5;

$JSON::PP::IncrParser::VERSION = '1.01';

my $unpack_format = $] < 5.006 ? 'C*' : 'U*';

sub new {
    my ( $class ) = @_;

    bless {
        incr_nest    => 0,
        incr_text    => undef,
        incr_parsing => 0,
        incr_p       => 0,
    }, $class;
}


sub incr_parse {
    my ( $self, $coder, $text ) = @_;

    $self->{incr_text} = '' unless ( defined $self->{incr_text} );

    if ( defined $text ) {
        if ( utf8::is_utf8( $text ) and !utf8::is_utf8( $self->{incr_text} ) ) {
            utf8::upgrade( $self->{incr_text} ) ;
            utf8::decode( $self->{incr_text} ) ;
        }
        $self->{incr_text} .= $text;
    }


    my $max_size = $coder->get_max_size;

    if ( defined wantarray ) {

        $self->{incr_mode} = INCR_M_WS unless defined $self->{incr_mode};

        if ( wantarray ) {
            my @ret;

            $self->{incr_parsing} = 1;

            do {
                push @ret, $self->_incr_parse( $coder, $self->{incr_text} );

                unless ( !$self->{incr_nest} and $self->{incr_mode} == INCR_M_JSON ) {
                    $self->{incr_mode} = INCR_M_WS if $self->{incr_mode} != INCR_M_STR;
                }

            } until ( length $self->{incr_text} >= $self->{incr_p} );

            $self->{incr_parsing} = 0;

            return @ret;
        }
        else { # in scalar context
            $self->{incr_parsing} = 1;
            my $obj = $self->_incr_parse( $coder, $self->{incr_text} );
            $self->{incr_parsing} = 0 if defined $obj; # pointed by Martin J. Evans
            return $obj ? $obj : undef; # $obj is an empty string, parsing was completed.
        }

    }

}


sub _incr_parse {
    my ( $self, $coder, $text, $skip ) = @_;
    my $p = $self->{incr_p};
    my $restore = $p;

    my @obj;
    my $len = length $text;

    if ( $self->{incr_mode} == INCR_M_WS ) {
        while ( $len > $p ) {
            my $s = substr( $text, $p, 1 );
            $p++ and next if ( 0x20 >= unpack($unpack_format, $s) );
            $self->{incr_mode} = INCR_M_JSON;
            last;
       }
    }

    while ( $len > $p ) {
        my $s = substr( $text, $p++, 1 );

        if ( $s eq '"' ) {
            if (substr( $text, $p - 2, 1 ) eq '\\' ) {
                next;
            }

            if ( $self->{incr_mode} != INCR_M_STR  ) {
                $self->{incr_mode} = INCR_M_STR;
            }
            else {
                $self->{incr_mode} = INCR_M_JSON;
                unless ( $self->{incr_nest} ) {
                    last;
                }
            }
        }

        if ( $self->{incr_mode} == INCR_M_JSON ) {

            if ( $s eq '[' or $s eq '{' ) {
                if ( ++$self->{incr_nest} > $coder->get_max_depth ) {
                    Carp::croak('json text or perl structure exceeds maximum nesting level (max_depth set too low?)');
                }
            }
            elsif ( $s eq ']' or $s eq '}' ) {
                last if ( --$self->{incr_nest} <= 0 );
            }
            elsif ( $s eq '#' ) {
                while ( $len > $p ) {
                    last if substr( $text, $p++, 1 ) eq "\n";
                }
            }

        }

    }

    $self->{incr_p} = $p;

    return if ( $self->{incr_mode} == INCR_M_STR and not $self->{incr_nest} );
    return if ( $self->{incr_mode} == INCR_M_JSON and $self->{incr_nest} > 0 );

    return '' unless ( length substr( $self->{incr_text}, 0, $p ) );

    local $Carp::CarpLevel = 2;

    $self->{incr_p} = $restore;
    $self->{incr_c} = $p;

    my ( $obj, $tail ) = $coder->PP_decode_json( substr( $self->{incr_text}, 0, $p ), 0x10000001 );

    $self->{incr_text} = substr( $self->{incr_text}, $p );
    $self->{incr_p} = 0;

    return $obj || '';
}


sub incr_text {
    if ( $_[0]->{incr_parsing} ) {
        Carp::croak("incr_text can not be called when the incremental parser already started parsing");
    }
    $_[0]->{incr_text};
}


sub incr_skip {
    my $self  = shift;
    $self->{incr_text} = substr( $self->{incr_text}, $self->{incr_c} );
    $self->{incr_p} = 0;
}


sub incr_reset {
    my $self = shift;
    $self->{incr_text}    = undef;
    $self->{incr_p}       = 0;
    $self->{incr_mode}    = 0;
    $self->{incr_nest}    = 0;
    $self->{incr_parsing} = 0;
}

###############################


1;
} # }}}
# vim:ft=perl:noet:ts=4:sts=4:sw=4
use strict;
use warnings;

# non-core modules
JSON::PP->import(qw/decode_json encode_json/);
use HTTP::Tiny;
# NOTE: if you add more non-core modules,
# be sure to update ./pack!

use Getopt::Long qw/GetOptionsFromArray :config no_ignore_case/;
use File::Temp qw/tempdir tempfile/;
use File::Basename qw/dirname/;
use POSIX qw/strftime/;
use FindBin;
use Socket qw/inet_ntoa/;
use Cwd qw/getcwd abs_path/;

our $VERSION = "2.2.1";
our $GITHUB_URL = "https://github.com/starkandwayne/genesis";
our $USER_AGENT_STRING = "genesis/$VERSION";

sub DumpJSON {
	my ($file, $data) = @_;
	open my $fh, ">", $file or die "Unable to write to $file: $!\n";
	print $fh encode_json($data);
	close $fh;
}

sub LoadFile {
	my ($file) = @_;
	decode_json(qx(spruce json $file));
}

sub Load {
	my ($yaml) = @_;

	my $tmp = workdir();
	open my $fh, "|-", "spruce json >$tmp/yaml.json"
		or die "Failed to execute `spruce json': $!\n";
	print $fh $yaml;
	close $fh;

	return LoadFile("$tmp/yaml.json")
}

my $END_HOOKS = [];
sub at_exit {
	my ($fn) = @_;
	push @$END_HOOKS, $fn;
}

END {
	$_->($?) for @$END_HOOKS;
}

sub envset {
	my ($var) = @_;
	return (defined $ENV{$var} and $ENV{$var} =~ m/^(1|y|yes|true)$/i);
}

sub envdefault {
	my ($var, $default) = @_;
	return defined $ENV{$var} ? $ENV{$var} : $default;
}

sub ago {
	my ($ts) = @_;
	my $ago = time - $ts;
	if ($ago >  90 * 86400) { return sprintf("%i months ago", $ago / 30 / 86400); }
	if ($ago >= 21 * 86400) { return sprintf("%i weeks ago", $ago / 7  / 86400); }
	if ($ago >= 2  * 86400) { return sprintf("%i days ago", $ago / 86400); }
	if ($ago >= 90 * 60)    { return sprintf("%i hours ago", $ago / 3600); }
	if ($ago >  60)         { return sprintf("%i minutes ago", $ago / 60); }
	return "just now";
}

sub colorize {
	my ($c, $msg) = @_;
	return $msg if envset('NOCOLOR');
	$c = substr $c, 1, 1;
	my %color = (
		'k'		=> "\e[30m",     #black
		'K'		=> "\e[1;30m",   #black (BOLD)
		'r'		=> "\e[31m",     #red
		'R'		=> "\e[1;31m",   #red (BOLD)
		'g'		=> "\e[32m",     #green
		'G'		=> "\e[1;32m",   #green (BOLD)
		'y'		=> "\e[33m",     #yellow
		'Y'		=> "\e[1;33m",   #yellow (BOLD)
		'b'		=> "\e[34m",     #blue
		'B'		=> "\e[1;34m",   #blue (BOLD)
		'm'		=> "\e[35m",     #magenta
		'M'		=> "\e[1;35m",   #magenta (BOLD)
		'p'		=> "\e[35m",     #purple (alias for magenta)
		'P'		=> "\e[1;35m",   #purple (BOLD)
		'c'		=> "\e[36m",     #cyan
		'C'		=> "\e[1;36m",   #cyan (BOLD)
		'w'		=> "\e[37m",     #white
		'W'		=> "\e[1;37m",   #white (BOLD)
	);

	if ($c eq "*") {
		my @rainbow = ('R','G','Y','B','M','C');
		my $i = 0;
		my $msgc = "";
		foreach my $char (split //, $msg) {
			$msgc = $msgc . "$color{$rainbow[$i%6]}$char";
			if ($char =~ m/\S/) {
				$i++;
			}
		}
		return "$msgc\e[0m";
	} else {
		return "$color{$c}$msg\e[0m";
	}
}

sub csprintf {
	my ($fmt, @args) = @_;
	return '' unless $fmt;
	my $s = sprintf($fmt, @args);
	$s =~ s/(#[KRGYBMPCW*]\{)(.*?)(\})/colorize($1, $2)/egi;
	return $s;
}
sub explain(@) {
	return if envset "QUIET";
	my $colorize = $ENV{NOCOLOR};
	$ENV{NOCOLOR} = "true" if (! -t STDOUT);
	print csprintf(@_);
	$ENV{NOCOLOR} = $colorize;
	print "\n";
}

sub debug(@) {
	return unless envset "DEBUG";
	print STDERR "DEBUG> ";
	my $colorize = $ENV{NOCOLOR};
	$ENV{NOCOLOR} = "true" if (! -t STDERR);
	print STDERR csprintf(@_);
	$ENV{NOCOLOR} = $colorize;
	print STDERR "\n";
}

sub trace(@) {
	return unless envset "TRACE";
	print STDERR "TRACE> ";
	print STDERR csprintf(@_);
	print STDERR "\n";
}

sub error {
	printf STDERR csprintf(@_) . "\n";
}

sub online {
	return !envset('OFFLINE');
}

sub execute {
	my ($prog) = @_;
	debug "executing `#C{$prog} 2>&1`";
	my $out = qx($prog 2>&1);
	my $rc = $?;

	if ($rc != 0) {
		debug "command exited #R{%d}.", $rc >> 8;
		debug "--------------------------------";
		debug $out;
		debug "--------------------------------";
		return 0;
	}
	return 1;
}

sub system_execute {
	my ($prog) = @_;
	debug "executing `#C{$prog}`";
	my $out = system "$prog";
	my $rc = $?;

	if ($rc != 0) {
		debug "command exited #R{%d}.", $rc >> 8;
		return 0;
	}
	return 1;
}

sub mkfile_or_fail {
	my ($f, $c) = @_;
	debug "creating file $f";
	eval {
		open my $fh, ">", $f;
		print $fh $c;
		close $fh;
	} or die "Error creating file $f: $!\n";
}

# mkdir_or_fail $dir;
sub mkdir_or_fail {
	my ($dir) = @_;
	return if -d $dir;
	debug "creating directory $dir/";
	system("mkdir", "-p", "$dir/") == 0 or die "Unable to create directory $dir/: $!\n";
}
# chdir_or_fail $dir;
sub chdir_or_fail {
	my ($dir) = @_;
	debug "changing current working directory to $dir/";
	chdir $dir or die "Unable to change directory to $dir/: $!\n";
}

# symlink_or_fail $source $dest;
sub symlink_or_fail {
	my ($source, $dest) = @_;
	-d $source or die "$source does not exist!\n";
	-e $dest and die abs_path($dest)." already exists!";
	symlink($source, $dest) or die "Unable to link $source to $dest: $!\n";
}

our @DIRSTACK;
sub pushd {
	my ($dir) = @_;
	push @DIRSTACK, Cwd::cwd;
	chdir_or_fail($dir);
}
sub popd {
	@DIRSTACK or die "popd called when we don't have anything on the directory stack; please file a bug\n";
	chdir_or_fail(pop @DIRSTACK);
}

# copy_or_fail $from, $to;
sub copy_or_fail {
	my ($from, $to) = @_;
	-f $from or die "$from: $!\n";
	open my $in,  "<", $from or die "Unable to open $from for reading: $!\n";
	open my $out, ">", $to   or die "Unable to open $to for writing: $!\n";
	print $out $_ while (<$in>);
	close $in;
	close $out;
}
# chmod_or_fail 0755, $path; <-- don't quote the mode. make it an octal number.
sub chmod_or_fail {
	my ($mode, $path) = @_;
	-e $path or die "$path: $!\n";
	chmod $mode, $path;
}

# check we're in a Genesis v2 directory
sub in_repo_dir {
  return  -d ".genesis" && -e ".genesis/config";
}

# workdir;
my $WORKDIR;
sub workdir {
	if (!defined $WORKDIR) {
		$WORKDIR = tempdir(CLEANUP => 1);
	}
	return $WORKDIR;
}
# put_file $path, $contents;
sub put_file {
	my ($path, $contents, $mode) = @_;
	debug "populating $path file";
	open my $fh, ">", $path
		or die "Unable to open $path for writing: $!\n";
	chmod_or_fail $mode, $path if defined $mode;
	print $fh $contents || "";
	close $fh;
}

# get_file $path
sub get_file {
	my ($file) = @_;
	open my $fh, "<", $file
		or die "failed to open '$file' for reading: $!\n";
	my $contents = do { local $/; <$fh> };
	close $fh;
	return $contents;
}

sub yaml_bool {
	my ($bool, $default) = @_;
	return ($default || 0) unless defined($bool);
	return $bool;
}

sub validate_subkits {
	my ($kit, $version, $meta, @subkits) = @_;
	for my $sk (@subkits) {
		die "You specified a subkit without a name\n" unless $sk;
		my $path = kit_file($kit, $version, "subkits/$sk", 0);
		my ($k, $v) = ($kit, $version);
		$k ||= "dev";
		$v = "latest" unless defined $v;
		die "No subkit '$sk' found in kit $k/$v.\n"
			unless -d $path;
	}

	my %requested_subkits = map { $_ => 1 } @subkits;
	for my $sk (@{$meta->{subkits}}) {
		if ($sk->{choices}) {
			my $matches = 0;
			my $min_matches = 1;
			my @choices;
			for my $choice (@{$sk->{choices}}) {
				push @choices, $choice->{subkit} if defined $choice && defined $choice->{subkit};
				if (! defined $choice->{subkit}){
					$min_matches = 0;
				} elsif ($requested_subkits{$choice->{subkit}}) {
					$matches++;
				}
			}
			my $choices = join(", ", map { "'$_'" } @choices);
			if ($matches > 1) {
				die "You selected too many subkits for your $sk->{type}. Should be only one of $choices\n";
			}
			if ($matches < $min_matches) {
				die "You must select a subkit to provide your $sk->{type}. Should be one of $choices\n";
			}
		}
	}
}

sub run_subkit_hook {
	my ($kit, $version, @subkits) = @_;
	my $hook_dir = kit_file($kit, $version, "hooks", 0); # grab subkit hook + any helpers
	my $hook = "$hook_dir/subkit";
	return @subkits unless -f $hook;


	$kit ||= "dev";
	$version = "latest" unless defined $version;
	chmod(0755,$hook) unless -e $hook;

	my $cmd = "$hook " . join(" ", map { "'$_'" } @subkits);
	my $out = qx($cmd);
	die "Error running subkit hook for $kit/$version. Contact your kit author for a bugfix.\n"
		if $? >> 8;

	@subkits = map { $_ =~ s/^\s+|\s+$//g; $_ } split /\n/, $out, -1;
	pop @subkits if @subkits && $subkits[-1] eq "";
	return @subkits;
}

sub run_param_hook {
	my ($kit, $version, $env_name, $vault_prefix, $params, @subkits) = @_;
	my $hook_dir = kit_file($kit, $version, "hooks", 0); # grab params hook + any helpers
	my $hook = "$hook_dir/params";
	return $params unless -f $hook;


	$kit ||= "dev";
	$version = "latest" unless defined $version;
	chmod(0755,$hook) unless -e $hook;

	my $dir = workdir;
	DumpJSON "$dir/in", $params;
	my $cmd = "$hook $dir/in $dir/out " . join(" ", map { "'$_'" } @subkits);
	$ENV{GENESIS_ENVIRONMENT_NAME} = $env_name;
	$ENV{GENESIS_VAULT_PREFIX} = $vault_prefix;
	system($cmd);
	die "\nNew environment creation cancelled.\n"
		if $? >> 8 eq 130;
	die "Error running params hook for $kit/$version. Contact your kit author for a bugfix.\n"
		if $? >> 8;

	# FIXME: get a better error message when json fails to load
	open my $fh, "<", "$dir/out";
	my @json = <$fh>;
	close $fh;
	return decode_json(join("\n",@json));
}

sub new_environment {
	my ($meta, $kit, $version, $env, $vault_prefix, $params, @subkits) = @_;

	$kit     = "dev"    unless defined $kit;
	$version = "latest" unless defined $version;

	my $file = "$env.yml";
	open my $fh, ">", $file or die "Couldn't write to $file: $!";
	print $fh <<EOF;
---
kit:
  name:    $kit
  version: $version
EOF
	if (! @subkits) {
		print $fh "  subkits: []\n";
	} else {
		print $fh "  subkits:\n";
		for my $subkit (@subkits) {
			print $fh <<EOF;
  - $subkit
EOF
		}
	}
	print $fh <<EOF;

params:
  env:   $env
  vault: $vault_prefix
EOF
	if (defined($ENV{GENESIS_BOSH_ENVIRONMENT})) {
		print $fh <<EOF;
  bosh:  $ENV{GENESIS_BOSH_ENVIRONMENT}
EOF
	} elsif (defined($ENV{BOSH_ENVIRONMENT})) {
		print $fh <<EOF;
  bosh:  $ENV{BOSH_ENVIRONMENT}
EOF
	}

	for my $param (@$params) {
		print $fh "\n";
		my $indent = "  # ";
		if (defined $param->{comment}) {
			for my $line (split /\n/, $param->{comment}) {
				print $fh "${indent}$line\n";
			}
		}
		if (defined $param->{example}) {
			print $fh "${indent}(e.g. $param->{example})\n";
		}

		$indent = $param->{default} ? "  #" : "  ";

		for my $val (@{$param->{values}}) {
			my $k = (keys(%$val))[0];
			# if the value is a spruce operator, we know it's a string, and don't need fancy encoding of the value
			# this helps us not run into issues resolving the operator
			my $v = $val->{$k};
			if (defined $v && ! ref($v) && $v =~ m/^\(\(.*\)\)$/) {
				print $fh "${indent}$k: $v\n";
				next;
			}
			my $tmpdir = workdir;
			open my $tmpfile, ">", "$tmpdir/value_formatting";
			print $tmpfile encode_json($val);
			close $tmpfile;
			open my $spruce, "-|", "spruce merge $tmpdir/value_formatting";

			for my $line (<$spruce>) {
				chomp $line;
				next unless $line;
				next if $line eq "---";
				print $fh "${indent}$line\n";
			}
			close $spruce;
			die "Unable to convert JSON to spruce-compatible YAML. This is a bug\n"
				if $? >> 8;
		}
	}
	close $fh;
}

sub kit_yaml_files_in {
	my ($env, $dir, @subkits) = @_;
	$env =~ s/\.ya?ml$//;

	my @files = glob "$dir/base/*.yml";
	push @files, map { glob "$dir/subkits/$_/*.yml" } @subkits;
	return @files;
}

sub kit_yaml_files {
	my ($env) = @_;
	my @files;

	my $kit     = get_key($env, 'kit.name');
	my $version = get_key($env, 'kit.version');
	my @subkits = @{get_key($env, 'kit.subkits', [])};
	my $meta = read_kit_metadata($kit, $version);
	validate_subkits($kit, $version, $meta, @subkits);

	if ($kit && $version && $kit ne 'dev') {
		my $dir = workdir();
		qx(tar -xz -C $dir --strip-components 1 -f .genesis/kits/$kit-$version.tar.gz);
		$? == 0 or die;
		return kit_yaml_files_in($env, $dir, @subkits);
	}

	if (-d "dev") {
		return kit_yaml_files_in($env, "dev", @subkits);
	}

	die "No kit/version detected in $env.\n";
}

# takes a list of tokens, in order, and generates
# all strictly ordered combinations of them.
#
# for example:
#  [us, east, 1] -> [[us]
#                    [us-east]
#                    [us-east-1]]
#
sub expand_tokens {
	my @tokens = @_;

	my @l;
	my @pre;

	for (@tokens) {
		push @pre, $_;
		push @l, join '-', @pre;
	}

	return @l;
}

# return a list of the hyphen-separated tokens
# that form a common prefix to both arguments.
#
# for example:
#   us-east-1-preprod-a
#   us-east-1-sandbox-a
#   ->    (us, east, 1)
#
sub common_base {
	my ($a, $b) = @_;
	my @a = split /-/, $a;
	my @b = split /-/, $b;
	my @c = (); # common

	while (@a and @b) {
		$a = shift @a;
		$b = shift @b;
		last unless $a eq $b;
		push @c, $a;
	}
	return @c;
}

# return a list of the hyphen-separated tokens
# that form a unique suffix for the second argument.
#
# for example:
#   us-east-1-preprod-a
#   us-east-1-sandbox-a
#   ->     us-east-1, (sandbox, a)
sub unique_suffix {
	my ($a, $b) = @_;
	my @a = split /-/, $a;
	my @b = split /-/, $b;
	my @pre;

	while (@a and @b) {
		last if $a[0] ne $b[0];
		$a = shift @a;
		$b = shift @b;
		push @pre, $a;
	}
	return join('-', @pre), @b;
}

sub mergeable_yaml_files {
	my ($file) = @_;
	$file =~ s/\.yml$//;
	my @parts = split /-/, $file;

	my @ll;
	if ($ENV{PREVIOUS_ENV}) {
		for (expand_tokens(common_base($file, $ENV{PREVIOUS_ENV}))) {
			my $here = ".genesis/cached/$ENV{PREVIOUS_ENV}/$_.yml";
			push @ll, $here if -f $here;
		}
		my ($pre, @unique) = unique_suffix($ENV{PREVIOUS_ENV}, $file);
		$pre = "$pre-" unless $pre eq "";
		for (map { "$pre$_" } expand_tokens(@unique)) {
			my $here = "$_.yml";
			push @ll, $here if -f $here;
		}

	} else {
		while (@parts) {
			my $here = join('-', @parts) . ".yml";
			push @ll, $here if -f $here;
			pop @parts;
		}
		@ll = reverse @ll;
	}
	return @ll;
}

sub standalone_environment_yaml_files {
	my @envs = @_;
	grep { has_own_key($_, "params.env") } @envs;
}

sub has_key {
	my ($file, $key) = @_;
	for (mergeable_yaml_files $file) {
		chomp(my $out = qx(spruce json $_ | jq -r '.$key'));
		return 1 if $? == 0 and $out ne "null";
	}
	return 0;
}

sub has_own_key {
	my ($file, $key) = @_;
	return 0 unless -f $file;
	chomp(my $out = qx(spruce json $file | jq -r '.$key'));
	return 1 if $? == 0 and $out ne "null";
}

sub get_key {
	my ($file, $key, $default) = @_;
	return $default unless has_key($file, $key);

	my $result = Load(spruce_merge({ 'cherry-pick' => $key },
	                               mergeable_yaml_files($file)));
	for (grep {$_ !~ m/^\.?$/} split(/(\.|\[[0-9+]\])/, $key)) {
		if ($_ =~ m/^\[[0-9]+\]$/) {
			return $default unless @{$result}[0];
			$result = @{$result}[0];
		} else {
			return $default unless exists $result->{$_};
			$result = $result->{$_};
		}
	}
	return defined $result ? $result : $default;
}

sub has_subkit {
	my ($file, $subkit) = @_;
	my %subkits = map { $_ => 1 } @{get_key($file, "kit.subkits", [])};
	return $subkits{$subkit};
}

###########################################################################

sub dereference_param {
	my ($env, $key) = @_;
	my $val = get_key($env, $key);
	die "Unable to resolve '$key' for $env. This must be defined in the environment YAML.\n"
		unless defined $val;
	return $val;
}

sub dereference_params {
	my ($cmd, $env) = @_;
	$cmd =~ s/\$\{(.*?)\}/dereference_param($env, $1)/ge;
	return $cmd;
}

sub safe_commands {
	my ($creds, %options) = @_;
	my @cmds;
	my $force_rotate = ($options{scope}||'') eq 'force';
	my $missing_only = ($options{scope}||'') eq 'add';
	for my $path (sort keys %$creds) {
		if (! ref $creds->{$path}) {
			my $cmd = $creds->{$path};
			$cmd = dereference_params($cmd, $options{env});

			if ($cmd =~ m/^(ssh|rsa)\s+(\d+)(\s+fixed)?$/) {
				my $safe = [$1, $2, "secret/$options{prefix}/$path"];
				push @$safe, "--no-clobber", "--quiet" if ($3 && !$force_rotate) || $missing_only;
				push @cmds, $safe;

			} elsif ($cmd =~ m/^dhparams?\s+(\d+)(\s+fixed)?$/) {
				my $safe = ['dhparam', $1, "secret/$options{prefix}/$path"];
				push @$safe, "--no-clobber", "--quiet" if ($2 && !$force_rotate) || $missing_only;
				push @cmds, $safe;

			} else {
				die "unrecognized credential type: `$cmd'\n";
			}
		} elsif ('HASH' eq ref $creds->{$path}) {
			for my $attr (sort keys %{$creds->{$path}}) {
				my $cmd = $creds->{$path}{$attr};
				$cmd = dereference_params($cmd, $options{env});

				if ($cmd =~ m/^random\s+(\d+)(\s+fmt\s+(\S+)(\s+at\s+(\S+))?)?(\s+allowed-chars\s+(\S+))?(\s+fixed)?$/) {
					my ($len, $format, $destination, $valid_chars, $fixed) = ($1, $3, $5, $7, $8);
					my @allowed_chars = ();
					if ($valid_chars) {
						@allowed_chars = ("--policy", $valid_chars);
					}
					my $safe = ['gen', $len, @allowed_chars, "secret/$options{prefix}/$path", $attr];
					push @$safe, "--no-clobber", "--quiet" if ($fixed && !$force_rotate) || $missing_only;
					push @cmds, $safe;
					if ($format) {
						$destination ||= "$attr-$format";
						my $safe = ["fmt", $format , "secret/$options{prefix}/$path", $attr, $destination];
						push @$safe, "--no-clobber", "--quiet" if ($fixed && !$force_rotate) || $missing_only;
						push @cmds, $safe;
					}

				} else {
					die "unrecognized credential type: `$cmd'\n";
				}
			}
		} else {
			die "unrecognized datastructure for $path. Please contact your kit author\n";
		}
	}

	return @cmds;
}

sub cert_commands {
	my ($certs, %options) = @_;
	my @cmds;
	my $force_rotate = ($options{scope}||'') eq 'force';
	my $missing_only = ($options{scope}||'') eq 'add';
	for my $path (sort keys %$certs) {
		my @cmd = (
			"x509",
			"issue",
			"secret/$options{prefix}/$path/ca",
			"--name", "ca.$path",
			"--ca");
		push @cmd, "--no-clobber", "--quiet" if !$force_rotate; # All CA certs are considered kept
		push @cmds, \@cmd;

		for my $cert (sort keys %{$certs->{$path}}) {
			next if $cert eq "ca";
			my $c = $certs->{$path}{$cert};

			die "Required 'names' value missing for cert at $path/$cert.\n" unless $c->{names}[0];
			my $cn = $c->{names}[0];
			$c->{valid_for} ||= "1y";

			my @name_flags = map {( "--name", dereference_params($_, $options{env}) )} @{$c->{names}};
			my @cmd = (
				"x509",
				"issue",
				"secret/$options{prefix}/$path/$cert",
				"--ttl", $c->{valid_for},
				@name_flags,
				"--signed-by", "secret/$options{prefix}/$path/ca");
			push @cmd, "--no-clobber", "--quiet" if $missing_only;
			push @cmds, \@cmd;
		}
	}
	return @cmds;
}

sub check_secret {
	my ($cmd, %options) = @_;
	my (@keys);
	my $type = $cmd->[0];
	my $path = $cmd->[2];
	if ($type eq 'x509') {
		if (grep {$_ eq '--signed-by'} @$cmd) {
			$type = "certificate";
			@keys = qw(certificate combined key);
		} else {
			$type = "CA certificate";
			@keys = qw(certificate combined crl key serial);
		}
	} elsif ($type eq 'rsa') {
		@keys = qw(private public);
	} elsif ($type eq 'ssh') {
		@keys = qw(private public fingerprint);
	} elsif ($type eq 'dhparam') {
		@keys = qw(dhparam-pem);
	} elsif ($type eq 'gen') {
		$type = 'random';
		my $path_offset = $cmd->[1] eq '-l' ? 3 : 2;
		$path_offset += 2 if $cmd->[$path_offset] eq '--policy';
		$path = $cmd->[$path_offset];
		@keys = ($cmd->[$path_offset + 1]);
	} elsif ($type eq 'fmt') {
		$type = 'random/formatted';
		@keys = ($cmd->[4]);
	} else {
		die "Unrecognized credential or certificate command: '".join(" ", @$cmd)."'\n";
	}

	my @missing = ();
	for (@keys) {
		system('safe', 'exists', "$path:$_");
		push @missing, ["[$type]", "$path:$_"] if $?;
	}
	return @missing;
}

###########################################################################

sub validate_repo_name {
	my ($name) = @_;
	return $name =~ m/^[a-z][a-z0-9-]+$/;
}

sub validate_env_name {
	my ($name) = @_;
	return $name =~ m/^[a-z][a-z0-9-]+$/
	    && $name !~ m/--/;
}

###########################################################################

our %ord_suffix = (11 => 'th', 12 => 'th', 13 => 'th', 1 => 'st', 2 => 'nd', 3 => 'rd');
sub ordify {
	return "$_[0]". ($ord_suffix{ $_[0] % 100 } || $ord_suffix{ $_[0] % 10 } || 'th')." ";
}

sub __prompt_for_line {
	my ($prompt,$validation,$err_msg,$default,$allow_blank) = @_;
	$prompt = join(' ', grep {defined($_) && $_ ne ""} ($prompt, '>')) . " ";

	# `validate` is a sub with first argument the test value, and the second
	# being an optional error message
	my $validate;
	if (defined($validation)) {
		if ($validation =~ m/^\/(.*)\/(i?m?s?)$/) {
			my $__vre;
			# safe because the only thing being eval'ed is the optional i,s, or m
			eval "\$__vre = qr/\$1/$2"
				or die "Error compiling param regex: $!";
			$validate = sub() {
				return ($_[0] =~ $__vre ? "" : ( $_[1] ? $_[1] : "Does not match required pattern"));
			}
		} elsif ($validation =~ m/^((^|,)[^,]+){2,}$/) {
			my @__vlist = split(",", $validation);
			$validate = sub() {
				my $needle=shift;
				my @matches = grep {$_ eq $needle} @__vlist;
				return (scalar(@matches) != 0 ? "" : ($_[1] ? $_[1] : "Expecting one of ".join(", ",@__vlist)))
			}
		} elsif ($validation eq "vault_path") {
			my $validate = sub() {
				system "safe exists $_[0]";
				return ( $? eq 0 ? "" : ($_[1] ? $_[1] :"$_[0] not found in vault\n"))
			}
		}
	}

	while (1) {
		print csprintf($prompt);
		chomp (my $in=<STDIN>);
		$in = $default if ($in eq "" && defined($default));
		$in =~ s/^\s+|\s+$//g;

		return "" if ($in eq "" && $allow_blank);
		my $err="";
		if ($in eq "") {
			return "" if $allow_blank;
			$err= "#R{No default:} you must specify a non-empty string";
		} else {
			$err = &$validate($in,$err_msg) if defined($validate);
			$err = "#r{Invalid:} $err" if $err;
		}

		no warnings "numeric";
		return (($in eq $in + 0) ? $in + 0 : $in) unless $err;
		use warnings "numeric";
		error($err);
	}
}

sub __prompt_for_block {
	my ($prompt) = @_;
	$prompt = "$prompt (Enter <CTRL-D> to end)";
	(my $line = $prompt) =~ s/./-/g;
	print "\n$prompt\n$line\n";
	my @data = <STDIN>;
	return join("", @data);
}

sub prompt_for_boolean {
	my ($prompt,$default) = @_;

	my $true_re = qr/^(?:y(?:es)?|t(rue)?)$/i;
	my $false_re =  qr/^(?:no?|f(alse)?)$/i;
	my $val_prompt = "[y|n]";
	if (defined $default) {
		$default = $default ? "y" : "n" if $default =~ m/^[01]$/; # standardize
		$val_prompt = $default =~ $true_re ? "[#g{Y}|n]" : "[y|#g{N}]";
	}

	print "$prompt\n";
	while (1) {
		my $answer = __prompt_for_line($val_prompt,undef,undef,$default,'allow_blank');
		return JSON::PP::true  if $answer =~ $true_re;
		return JSON::PP::false if $answer =~ $false_re;
		error "#r{Invalid response:} you must specify y, yes, true, n, no or false";
	}
}

sub prompt_for_line {
	my ($prompt,$label,$default,$validation,$err_msg) = @_;
	print "$prompt";
	my $padding = ($prompt =~ /\s$/) ? "" : " ";
	print(csprintf("${padding}#g{(default: $default)}")) if defined($default);
	print "\n";
	return __prompt_for_line(defined($label) ? $label : "", $validation, $err_msg, $default);
}

sub prompt_for_list {
	my ($type,$prompt,$label,$min,$max,$validation, $err_msg) = @_;
	$label ||= "value";
	$min ||= 0;
	die "Illegal list maximum count specified. Please contact your kit author for a fix.\n"
		if (defined($max) and $max < 2);

	print "$prompt (leave $label empty to end)\n";

	my @ll;
	while (1) {
		my $v;
		if ($type eq 'line') {
			$v = __prompt_for_line(ordify(scalar(@ll) + 1) . $label, $validation, $err_msg, undef, 'allow_blank');
		} else {
			$v = __prompt_for_block(ordify(scalar(@ll) + 1) . $label);
		}
		if ($v eq "") {
			if (scalar(@ll) < $min) {
				error "#r{ERROR:} Insufficient items provided - at least $min required.";
				next;
			}
			last;
		}
		push @ll, $v;
		last if (defined($max) && scalar(@ll) == $max);
	}
	return \@ll;
}

sub prompt_for_block {
	return __prompt_for_block(@_);
}

my $BOSH; # used for abstracting out the actual name of the installed
          # bosh (v2) cli (could be bosh, bosh2, or boshv2)
sub detect_bosh_version {
	my ($BOSH2_MIN_VERSION) = @_;
	foreach my $boshcmd ("bosh", "bosh2", "boshv2") {
		my $version = qx($boshcmd -v 2>&1 | grep version | head -n1);
		if ($version) {
			chomp($version);
			if ($version =~ s/version (\S+?)-.*/$1/){
				if (!new_enough("bosh2", $version, $BOSH2_MIN_VERSION)) {
					error "BOSH (v2) CLI v${version} is installed, but Genesis requires #R{at least $BOSH2_MIN_VERSION} - upgrade your BOSH CLI, via #B{https://github.com/cloudfoundry/bosh-cli/releases}";
				}
				$BOSH = $boshcmd;
			}
		}
	}
	if (!$BOSH) {
		error "Missing `bosh2' - install the BOSH (v2) CLI from #B{https://github.com/cloudfoundry/bosh-cli/releases}";
	}
}

sub is_create_env {
	my ($env) = @_;
	# convert env to file for env if not already done
	$env = "$env.yml" unless $env =~ /\.yml$/;
	return has_subkit($env, 'bosh-init') || has_subkit($env, 'create-env');
}

sub bosh_deploy {
	my ($target, $deployment, $path_to_manifest, @deploy_opts) = @_;
	my @args = ();
	if ($target eq "create-env") {
		@args = ("create-env", "--state", $deployment);
		push @args, "-n" if $ENV{BOSH_NON_INTERACTIVE};
		push @args, $path_to_manifest;
	} else {
		@args = ("-e", $target, "-d", $deployment);
		push @args, "-n" if $ENV{BOSH_NON_INTERACTIVE};
		push @args, "deploy", @deploy_opts, $path_to_manifest;
	}
	system($BOSH, @args) == 0 or return 1;
	return 0;
}

sub bosh_alias {
	my ($target) = @_;
	system($BOSH, "alias-env", $target) == 0, or exit 1;
}

sub bosh_run_errand {
	my ($target, $deployment, $errand) = @_;
	system($BOSH, "-n", "-e", $target, "-d", $deployment, "run-errand", $errand) == 0 or exit 1;
}

sub bosh_upload_stemcell {
	my ($name, $version, $sha1, $url) = @_;
	system($BOSH, "-n", "upload-stemcell", "--name", $name, "--version", $version, "--sha1", $sha1, $url) == 0 or exit 1;
}

sub bosh_download_cloud_config {
	my ($target, $path_to_cloudconfig) = @_;
	execute("$BOSH -e $target cloud-config > $path_to_cloudconfig") or
		die "Failed to download cloud-config from '$target' BOSH director.\n";
	die "No cloud-config defined on BOSH director '$target'.\n" unless -s $path_to_cloudconfig;
}

# `genesis bosh ...`
sub bosh_exec {
	die "not implemented";
}

sub write_stemcell_data {
	my ($file) = @_;
	my $stemcells = "{}";
	if ($ENV{GENESIS_INDEX} ne "no") {
		$stemcells = `curl -ks $ENV{GENESIS_INDEX}/v1/stemcell/latest | jq '. | map({"key": .name, "value": { "sha1": .sha1, "url": .url}}) | from_entries' -Mc`;
		die "Unable to contact the genesis index to retrieve stemcell data. Cannot continue." unless ($? == 0);
	}
	open my $fh, ">", $file;
	print $fh <<EOF;
---
meta:
  latest_stemcells: $stemcells

EOF
	close $fh;
}

sub spruce_vault_paths {
	my (@files) = @_;
	my $ymls = join(" ", @files);
	my @keys= qx/spruce vaultinfo --go-patch $ymls | spruce json | jq -r '.secrets[].key'/;
	if ($? != 0) {
		die "Failure while running spruce vaultinfo.\n";
	}
	my %paths = map {$_ =~ s/:.*?$//; $_ => 1} @keys;
	return keys %paths;
}

sub spruce_merge {
	my (@files) = @_;
	if (!@files) {
		my (undef, $file, $line) = caller;
		die "BUG DETECTED!  $file:$line called spruce_merge without any arguments.  Please file a bug report at $GITHUB_URL\n";
	}

	# spruce_merge({ prune => ['meta', 'pipeline']}, $file1, $file2)
	# spruce_merge({ prune => 'meta'}, $file1, $file2)
	my $opts = ref($files[0]) eq 'HASH' ? shift @files : {};
	my @flags;
	for my $flag (keys %$opts) {
		for my $value (ref($opts->{$flag}) ? @{ $opts->{$flag} } : ($opts->{$flag})) {
			push @flags, "--$flag", $value;
		}
	}
	push @flags, "--go-patch";

	open my $cmd, "-|", (qw(spruce merge), @flags, @files)
		or die "Failed to execute `spruce merge': $!\n";
	my $out = do { local $/; <$cmd> };
	close $cmd;
	exit ($? >> 8 ) unless $? == 0;
	return $out;
}

# finds the "name" of the deployment type that we are in
# (i.e. redis-deployments/... -> 'redis')
sub deployment_suffix {
	my $config = LoadFile(".genesis/config");
	die "No deployment type defined in .genesis/config." unless $config->{deployment_type};
	return $config->{deployment_type};
}

sub base_yaml_files {
	my ($env) = @_;
	my $type = deployment_suffix;
	my $dir = workdir;
	open my $fh, ">", "$dir/base.yml";
	print $fh <<EOF;
params:
  name: (( concat params.env "-$type" ))
name: (( grab params.name ))
EOF
	close $fh;
	return "$dir/base.yml";
}

sub merge_files {
	my ($env, $options) = @_;
	$env =~ s/(\.yml)?$/.yml/;

	my @files = ();
	push @files, base_yaml_files($env);
	push @files, kit_yaml_files($env);
	push @files, mergeable_yaml_files($env);
	push @files, grep { $_ } $options->{'cloud-config'};
	return \@files;
}

sub merge_manifest {
	my ($file, $options) = @_;
	$file =~ s/(\.yml)?$/.yml/;

	my @prunables = qw/meta pipeline params kit compilation/;
	push @prunables, qw/resource_pools disk_pools
	                    networks vm_types disk_types
	                    azs vm_extensions/
		unless $options->{'create-env'};

	if ($options->{'create-env'}) {
		my $dir = workdir;
		write_stemcell_data("$dir/cloud.yml");
		$options->{'cloud-config'} = "$dir/cloud.yml";
	}

	return spruce_merge({
			prune => [@prunables],
		},
		@{merge_files($file, $options)});
}

sub deploy_manifest {
	my ($env, $options) = @_;
	$ENV{REDACT} = '';
	my $dir = workdir;
	my $target = ''; 
	my $create_env = has_subkit($env, 'bosh-init') || has_subkit($env, 'create-env');

	if (!$create_env) {
		$target = bosh_target_for($env);
		bosh_download_cloud_config($target, "$dir/cloud.yml");
		$options->{'cloud-config'} = "$dir/cloud.yml";
	} else {
		$ENV{OFFLINE} = 1; # set offline since there's no director to talk to
	}

	my $merge_opts = {
		'cloud-config' => $options->{'cloud-config'},
		'create-env'   => $create_env,
	};
	mkfile_or_fail("$dir/manifest.yml", merge_manifest($env, $merge_opts));

	$env =~ s/.yml$//;
	my $deployment = "$env-" . deployment_suffix;

	mkdir_or_fail(".genesis/manifests");

	$ENV{REDACT} = 'true';
	mkfile_or_fail(".genesis/manifests/$env.yml", merge_manifest($env, $merge_opts));

	if ($create_env) {
		$target = "create-env";
		$deployment = ".genesis/manifests/$env-state.yml";
	}
	my @deploy_opts;
	foreach (qw/no-redact fix recreate/) {
		push @deploy_opts, "--$_" if $options->{$_};
	}
	my $rc = bosh_deploy $target, $deployment, "$dir/manifest.yml", @deploy_opts;
	return $rc;
}

sub curl {
	my ($method, $url, $headers, $data, $skip_verify, $creds) = @_;
	my $flags = "-X '$method'";
	for my $header (keys %$headers) {
		$flags .= " -H '$header: $headers->{$header}'";
	}
	if ($data) {
		$flags .= " -d '$data'";
	}
	if ($skip_verify) {
		$flags .= " -k";
	}
	if ($creds) {
		$flags .= " -u '$creds'";
	}
	my $status = "";
	my $status_line = "";
	my @data = qx(curl -isL $url $flags);
	unless (scalar(@data) && $? == 0) {
		system "curl -L $url $flags"; # curl again to get stdout/err into concourse for debugging
		return 599, "Unable to execute curl command", "";
	}
	while (my $line = shift @data) {
		if ($line =~ m/^HTTP\/\d+\.\d+\s+((\d+)(\s+.*)?)$/) {
			$status_line = $1;
			$status = $2;
		}
		# curl -iL will output a second set of headers if following links
		if ($line =~ /^\s+$/ && $status !~ /^3\d\d$/) {
			last;
		}
	}
	return $status, $status_line, join("", @data);
}

###########################################################################

sub vault_auth {
	my %options = @_;
	for (qw/vault skip_verify secret_id role_id/) {
		next if exists $options{$_} and defined $options{$_};
		die "vault_auth() requires the '$_' argument; please file a bug.\n";
	}

	my ($code, $msg, $data) = curl "POST", "$options{vault}/v1/auth/approle/login", {
			'Content-type' => 'application/json',
		},
		encode_json({
			role_id => $options{role_id},
			secret_id  => $options{secret_id},
		}), $options{skip_verify};

	if ($code != 200) {
		die "Failed to authenticate to the Vault at $options{vault} using role ID $options{role_id}:\n".
			"HTTP $msg\n$data\n";
	}
	my $output;
	eval { $output = decode_json($data); 1 }
		or die "Invalid JSON received from the Vault at $options{vault}\n($data)\n";
	exists $output->{auth} and exists $output->{auth}{client_token}
		or die "No Client Token found in response from the Vault at $options{vault}\n($data)\n";

	$ENV{VAULT_TOKEN} = $output->{auth}{client_token};
	$output = qx(vault status 2>&1);
	if ($? != 0) {
		die "Failed to authenticate to the Vault at $options{vault}\n:`vault status` said:\n$output\n";
	}

	$output = qx(vault read secret/handshake 2>&1);
	if ($? != 0) {
		die "Failed to retrieve secret/handshake from the Vault at $options{vault}; assuming token authentication failure.\n";
	}
}

sub commit_changes {
	my ($indir, $outdir, $branch, $key, $message) = @_;

	# the below copying of files into new repos from older repos is all
	# done in the name of avoiding merge conflicts, or weird errors when
	# rebasing, and git discovers that there are no changes after you rebase

	# create an output git repo based off of latest origin/$branch
	system("cp -R $indir $outdir") == 0 or exit 1;
	pushd $outdir;

	# We need this here so we can do a manual pull after the build/deploy, but
	# prior to pushing. Rebasing inside the concourse resource will not work,
	# as we are changing files that are not watched by the resources. This may
	# cause conflicts as older commits try to change more and more things that
	# have already been updated in the .genesis/manifests directory.
	#
	my $tmp = workdir;
	mkdir_or_fail("$tmp/home/.ssh");
	chmod_or_fail(0700, "$tmp/home/.ssh");
	put_file("$tmp/home/.ssh/key", $key, 0600);
      put_file("$tmp/home/.ssh/config", <<EOF);
Host *
  StrictHostKeyChecking no
  UserKnownHostsFile /dev/null
  LogLevel QUIET
  IdentityFile $tmp/home/.ssh/key
EOF

	$ENV{GIT_AUTHOR_NAME}   ||= 'Concourse Bot';
	$ENV{GIT_AUTHOR_EMAIL}  ||= 'concourse@pipeline';
	$ENV{GIT_COMMITTER_NAME}  = $ENV{GIT_AUTHOR_NAME};
	$ENV{GIT_COMMITTER_EMAIL} = $ENV{GIT_AUTHOR_EMAIL};
	$ENV{GIT_ASKPASS}         = "/bin/false";
	$ENV{GIT_SSH_COMMAND}     = "ssh -F $tmp/home/.ssh/config";
	$ENV{HOME}                = "$tmp/home";

	# no need to fetch or pull from origin/$branch, as the git resource in the pipeline should
	# have the latest data from origin, we just need to reset to the newest applicable ref
	system(qq( HOME=$tmp/home \
	             git reset --hard origin/$branch && \
	             git checkout $branch && \
	             git pull origin $branch)) == 0 or exit 1;
	popd;

	# find and copy all potential changes to the outdir
	pushd $indir;
	my @output = qx(git status --porcelain);
	popd;
	my @changes = map { chomp; s/^...//; $_; } @output;
	for my $file (@changes) {
		mkdir_or_fail(dirname("$outdir/$file"));
		system("cp", "-R", "$indir/$file", "$outdir/$file") == 0 or exit 1;
	}

	# check if any changes actually exist in the outdir (potential changes may have alread
	# been tracked after $indir's commit, so they could disappear here), then commit them
	pushd $outdir;
	my $output = qx(git status --porcelain 2>&1);
	if ($output) {
		system(qq( HOME=$tmp/home \
		             git add -A && \
		             git status && \
		             git --no-pager diff --cached && \
		             git commit -m "CI commit: $message" ));
	}
}

sub read_pipeline {
	my ($file) = @_;

	my @errors = ();
	my $p = Load(spruce_merge($file));
	unless (exists $p->{pipeline}) {
		# fatal error
		push @errors, "Missing top-level 'pipeline:' key.";
		return $p, \@errors;
	}

	unless (ref($p->{pipeline}) eq 'HASH') {
		# fatal error
		push @errors, "Top-level 'pipeline:' key must be a map.";
		return $p, \@errors;
	}
	for (keys %{$p->{pipeline}}) {
		push @errors, "Unrecognized `pipeline.$_' key found."
			unless m/^(name|public|tagged|errands|vault|git|slack|hipchat|email|boshes|task|layout|layouts|debug|stemcells|skip_upkeep|locker)$/;
	}
	for (qw(name vault git boshes)) {
		push @errors, "`pipeline.$_' is required."
			unless $p->{pipeline}{$_};
	}

	# validate pipeline.vault.*
	if (ref($p->{pipeline}{vault}) ne 'HASH') {
		push @errors, "`pipeline.vault' must be a map.";
	} else {
		# required subkeys
		for (qw(url)) {
			push @errors, "`pipeline.vault.$_' is required."
				unless $p->{pipeline}{vault}{$_};
		}
		# allowed subkeys
		for (keys %{$p->{pipeline}{vault}}) {
			push @errors, "Unrecognized `pipeline.vault.$_' key found."
				unless m/^(url|role|secret|verify)$/;
		}
	}

	# validate pipeline.git.*
	if (ref($p->{pipeline}{git}) ne 'HASH') {
		push @errors, "`pipeline.git' must be a map.";
	} else {
		# required subkeys
		for (qw(owner repo private_key)) {
			push @errors, "`pipeline.git.$_' is required."
				unless $p->{pipeline}{git}{$_};
		}
		# allowed subkeys
		for (keys %{$p->{pipeline}{git}}) {
			push @errors, "Unrecognized `pipeline.git.$_' key found."
				unless m/^(host|owner|repo|private_key)$/;
		}
	}

	# validate stemcells
	if (! $p->{pipeline}{skip_upkeep}) {
		if (! $p->{pipeline}{stemcells}) {
			push @errors, "Neither `pipeline.skip_upkeep' nor `pipeline.stemcells' were configured. One or the other is required.";
		} elsif (ref($p->{pipeline}{stemcells}) ne 'HASH') {
			push @errors, "`pipeline.stemcells' must be a map.";
		}
	}

	# validate locker
	if ($p->{pipeline}{locker}) {
		if (ref($p->{pipeline}{locker}) ne 'HASH') {
			push @errors, "`pipeline.locker' must be a map.";
		} else {
			for (qw/url username password/) {
				push @errors, "`pipeline.locker.$_' is required."
					unless $p->{pipeline}{locker}{$_};
			}
			for (keys %{$p->{pipeline}{locker}}) {
				push @errors, "Unrecognized `pipeline.locker.$_' key found."
					unless m/^(url|username|password|ca_cert|skip_ssl_validation)/;
			}
		}
	} else {
		$p->{pipeline}{locker}{url} = "";
	}

	# validate notifications
	my $n = 0;
	for (qw(slack hipchat email)) {
		$n++ if exists $p->{pipeline}{$_};
	}
	if ($n == 0) {
		push @errors, "No notification stanzas defined.  Please define `pipeline.slack' or `pipeline.email'.\n";
	} else {
		if ($p->{pipeline}{slack}) {
			# validate pipeline.slack.*
			if (ref($p->{pipeline}{slack}) ne 'HASH') {
				push @errors, "`pipeline.slack' must be a map.";
			} else {
				# required subkeys
				for (qw(webhook channel)) {
					push @errors, "`pipeline.slack.$_' is required."
						unless $p->{pipeline}{slack}{$_};
				}
				# allowed subkeys
				for (keys %{$p->{pipeline}{slack}}) {
					push @errors, "Unrecognized `pipeline.slack.$_' key found."
						unless m/^(webhook|channel|username|icon)$/;
				}
			}
		}
		if ($p->{pipeline}{hipchat}) {
			# validate pipeline.hipchat.*
			if (ref($p->{pipeline}{hipchat}) ne 'HASH') {
				push @errors, "`pipeline.hipchat' must be am ap.";
			} else {
				# required subkeys
				for (qw/room_id token/) {
					push @errors, "`pipeline.hipchat.$_' is required."
						unless $p->{pipeline}{hipchat}{$_};
				}
				# allowed subkeys
				for (keys %{$p->{pipeline}{hipchat}}) {
					push @errors, "Unrecognized `pipeline.hipchat.$_' key found."
						unless m/^(url|token|room_id|notify|username)$/;
				}
			}
		}
		if ($p->{pipeline}{email}) {
			# validate pipeline.email.*
			# FIXME: fully implement and test email notifications
			push @errors, "Email notifications are not fully implemented yet.";
			if (ref($p->{pipeline}{email}) ne 'HASH') {
				push @errors, "`pipeline.email' must be a map.";
			} else {
				# required subkeys
				for (qw(to from smtp)) {
					push @errors, "`pipeline.email.$_' is required."
						unless $p->{pipeline}{email}{$_};
				}
				# to must be a list...
				if (exists $p->{pipeline}{email}{to}) {
					if (ref($p->{pipeline}{email}{to}) ne 'ARRAY') {
						push @errors, "`pipeline.email.to' must be a list of addresses.";
					} else {
						if (@{$p->{pipeline}{email}{to}} == 0) {
							push @errors, "`pipeline.email.to' must contain at least one address.";
						}
					}
				}
				# allowed subkeys
				for (keys %{$p->{pipeline}{email}}) {
					push @errors, "Unrecognized `pipeline.email.$_' key found."
						unless m/^(to|from|smtp)$/;
				}
				if (ref($p->{pipeline}{email}{smtp}) eq 'HASH') {
					# required sub-subkeys
					for (qw(host username password)) {
						push @errors, "`pipeline.email.smtp.$_' is required."
							unless $p->{pipeline}{email}{smtp}{$_};
					}
					# allowed subkeys
					for (keys %{$p->{pipeline}{email}{smtp}}) {
						push @errors, "Unrecognized `pipeline.email.smtp.$_' key found."
							unless m/^(host|port|username|password)$/;
					}
				} else {
				}
			}
		}
	}

	# validate (optional) pipeline.task.*
	if (exists $p->{pipeline}{task}) {
		if (ref($p->{pipeline}{task}) eq 'HASH') {
			# allowed subkeys
			for (keys %{$p->{pipeline}{task}}) {
				push @errors, "Unrecognized `pipeline.task.$_' key found."
					unless m/^(image|version)$/;
			}
		} else {
			push @errors, "`pipeline.task' must be a map.";
		}
	}

	# validate layouts
	my $key = undef; # for better messaging, later
	if (exists $p->{pipeline}{layout} && exists $p->{pipeline}{layouts}) {
		push @errors, "Both `pipeline.layout' and `pipeline.layouts' (plural) specified.  Please pick one or the other.";
	} elsif (exists $p->{pipeline}{layout}) {
		$p->{pipeline}{layouts}{default} = $p->{pipeline}{layout};
		delete $p->{pipeline}{layout};
		$key = 'pipeline.layout'; # we're pretending the user did it correctly.
	}
	if (ref($p->{pipeline}{layouts}) eq 'HASH') {
		for (keys %{$p->{pipeline}{layouts}}) {
			if (ref($p->{pipeline}{layouts}{$_})) {
				my $k = $key || "pipeline.layouts.$_";
				push @errors, "`$k' must be a string.";
			}
		}
	} else {
		push @errors, "`pipeline.layouts' must be a map.";
	}

	# validate BOSH directors
	if (ref($p->{pipeline}{boshes}) eq 'HASH') {
		for my $env (keys %{$p->{pipeline}{boshes}}) {
			# required sub-subkeys
			if (is_create_env($env)) {
				# allowed subkeys for a create-env deploy
				for (keys %{$p->{pipeline}{boshes}{$env}}) {
					push @errors, "Unrecognized `pipeline.boshes[$env].$_' key found."
						unless m/^(alias)$/;
				}
			} else {
				for (qw(url ca_cert username password)) {
					push @errors, "`pipeline.boshes[$env].$_' is required."
						unless $p->{pipeline}{boshes}{$env}{$_};
				}
				# allowed subkeys
				for (keys %{$p->{pipeline}{boshes}{$env}}) {
					push @errors, "Unrecognized `pipeline.boshes[$env].$_' key found."
						unless m/^(stemcells|url|ca_cert|username|password|alias)$/;
				}
			}

			if (! $p->{pipeline}{skip_upkeep}) {
				unless (is_create_env($env)) {
					if (! $p->{pipeline}{boshes}{$env}{stemcells}) {
						push @errors, "No stemcells specified for `pipeline.boshes[$env]' and `pipeline.skip_upkeep' not enabled.";
					} elsif (ref($p->{pipeline}{boshes}{$env}{stemcells}) ne 'ARRAY') {
						push @errors, "`pipeline.boshes[$env].stemcells' is not an array";
					} else {
						for (@{$p->{pipeline}{boshes}{$env}{stemcells}}) {
							push @errors, "`pipeline.boshes[$env].stemcells.$env' is not a stemcell alias listed in `pipeline.stemcells'"
								unless $p->{pipeline}{stemcells}{$_};
						}
					}
				}
			}
		}
	}

	return $p, @errors;
}

sub parse_pipeline {
	my ($file, $layout) = @_;
	my ($pipeline, @errors) = read_pipeline($file);
	if (@errors) {
		error "#R{ERRORS encountered} in pipeline definition in #Y{$file}:";
		error "  - #R{$_}" for @errors;
		exit 1;
	}

	my $src = $pipeline->{pipeline}{layouts}{$layout}
		or die "No such layout `${layout}'\n";

	# our internal representatio
	my $P = $pipeline;
	$P->{file} = $file;  # the path to the original pipeline file,
	                     # which we need to merge in with the guts.yml
	                     # definition to get the final configuration.

	$P->{auto} = [];     # list of patterns that match environments
	                     # we want concourse to trigger automatically.

	$P->{envs} = [];     # list of all environment names seen in the
	                     # configuration, to be used for validation.

	$P->{will_trigger} = {}; # map of (A -> [B, C, D]) triggers, where A triggers
	                         # a deploy (or notification) of B, C, and D.  Note that
	                         # the values are lists, because one environment
	                         # can trigger multiple other environments.
	$P->{triggers} = {};     # map of B -> A where B was a deploy triggered
	                         # by a successful deploy of A. Only one environment
	                         # can have triggered each given environment

	# handle yes/no/y/n/true/false/1/0 in our source YAML.
	$P->{pipeline}{tagged} = yaml_bool($P->{pipeline}{tagged}, 0);
	$P->{pipeline}{public} = yaml_bool($P->{pipeline}{public}, 0);

	# some default values, if the user didn't supply any
	$P->{pipeline}{vault}{role}   ||= "";
	$P->{pipeline}{vault}{secret} ||= "";
	$P->{pipeline}{vault}{verify} = yaml_bool($P->{pipeline}{vault}{verify}, 1);

	$P->{pipeline}{task}{image}   ||= 'starkandwayne/concourse';
	$P->{pipeline}{task}{version} ||= 'latest';

	# NOTE that source-level mucking about via regexen obliterates
	# all of the line and column information we would expect from
	# a more traditional parser.  If it becomes important to report
	# syntax / semantic errors with line information, this whole
	# parser has to be gutted and re-written.

	$src =~ s/\s*#.*$//gm;   # remove comments (without strings, this is fine)
	$src =~ s/[\r\n]+/ ; /g; # collapse newlines into ';' terminators
	$src =~ s/(^\s+|\s+$)//; # strip leading and trailing whitespace

	# condense the raw stream of tokens into a list or rules,
	# where each rule is itself a list of the significant tokens
	# between two terminators (or begining of file and a terminator)
	#
	# i.e.
	#   [['auto', 'sandbox*'],
	#    ['auto', 'preprod*'],
	#    ['tagged'],
	#    ['sandbox-a', '->', 'sandbox-b']]
	#
	# this structure is designed to be easier to interpret individual
	# rules from, since we can assert against arity and randomly access
	# tokens (i.e. a trigger rule must have '->' at $rule[1]).
	#
	my @rules = ();
	my $rule = [];
	for my $tok (split /\s+/, "$src ;") {
		$tok or die "'$tok' was empty in [$src]!\n";
		if ($tok eq ';') {
			if (@$rule) {
				push @rules, $rule;
				$rule = [];
			}
			next;
		}
		push @$rule, $tok;
	}

	my @auto; # patterns; we'll expand them once we have all the
	          # environments, and then populate $P->{auto};
	my %envs; # de-duplicating map; keys will become $P->{envs}
	for $rule (@rules) {
		if (@$rule >= 3 && $rule->[1] eq '->') {
			my $orig = join ' ', @$rule;
			while (@$rule >= 3 && $rule->[1] eq '->') {
				my ($a, $b) = ($rule->[0], $rule->[2]);
				$envs{$a} = $envs{$b} = 1;
				$P->{will_trigger}{$a} ||= [];
				push @{$P->{will_trigger}{$a}}, $b;
				shift @$rule;
				shift @$rule;
			}
			die "Invalid pipeline definition '$orig'.\n"
				unless @$rule == 1;
			next;
		}

		my ($cmd, @args) = @$rule;
		if ($cmd eq 'auto') {
			die "The 'auto' directive requires at least one argument.\n"
				unless @args;
			push @auto, @args;
			next;
		}

		die "Unrecognized configuration directive '$cmd'.\n";
	}
	$P->{envs} = [keys %envs];
	$P->{aliases} = { map { $_ => ($P->{pipeline}{boshes}{$_}{alias} || $_) } keys %envs};

	%envs = (); # we'll reuse envs for auto environment de-duplication
	for my $pattern (@auto) {
		my $regex = $pattern;
		$regex =~ s/\*/.*/g;
		$regex = qr/^$regex$/;

		my $n = 0;
		for my $env (@{$P->{envs}}) {
			if ($env =~ $regex) {
				$envs{$env} = 1;
				$n++;
			}
		}
		if ($n == 0) {
			error "#Y{warning}: rule `auto $pattern' did not match any environments...\n";
		}
	}
	$P->{auto} = [keys %envs];

	# make sure we have a BOSH director for each seen environment.
	# (thanks to read_pipeline, we know any extant BOSH director configs are good)
	for my $env (@{$P->{envs}}) {
		die "No BOSH director configuration found for $env (at `pipeline.boshes[$env]').\n"
			unless $P->{pipeline}{boshes}{$env};
	}

	# figure out who triggers each environment.
	# this is an inversion of the directed acyclic graph that we
	# are storing in {triggers}.
	#
	# this means that it is illegal for a given environment to be
	# triggererd by more than one other environment.  this decision
	# was made to simplify implementation, and was deemed to not
	# impose overly much on desired pipeline structure.
	my $triggers = {};
	for my $a (keys %{$P->{will_trigger}}) {
		for my $b (@{$P->{will_trigger}{$a}}) {
			# $a triggers $b, that is $b won't deploy unti we
			# see a successful deploy (+test) of the $a environment
			die "Environment '$b' is already being triggered by environment '$triggers->{$b}'.\nIt is illegal to trigger an environment more than once.\n"
				if $triggers->{$b} and $triggers->{$b} ne $a;
			$triggers->{$b} = $a;
		}
	}
	$P->{triggers} = $triggers;

	return $P;
}

# FYI: we use quasi-JSON here, so we don't need to care about our indent level when consuming
#      the notification definitions
sub gen_notifications {
	my ($pipeline, $message, $alias) = @_;
	$alias = "" unless defined $alias;
	my $notification = "aggregate: [\n";
	if ($pipeline->{pipeline}{slack}) {
		$notification .= <<EOF;
{
  put: "slack",
  params: {
    channel: "(( grab pipeline.slack.channel ))",
    username: "(( grab pipeline.slack.username ))",
    icon_url: "(( grab pipeline.slack.icon ))",
    text: '(( concat pipeline.name ": $message" ))'
  }
},
EOF
	}
	if ($pipeline->{pipeline}{hipchat}) {
		$notification .= <<EOF;
{
  put: "hipchat",
  params: {
    from: "(( grab pipeline.hipchat.username ))",
    color: "gray",
    message: '(( concat pipeline.name ": $message" ))',
    notify: "(( grab pipeline.hipchat.notify ))"
  }
},
EOF
	}
	if ($pipeline->{pipeline}{email}) {
		$notification .= <<EOF;
{
  do: [
  { get: build-email-$alias },
  { task: write-email-body,
    config: {
      platform: linux,
      image_resource: {
        type: docker-image,
        source: {
          repository: ubuntu,
        },
      },

      inputs: [
        { name: build-email-$alias },
        { name: out },
      ],
      outputs: [
        { name: email },
      ],

      run: {
        path: build-email-$alias/run,
        args: [],
      },
    },
  },

  { put: email,
    params: {
      body:    email/body,
      headers: email/header,
      subject: email/subject,
    },
  }]
}
EOF
	}
	$notification .= "]";
	return $notification;
}

sub generate_pipeline_concourse_yaml {
	my ($pipeline) = @_;
	my $dir = workdir;
	open my $OUT, ">", "$dir/guts.yml"
		or die "Failed to generate Concourse Pipeline YAML configuration: $!\n";

	# Figure out what environments auto-trigger, and what don't
	my %auto = map { $_ => 1 } @{$pipeline->{auto}};

	# Determine what stemcells are being tracked
	my @stemcells = ();
	unless ($pipeline->{pipeline}{skip_upkeep}) {
		@stemcells = map { { name => $pipeline->{pipeline}{stemcells}{$_}, alias => $_ } } keys %{$pipeline->{pipeline}{stemcells}}
	}

	# CONCOURSE: pipeline (+params) {{{
	print $OUT <<'EOF';
---
pipeline:
  git:
    host:        github.com
    uri:         (( concat "git@" pipeline.git.host ":" pipeline.git.owner "/" pipeline.git.repo ))
    owner:       (( param "Please specify the name of the user / organization that owns the Github repository" ))
    repo:        (( param "Please specify the name of the Github repository" ))
    branch:      master
    private_key: (( param "Please generate an SSH Deployment Key and install it into Github (with write privileges)" ))

EOF

	if ($pipeline->{pipeline}{slack}) {
		print $OUT <<'EOF';
  slack:
    webhook:  (( param "Please provide a Slack Integration WebHook." ))
    channel:  (( param "Please specify the channel (#name) or user (@user) to send messages to." ))
    username: runwaybot
    icon:     http://cl.ly/image/3e1h0H3H2s0P/concourse-logo.png
EOF
	}
	if ($pipeline->{pipeline}{hipchat}) {
		print $OUT <<'EOF';
  hipchat:
    url:      http://api.hipchat.com
    room_id:  (( param "Please specify the room ID that Concourse should send HipChat notifications to" ))
    token:    (( param "Please specify the HipChat authentication token" ))
    notify:   false
    username: runwaybot
EOF
	}
	if ($pipeline->{pipeline}{email}) {
		print $OUT <<'EOF';
  email:
    to:   (( param "Please provide a list of email addresses to send 'Pending Deployment' notifications to." ))
    from: (( param "Please specify a 'From:' account (an email address).  Email will be sent from this address." ))
    smtp:
      username: (( param "Please provide a username to authenticate against your Mail Server (SMTP) host." ))
      password: (( param "Please provide a password to authenticate against your Mail Server (SMTP) host." ))
      host:     (( param "Please specify the FQDN or IP address of your Mail Server (SMTP) host." ))
      port:     587
EOF
	}
	if ($pipeline->{pipeline}{locker}{url}) {
		print $OUT <<'EOF';
  locker:
    url:                 (( param "Please provide the URI to the locker API" ))
    username:            (( param "Please provide the locker API username" ))
    password:            (( param "Please provide the locker API password" ))
    # FIXME until we have service discovery (bosh dns) to reliably know the
    #       locker hostname, and have a ca_cert generated in the concourse kit,
    #       we need to turn on skip_ssl_validation, and nullify the ca_cert by default
    ca_cert:             ~
    skip_ssl_validation: true

EOF
	}
	# }}}
	# CONCOURSE: groups, and resource configuration {{{
	print $OUT <<EOF;
groups:
  - name: $pipeline->{pipeline}{name}
    jobs:
EOF
	print $OUT "    - $_\n" for sort map { "$pipeline->{aliases}{$_}-" . deployment_suffix } @{$pipeline->{envs}};
	print $OUT "    - notify-$_-changes\n" for sort map { "$pipeline->{aliases}{$_}-" . deployment_suffix }
		grep { ! $auto{$_} } @{$pipeline->{envs}};

	print $OUT <<EOF;

resources:
  - name: git
    type: git
    source:
      branch:      (( grab pipeline.git.branch ))
      private_key: (( grab pipeline.git.private_key ))
      uri:         (( grab pipeline.git.uri ))
EOF
	for (@stemcells) {
		print $OUT <<EOF;
  - name: $_->{alias}-stemcell
    type: bosh-io-stemcell
    source: { name: $_->{name} }
EOF
	}
   # }}}
	# CONCOURSE: env-specific resource configuration {{{
	for my $env (sort @{$pipeline->{envs}}) {
		my $alias = $pipeline->{aliases}{$env};
		print $OUT <<EOF;
  - name: ${alias}-changes
    type: git
    source:
      .: (( inject resources.git.source ))
      paths:
EOF
		# watch the common files in our predecessor cache - for example,
		# if us-west-1-sandbox-a triggers us-west-1-preprod-a, then
		# preprod-a would watch the cache of sandbox-a for:
		#
		#    us.yml
		#    us-west.yml
		#    us-west-1.yml
		#
		# and it would only check the top-level root for it's own files:
		#
		#    us-west-1-preprod.yml
		#    us-west-1-preprod-a.yml
		#
		if ($pipeline->{triggers}{$env}) {
			my $trigger = $pipeline->{triggers}{$env};
			my ($pre, @unique) = unique_suffix($trigger, $env);
			$pre = "$pre-" unless $pre eq "";
			for (map { "$pre$_" } expand_tokens(@unique)) {
				print $OUT <<EOF;
        - ${_}.yml
EOF
			}
			print $OUT <<EOF;

  - name: ${alias}-cache
    type: git
    source:
      .: (( inject resources.git.source ))
      paths:
        - .genesis/bin/genesis
        - .genesis/kits
        - .genesis/config
EOF
			print $OUT "# $trigger -> $env\n";
			for (expand_tokens(common_base($env, $trigger))) {
				print $OUT <<EOF;
        - .genesis/cached/${trigger}/${_}.yml
EOF
			}
		} else {
			print $OUT <<EOF;
        - .genesis/bin/genesis
        - .genesis/kits
        - .genesis/config
EOF
			for (expand_tokens(split /-/, $env)) {
				print $OUT <<EOF;
        - ${_}.yml
EOF
			}
		}
		unless (is_create_env($env)) {
			print $OUT <<EOF;

  - name: ${alias}-cloud-config
    type: bosh-config
    source:
      target: $pipeline->{pipeline}{boshes}{$env}{url}
      client: $pipeline->{pipeline}{boshes}{$env}{username}
      client_secret: $pipeline->{pipeline}{boshes}{$env}{password}
      ca_cert: |
EOF
			for (split /\n/, $pipeline->{pipeline}{boshes}{$env}{ca_cert}) {
				print $OUT <<EOF;
         $_
EOF
			}
			print $OUT <<EOF;
      config: cloud

  - name: ${alias}-runtime-config
    type: bosh-config
    source:
      target: $pipeline->{pipeline}{boshes}{$env}{url}
      client: $pipeline->{pipeline}{boshes}{$env}{username}
      client_secret: $pipeline->{pipeline}{boshes}{$env}{password}
      ca_cert: |
EOF
			for (split /\n/, $pipeline->{pipeline}{boshes}{$env}{ca_cert}) {
				print $OUT <<EOF;
        $_
EOF
			}
			print $OUT <<EOF;
      config: runtime

EOF
		}
		if ($pipeline->{pipeline}{locker}{url}) {
			my $deployment_suffix = deployment_suffix;
			unless (is_create_env($env)) {
				my $bosh_lock = $env;
				if ($pipeline->{pipeline}{boshes}{$env}{url} && $pipeline->{pipeline}{boshes}{$env}{url} =~ m|https?://(.*)?:(.*)|) {
					my $addr = gethostbyname($1);
					$bosh_lock = inet_ntoa($addr) . ":" . $2;
				}

				# <alias>-stemcell-lock is used to not upload the same stemcell to the same bosh multiple
				# times - not necessary for create-env
				# <alias>-bosh-lock is used to prevent the parent bosh from upgrading while we deploy
				# - not necessary for create-env
				print $OUT <<EOF;
  - name: ${alias}-stemcell-lock
    type: locker
    source:
      locker_uri: (( grab pipeline.locker.url ))
      username: (( grab pipeline.locker.username ))
      password: (( grab pipeline.locker.password ))
      skip_ssl_validation: (( grab pipeline.locker.skip_ssl_validation ))
      ca_cert: (( grab pipeline.locker.ca_cert ))
      lock_name: ${bosh_lock}-stemcell-lock

  - name: ${alias}-bosh-lock
    type: locker
    source:
      locker_uri: (( grab pipeline.locker.url ))
      username: (( grab pipeline.locker.username ))
      password: (( grab pipeline.locker.password ))
      skip_ssl_validation: (( grab pipeline.locker.skip_ssl_validation ))
      ca_cert: (( grab pipeline.locker.ca_cert ))
      bosh_lock: $pipeline->{pipeline}{boshes}{$env}{url}
EOF
			}
			print $OUT <<EOF;
  - name: ${alias}-deployment-lock
    type: locker
    source:
      locker_uri: (( grab pipeline.locker.url ))
      username: (( grab pipeline.locker.username ))
      password: (( grab pipeline.locker.password ))
      skip_ssl_validation: (( grab pipeline.locker.skip_ssl_validation ))
      ca_cert: (( grab pipeline.locker.ca_cert ))
      lock_name:  ${env}-${deployment_suffix}

EOF
		}
	}
	# }}}
	# CONCOURSE: notification resource configuration {{{
	if ($pipeline->{pipeline}{slack}) {
		print $OUT <<'EOF';
  - name: slack
    type: slack-notification
    source:
      url: (( grab pipeline.slack.webhook ))

EOF
	}
	if ($pipeline->{pipeline}{hipchat}) {
		print $OUT <<'EOF';
  - name: hipchat
    type: hipchat-notification
    source:
      hipchat_server_url: (( grab pipeline.hipchat.url ))
      room_id:  (( grab pipeline.hipchat.room_id ))
      token:    (( grab pipeline.hipchat.token ))
EOF
	}
	if ($pipeline->{pipeline}{email}) {
		print $OUT <<'EOF';
  - name: build-email-changes-staged
    type: script
    source:
      filename: run
      body: |
        #!/bin/bash
        mkdir -p email
        rm -rf email/*
        echo "X-Concourse-Site-Env: ${CI_SITE_ENV}" >>email/header
        head -n1 out/notif > email/subject
        sed -e 's/\`\`\`//' out/notif > email/body
  - name: build-email-success
    .: (( inject resources.build-email-changes-staged ))
  - name: build-email-failure
    .: (( inject resources.build-email-changes-staged ))

  - name: email
    type: email
    source:
      to:   (( grab pipeline.email.to ))
      from: (( grab pipeline.email.from ))
      smtp:
        host:     (( grab pipeline.email.smtp.host ))
        port:     (( grab pipeline.email.smtp.port ))
        username: (( grab pipeline.email.smtp.username ))
        password: (( grab pipeline.email.smtp.password ))
EOF
	}
	# }}}
	# CONCOURSE: resource types {{{
	print $OUT <<'EOF';
resource_types:
  - name: script
    type: docker-image
    source:
      repository: cfcommunity/script-resource

  - name: email
    type: docker-image
    source:
      repository: pcfseceng/email-resource

  - name: slack-notification
    type: docker-image
    source:
      repository: cfcommunity/slack-notification-resource

  - name: hipchat-notification
    type: docker-image
    source:
      repository: cfcommunity/hipchat-notification-resource

  - name: bosh-config
    type: docker-image
    source:
      repository: cfcommunity/bosh-config-resource

  - name: locker
    type: docker-image
    source:
      repository: cfcommunity/locker-resource

EOF
	# }}}
	print $OUT <<EOF;
jobs:
EOF
	for my $env (sort @{$pipeline->{envs}}) {
		# CONCOURSE: env-specific job configuration {{{

		# YAML snippets, to make the print's less obnoxious {{{
		#
		# 1) do we tag the jobs so that they are constrained to a
		#   specific subset of concourse workers? ('tagged' directive)
		my $tag_yaml = $pipeline->{pipeline}{tagged} ? "tags: [$env]" : "";

		# 2) Are we auto-triggering this environment?
		my $trigger = $auto{$env} ? "true" : "false";

		# 3) what is our deployment suffix?
		my $deployment_suffix = deployment_suffix;

		# 4) what previous (triggering) job/env do we need to wait
		#    on for our cached configuration changes
		my $passed =$pipeline->{triggers}{$env} ? $pipeline->{triggers}{$env} : "";
		my $passed_alias = $passed ? "$pipeline->{aliases}{$passed}-$deployment_suffix" : "";

		# 5) Alias of environment for concourse readabilitys
		my $alias = $pipeline->{aliases}{$env};

		# 6) If we have a previous environment, generate input definition
		#    too look at our cache
		my $cache_yaml = "";
		if ($pipeline->{triggers}{$env}) {
			if ($trigger eq "true") {
				$cache_yaml = "- { get: $alias-cache, passed: [$passed_alias], trigger: true }";
			} else {
				$cache_yaml = "- { get: $alias-cache, passed: [notify-$alias-$deployment_suffix-changes], trigger: false }";
			}
		}
		my $notify_cache = $pipeline->{triggers}{$env} ?
			"- { get: $alias-cache, passed: [$passed_alias], trigger: true }" : "";

		# 7) If we don't auto-trigger, we should use passed as our notify resource
		#    otherwise, use the live value
        my $changes_yaml = $trigger eq "true" ?
			"- { get: $alias-changes, trigger: true }" :
			"- { get: $alias-changes, trigger: false, passed: [notify-$alias-$deployment_suffix-changes]}";

		# 8) Build notifications for non-automatic deployments that sense changes
		my $changes_staged_notification = gen_notifications($pipeline,
			"Changes are staged to be deployed to $env-$deployment_suffix, " .
			"please schedule + run a deploy via Concourse", "changes-staged");

		# 9) Build notifications for failed deployments
		my $deployment_failure_notification = gen_notifications($pipeline,
			"Concourse deployment to $env-$deployment_suffix failed", "failure");

		# 10) Build notifications for successful deployments
		my $deployment_success_notification = gen_notifications($pipeline,
			"Concourse successfully deployed $env-$deployment_suffix", "success");

		# 11) notifications for stemcell upload success
		my $stemcell_success_notification = gen_notifications($pipeline,
			"New stemcells have been uploaded to the $env BOSH", "success");
		# 12) notifications for stemcell upload failure
		my $stemcell_failure_notification = gen_notifications($pipeline,
			"Failed uploading new stemcells to the $env BOSH", "failure");

		# 13) directory to find the genesis binary in (use previous env cache if present, else local-changes
		my $genesis_bindir = $passed ? "$alias-cache" : "$alias-changes";

		# }}}

		if ($trigger eq "false" ) {
			# notify job for non-automatic deploys {{{
			print $OUT <<EOF;
  - name: notify-$alias-$deployment_suffix-changes
    public: true
    serial: true
    plan:
    - aggregate:
      - { get: $alias-changes, trigger: true }
EOF
			unless (is_create_env($env)) {
				print $OUT <<EOF;
      - { get: $alias-cloud-config, trigger: true }
      - { get: $alias-runtime-config, trigger: true }
EOF
			}
			print $OUT <<EOF;
      $notify_cache
EOF
			unless ($pipeline->{pipeline}{skip_upkeep}) {
				for (@{$pipeline->{pipeline}{boshes}{$env}{stemcells}}) {
					print $OUT <<EOF;
      - get: $_-stemcell
        trigger: true
        params: { tarball: true }
EOF
				}
			}
			print $OUT <<EOF;
    - $changes_staged_notification
EOF
		}
		# }}}
		print $OUT <<EOF;
  - name: $alias-$deployment_suffix
    public: true
    serial: true
    plan:
    - on_failure:
        $deployment_failure_notification
      on_success:
        $deployment_success_notification
EOF
		if ($pipeline->{pipeline}{locker}{url}) {
			print $OUT <<EOF;
      ensure:
        do:
EOF
			unless (is_create_env($env)) {
				# <alias>-bosh-lock is used to prevent the parent bosh from upgrading while we deploy
				# - not necessary for create-env
				print $OUT <<EOF;
        - put: ${alias}-bosh-lock
          params:
            lock_op: unlock
            key: dont-upgrade-bosh-on-me
            locked_by: ${alias}-${deployment_suffix}
EOF
			}
			print $OUT <<EOF;
        - put: ${alias}-deployment-lock
          params:
            lock_op: unlock
            key: i-need-to-deploy-myself
            locked_by: ${alias}-${deployment_suffix}
EOF
		}
		print $OUT <<EOF;
      do:
EOF
		if ($pipeline->{pipeline}{locker}{url}) {
			unless (is_create_env($env)) {
				# <alias>-bosh-lock is used to prevent the parent bosh from upgrading while we deploy
				# - not necessary for create-env
				print $OUT <<EOF;
      - put: ${alias}-bosh-lock
        params:
          lock_op: lock
          key: dont-upgrade-bosh-on-me
          locked_by: ${alias}-${deployment_suffix}
EOF
			}
			print $OUT <<EOF;
      - put: ${alias}-deployment-lock
        params:
          lock_op: lock
          key: i-need-to-deploy-myself
          locked_by: ${alias}-${deployment_suffix}
EOF
		}
		print $OUT <<EOF;
      - aggregate:
EOF
		# only add cloud/runtime config on true-triggers, otherwise it goes in notifications
		# also make sure that we are not deploying with create-env (no cloud/runtime config for that scenario)
		if (! is_create_env($env) && $trigger eq "true") {
			print $OUT <<EOF;
        - { get: $alias-cloud-config, trigger: true }
        - { get: $alias-runtime-config, trigger: true }
EOF
		}
		unless ($pipeline->{pipeline}{skip_upkeep}) {
			for (@{$pipeline->{pipeline}{boshes}{$env}{stemcells}}) {
				print $OUT <<EOF;
        - get: $_-stemcell
          trigger: $trigger
          params: { tarball: true }
EOF
			}
		}
		print $OUT <<EOF;
        # genesis itself handles the propagation of files from successful environment
        # to the next. anything triggering env-changes should be considered to have passed
        # the previous environment, if in cached, and if not, should be triggered
        $changes_yaml
        $cache_yaml
EOF
		# Update stemcells unless we are create-env based or skip_upkeep requested {{{
		unless (is_create_env($env) || $pipeline->{pipeline}{skip_upkeep}) {
			if ($pipeline->{pipeline}{locker}{url}) {
				print $OUT <<EOF;
      - put: ${alias}-stemcell-lock
        params:
          lock_op: lock
          key: ${alias}-${deployment_suffix}
EOF
			}
			print $OUT <<EOF;
      - task: upload-stemcells
EOF
			if ($pipeline->{pipeline}{locker}{url}) {
				print $OUT <<EOF;
        ensure:
          put: ${alias}-stemcell-lock
          params:
            lock_op: unlock
            key: ${alias}-${deployment_suffix}
EOF
			}
			print $OUT <<EOF;
        config:
          inputs:
            - name: $genesis_bindir
EOF
			for (@{$pipeline->{pipeline}{boshes}{$env}{stemcells}}) {
				print $OUT <<EOF;
            - name: $_-stemcell
              path: stemcells/$pipeline->{pipeline}{stemcells}{$_}
EOF
			}
			print $OUT <<EOF;
          outputs:
            - name: out
          platform: linux
          image_resource:
            type: docker-image
            source:
              repository: starkandwayne/concourse
          run:
            path: .genesis/bin/genesis
            args: [ ci-stemcells ]
            dir: $genesis_bindir
          params:
            STEMCELLS:            ../stemcells
            BOSH_ENVIRONMENT:     $pipeline->{pipeline}{boshes}{$env}{url}
            BOSH_NON_INTERACTIVE: true
            BOSH_CA_CERT: |
EOF
			for (split /\n/, $pipeline->{pipeline}{boshes}{$env}{ca_cert}) {
				print $OUT <<EOF;
              $_
EOF
			}
			print $OUT <<EOF;
            BOSH_CLIENT:        $pipeline->{pipeline}{boshes}{$env}{username}
            BOSH_CLIENT_SECRET: $pipeline->{pipeline}{boshes}{$env}{password}

EOF
			print $OUT <<EOF if $pipeline->{pipeline}{debug};
            DEBUG:              $pipeline->{pipeline}{debug}
EOF
		}
		#   }}}
		print $OUT <<EOF;
      - task: bosh-deploy
        $tag_yaml
        config:
          platform: linux
          image_resource:
            type: docker-image
            source:
              repository: $pipeline->{pipeline}{task}{image}
              tag:        $pipeline->{pipeline}{task}{version}
          params:
            CURRENT_ENV:          $env
            PREVIOUS_ENV:         $passed
            CACHE_DIR:            $alias-cache
            GIT_BRANCH:           (( grab pipeline.git.branch ))
            GIT_PRIVATE_KEY:      (( grab pipeline.git.private_key ))
            VAULT_ROLE_ID:        $pipeline->{pipeline}{vault}{role}
            VAULT_SECRET_ID:      $pipeline->{pipeline}{vault}{secret}
            VAULT_ADDR:           $pipeline->{pipeline}{vault}{url}
            VAULT_SKIP_VERIFY:    ${\(!$pipeline->{pipeline}{vault}{verify})}
            BOSH_NON_INTERACTIVE: true
EOF
		# don't supply bosh creds if we're create-env, because no one to talk to
		unless (is_create_env($env)) {
			print $OUT <<EOF;
            BOSH_ENVIRONMENT:     $pipeline->{pipeline}{boshes}{$env}{url}
            BOSH_CA_CERT: |
EOF
			for (split /\n/, $pipeline->{pipeline}{boshes}{$env}{ca_cert}) {
				print $OUT <<EOF;
              $_
EOF
			}
			print $OUT <<EOF;
            BOSH_CLIENT:        $pipeline->{pipeline}{boshes}{$env}{username}
            BOSH_CLIENT_SECRET: $pipeline->{pipeline}{boshes}{$env}{password}
EOF
		}
		print $OUT <<EOF if $pipeline->{pipeline}{debug};
            DEBUG:              $pipeline->{pipeline}{debug}
EOF
		print $OUT <<EOF;
            WORKING_DIR:        $alias-changes # work out of latest changes for this environment
            OUT_DIR:            out/git


          run:
            # run from inside the environment changes to get latest cache + regular data
            # but use the executable from genesis
            path: $genesis_bindir/.genesis/bin/genesis
            args: [ci-pipeline-deploy]
          inputs:
            - { name: $alias-changes } # deploy from latest changes
EOF
		print $OUT <<EOF if $passed;
            - { name: $alias-cache }
EOF
		print $OUT <<EOF;
          outputs:
            - { name: out }

        # push the deployment changes up to git, even if the deploy fails, to save
        # files for create-env + reflect "live" state
        ensure:
          put: git
          params:
            repository: out/git
EOF

		# CONCOURSE: run optional errands as tasks - non-create-env only (otherwise no bosh to run the errand) {{{
		unless (is_create_env($env)) {
			for my $errand_name (@{$pipeline->{pipeline}{errands}}) {
				print $OUT <<EOF;
        # run errands against the deployment
      - task: $errand_name-errand
        $tag_yaml
        config:
          platform: linux
          image_resource:
            type: docker-image
            source:
              repository: $pipeline->{pipeline}{task}{image}
              tag:        $pipeline->{pipeline}{task}{version}
          params:
            CURRENT_ENV:        $env
            ERRAND_NAME:        $errand_name

            BOSH_ENVIRONMENT:   $pipeline->{pipeline}{boshes}{$env}{url}
            BOSH_CA_CERT: |
EOF
			for (split /\n/, $pipeline->{pipeline}{boshes}{$env}{ca_cert}) {
				print $OUT <<EOF;
              $_
EOF
			}
			print $OUT <<EOF;
            BOSH_CLIENT:        $pipeline->{pipeline}{boshes}{$env}{username}
            BOSH_CLIENT:        $pipeline->{pipeline}{boshes}{$env}{username}
            BOSH_CLIENT_SECRET: $pipeline->{pipeline}{boshes}{$env}{password}
EOF
			print $OUT <<EOF if $pipeline->{pipeline}{debug};
            DEBUG:              $pipeline->{pipeline}{debug}
EOF
			print $OUT <<EOF;

          run:
            path: ../../$genesis_bindir/.genesis/bin/genesis
            dir:  out/git
            args: [ci-pipeline-run-errand]
          inputs:
            - name: out
            - name: $genesis_bindir
EOF
			}
		}
		# }}}
		print $OUT <<EOF;
      - task: generate-cache
        $tag_yaml
        config:
          inputs:
          - { name: out }
          - { name: $genesis_bindir }
          outputs:
          - { name: cache-out }
          run:
            path: $genesis_bindir/.genesis/bin/genesis
            args: [ci-generate-cache]
          params:
            CURRENT_ENV:     $env
            WORKING_DIR:     out/git
            OUT_DIR:         cache-out/git
            GIT_BRANCH:      (( grab pipeline.git.branch ))
            GIT_PRIVATE_KEY: (( grab pipeline.git.private_key ))
EOF

		print $OUT <<EOF if $pipeline->{pipeline}{debug};
            DEBUG:       $pipeline->{pipeline}{debug}
EOF
		print $OUT <<EOF;
          platform: linux
          image_resource:
            type: docker-image
            source:
              repository: $pipeline->{pipeline}{task}{image}
              tag:        $pipeline->{pipeline}{task}{version}
      - put: git
        params:
          repository: cache-out/git
EOF

		for my $push_env (@{$pipeline->{will_trigger}{$env}}) {
			print $OUT <<EOF;
      - put: $pipeline->{aliases}{$push_env}-cache
        params:
          repository: cache-out/git
EOF
		}
	# }}}
	}
	close $OUT;

	return spruce_merge({ prune => [qw(meta pipeline)] },
		"$dir/guts.yml", $pipeline->{file});
}

sub generate_pipeline_graphviz_source {
	my ($pipeline) = @_;
	my $out = "";
	open my $fh, ">", \$out;
	print $fh "digraph {\n";
	print $fh "  rankdir = LR; node [shape=none]; edge [color=\"#777777\",fontcolor=\"red\"];\n";

	my %auto = map { $_ => 1 } @{$pipeline->{auto}};
	for my $b (keys %{$pipeline->{triggers}}) {
		my $a = $pipeline->{triggers}{$b};
		(my $b1 = $b) =~ s/-/_/g;
		(my $a1 = $a) =~ s/-/_/g;
		print $fh "  $a1 [label=\"$a\"];\n";
		print $fh "  $b1 [label=\"$b\"];\n";
		if ($auto{$b}) {
			print $fh "  $a1 -> $b1;\n";
		} else {
			print $fh "  $a1 -> $b1 [label=\"manual\"];\n";
		}
	}


	print $fh "}\n";
	close $fh;
	return $out;
}

sub pipeline_tree {
	my ($prefix, $env, $trees) = @_;
	#
	# sandbox
	#  |--> preprod
	#  |     |--> prod
	#  |     |--> prod-2
	#  |     `--> some-prod
	#  |
	#  `--> other-preprod
	#        `--> other-prod
	#

	print "$env\n";
	my $n = @{$trees->{$env} || []};
	for my $kid (sort @{$trees->{$env} || []}) {
		$n--;
		if ($n) {
			print "$prefix  |--> ";
			pipeline_tree("$prefix  |   ", $kid, $trees);
		} else {
			print "$prefix  `--> ";
			pipeline_tree("$prefix      ", $kid, $trees);
		}
	}
}

sub generate_pipeline_human_description {
	my ($pipeline) = @_;

	my %auto = map { $_ => 1 } @{$pipeline->{auto}};

	my %trees;
	my %envs = map { $_ => 1 } @{$pipeline->{envs}};
	for my $b (keys %{$pipeline->{triggers}}) {
		my $a = $pipeline->{triggers}{$b};
		push @{$trees{$a}}, $b;
		delete $envs{$b};
	}
	for (sort keys %envs) {
		pipeline_tree("", $_, \%trees);
		print "\n";
	}
}

sub semver {
	my ($name, $v) = @_;
	if ($v =~  m/^(\d+)(?:\.(\d+)(?:\.(\d+)(?:[.-]rc[.-]?(\d+))?)?)?$/) {
		return ($1, $2 || 0, $3 || 0, $4 || 0);
	}
	die "Unrecognized version string '$v' for $name\n";
}

sub new_enough {
	my ($name, $v, $min) = @_;
	my @v = semver($name, $v);
	my @min = semver($name, $min);
	while (@v) {
		return 1 if $v[0] > $min[0];
		return 0 if $v[0] < $min[0];
		shift @v;
		shift @min;
	}
	return 1;
}

sub check_prereqs {

	my %conditions = @_;

	my $SPRUCE_MIN_VERSION = "1.12.0";
	my $SAFE_MIN_VERSION   = "0.1.8";
	my $VAULT_MIN_VERSION  = "0.6.0";
	my $GIT_MIN_VERSION    = "1.8.0";
	my $BOSH2_MIN_VERSION  = "2.0.1";

	my @errors;
	my $version;

	# check that we has a spruce
	$version = qx(spruce -v 2>/dev/null);
	if (!$version || $version =~ s/not found//) {
		push @errors, "Missing `spruce' - install Spruce from #B{https://github.com/geofffranks/spruce/releases}";
	} else {
		unless(envset('GENESIS_DEV_MODE') && $version =~ /development/) {
			chomp($version); $version =~ s/.*version\s+(\S+).*/$1/i;
			if (!new_enough("spruce", $version, $SPRUCE_MIN_VERSION)) {
				push @errors, "Spruce v${version} is installed, but Genesis requires #R{at least $SPRUCE_MIN_VERSION} - upgrade your Spruce, via #B{https://github.com/geofffranks/spruce/releases}";
			}
		}
	}

	# check that we has a safe
	$version = qx(safe -v 2>&1 >/dev/null);
	if (!$version || $version =~ s/not found//) {
		push @errors, "Missing `safe' - install Safe from #B{https://github.com/starkandwayne/safe/releases}";
	} else {
		unless (envset('GENESIS_DEV_MODE') && $version =~ /development build/) {
			chomp($version); $version =~ s/^safe v(\S+)/$1/i;
			if (!new_enough("safe", $version, $SAFE_MIN_VERSION)) {
				push @errors, "Safe v${version} is installed, but Genesis requires #R{at least $SAFE_MIN_VERSION} - upgrade your Safe, via #B{https://github.com/starkandwayne/safe/releases}";
			}
		}
	}

	# check that we has a vault
	$version = qx(vault -v 2>/dev/null);
	if (!$version) {
		push @errors, "Missing `vault' - install Vault from #B{https://www.vaultproject.io/downloads.html}";
	} else {
		chomp($version); $version =~ s/^vault v(\S+).*/$1/i;
		if (!new_enough("vault", $version, $VAULT_MIN_VERSION)) {
			push @errors, "Vault v${version} is installed, but Genesis requires #R{at least $VAULT_MIN_VERSION} - upgrade your Vault, via #B{https://www.vaultproject.io/downloads.html}";
		}
	}

	# check that we has a bosh (v2)
	detect_bosh_version($BOSH2_MIN_VERSION);

	# check that we has a git
	$version = qx(git --version 2>/dev/null);
	if (!$version || $version =~ s/not found//) {
		push @errors, "Missing `git' - install git via your platform package manager";
	} else {
		chomp($version); $version =~ s/.*version\s+(\S+).*/$1/i;
		if (!new_enough("git", $version, $GIT_MIN_VERSION)) {
			push @errors, "Git v${version} is installed, but Genesis requires #R{at least $GIT_MIN_VERSION}";
		}
	}

	unless ($conditions{no_repo_needed}) {
		push @errors, "This command needs to be run from a Genesis v2 deployment repo, or specify one using -C <dir> option"
			unless in_repo_dir;
	}

	if (@errors) {
		error "#R{GENESIS PRE-REQUISITES CHECKS FAILED!!}";
		error;
		error "Encountered the following errors:";
		error "  - $_" for @errors;
		exit 2;
	}
}

sub extract_kit_name_and_version {
	my ($combined) = @_;
	return ($1, $2) if $combined =~ m{(.*)/(.*)};
	return $combined, "latest";
}

sub kit_release_url {
	my ($name, $version) = @_;

	my $creds = "";
	if ($ENV{GITHUB_USER} && $ENV{GITHUB_AUTH_TOKEN}) {
		$creds = "$ENV{GITHUB_USER}:$ENV{GITHUB_AUTH_TOKEN}";
	}
	my ($code, $msg, $data) = curl "GET", "https://api.github.com/repos/genesis-community/$name-genesis-kit/releases", undef, undef, 0, $creds;
	if ($code == 404) {
		die "Could not find Genesis Kit $name on Github; does https://github.com/genesis-community/$name-genesis-kit/releases exist?\n";
	}
	if ($code != 200) {
		die "Could not find Genesis Kit $name release information; Github returned a ".$msg."\n";
	}

	my $releases;
	eval { $releases = decode_json($data); 1 }
		or die "Failed to read releases information from Github: $@\n";

	if (!@$releases) {
		die "No released versions of Genesis Kit $name found at https://github.com/genesis-community/$name-genesis-kit/releases.\n";
	}

	for (map { @{$_->{assets} || []} } @$releases) {
		if ($version eq 'latest') {
			next unless $_->{name} =~ m/^\Q$name\E-(.*)\.(tar\.gz|tgz)$/;
			$version = $1;
		} else {
			next unless $_->{name} eq "$name-$version.tar.gz"
			         or $_->{name} eq "$name-$version.tgz";
		}
		return ($_->{browser_download_url}, $version);
	}

	die "$name/$version tarball asset not found on Github.  Oops.\n";
}

sub kit_file {
	my ($kit, $version, $relpath, $required) = @_;

	if (!$kit || $kit eq "dev") {
		-d "dev/"                       or die "dev/ kit directory not found. Please contact your kit author for a fix.\n";
		!$required || -f "dev/$relpath" or die "dev/$relpath not found. Please contact your kit author for a fix.\n";
		return "dev/$relpath";
	}
	-f ".genesis/kits/$kit-$version.tar.gz"
		or die "Kit $kit/$version not found in .genesis/kits!\n";

	my $tmp = workdir();
	qx(tar -C $tmp -xzf .genesis/kits/$kit-$version.tar.gz $kit-$version/$relpath 2>/dev/null);
	!$required || -f "$tmp/$kit-$version/$relpath"
		or die "$relpath not found in $kit-$version kit. Please contact your kit author for a fix.\n";
	return "$tmp/$kit-$version/$relpath";
}

sub download_kit_tarball
{
	my ($name, $want) = @_;

	if ($want eq 'latest') {
		explain "Downloading Genesis kit #M{$name} (#Y{latest} version)\n";
	} else {
		explain "Downloading Genesis kit #M{$name}, version #C{$want}\n";
	}
	my ($url, $version) = kit_release_url($name, $want);
	mkdir_or_fail ".genesis";
	mkdir_or_fail ".genesis/kits";
	open my $kit, ">", ".genesis/kits/$name-$version.tar.gz"
		or die "Failed to open .genesis/kits/$name-$version.tar.gz for writing: $!\n";
	my ($code, $msg, $data) = curl "GET", $url;
	if ($code != 200) {
		die "Failed to download $name/$version from $url: Github returned an HTTP ".$msg."\n";
	}
	print $kit $data;
	close $kit;
	debug "downloaded kit #M{$name}/#C{$version}\n";
}
sub validate_kit_files {

	my $dir = shift;
	my @errors = ();
	if (-d $dir) {
		for (qw(base subkits hooks)) {
			push @errors, "$dir/$_ directory does not exist" unless -d "$dir/$_";
		}
		for (qw(kit.yml README.md base/params.yml)) {
			push @errors, "$dir/$_ does not exist" unless -f "$dir/$_";
		}
		for (glob "$dir/subkits/*") {
			push @errors, "$_/params.yml does not exist" unless -f "$_/params.yml";
		}
	} else {
		push @errors, "$dir does not exist";
	}
	die("$dir does not look like a valid kit directory:\n".
		"  * ".join("\n  * ", @errors).
		"\n\nCannot continue.\n")
		if @errors;
}

sub validate_kit_metadata {
	my ($kit, $version, $meta,$is_author) = @_;
	$kit ||= "dev";
	$version = "latest" unless defined $version;
	my @errors;

	# validate params
	for my $subkit (sort keys %{$meta->{params}}) {
		my $i = 0;
		debug ("Validating params for subkit '$subkit' (#$i)");
		if (ref($meta->{params}{$subkit}) ne "ARRAY") {
			push @errors, "$subkit subkit parameters not a list (found ".(ref($meta->{params}{$subkit}) || "a string").")";
		} else {
			for my $param (@{$meta->{params}{$subkit}}) {
				my $parameter = "params.$subkit\[$i\]";
				my (@extras, @bad);
				for my $key (sort keys %$param) {
					push @extras, $key if $key !~ m/^(params?|ask|vault|description|example|type)$/;
				}
				if (defined($param->{ask})) {
					my $type = exists($param->{type}) ? $param->{type} : "string";
					if (defined($param->{validate})) {
						if ($type =~ m/^(string|list)$/) {
							@extras = grep {$_ !~ /^(validate|err_msg)$/ } @extras;
							if ($param->{validate} !~ m/^\/.*\/i?m?s?$/     && # regex validation
								$param->{validate} !~ m/^((^|,)[^,]+){2,}$/ && # comma-separated list
								$param->{validate} !~ m/^(vault_path)$/     ){ # key-words
								push @errors, "$parameter has an invalid validation formula";
							}
						}
					}
					if ( $type =~ m/^(string|block|multi-?line)$/) {
						push @bad, grep {$_ !~ m/^(label|default)$/} @extras;
					} elsif ($type eq 'boolean') {
						push @bad, grep {$_ !~ m/^(label|default)$/} @extras;
						push @errors, "$parameter has invalid default value '$param->{default}'"
						  if (defined($param->{default}) && $param->{default} !~ /^(1|0|y(es)?|no?|true|false)$/i);
					} elsif ($type =~ m/^((block|multi-?line)-)?list$/) {
						push @bad, grep {$_ !~ m/^(label|(max|min)_count)$/} @extras;
					} else {
						push @errors, "$parameter has unsupported type '$type'";
						@bad = @extras;
					}
				} else {
					@bad = @extras;
				}
				push @errors, "$parameter has an invalid attribute: '$_'" foreach @bad;
				push @errors, "$parameter does not specify 'vault', 'param', or 'params'"
					unless ($param->{param} || $param->{params} || $param->{vault});
				push @errors, "$parameter specifies both 'param' and 'params'"
					if ($param->{param} && $param->{params});
				push @errors, "$parameter specifies both 'param' and 'vault'"
					if ($param->{param} && $param->{vault});
				push @errors, "$parameter specifies both 'params' and 'vault'"
					if ($param->{vault} && $param->{params});
				push @errors, "$parameter specifies 'param', but it is not a string"
					if $param->{param} && ref $param->{param};
				push @errors, "$parameter specifies 'params', but it is not an array"
					if $param->{params} && ref $param->{params} ne "ARRAY";
				push @errors, "$parameter specifies both 'params' and 'ask'"
					if $param->{params} && $param->{ask};
				push @errors, "$parameter does not have a 'description'"
					if ! $param->{description};
				push @errors, "$parameter specifies 'ask', but does not have a corresponding 'vault' or 'param'"
					if ($param->{ask} && ! $param->{vault} && ! $param->{param});
				push @errors, "$parameter specifies 'vault' but does not have a corresponding 'ask'"
					if $param->{vault} && ! $param->{ask};

				$i++;
			}
		}
	}

	if (@errors) {
		print STDERR "The following errors have been encountered validating the $kit/$version kit:\n";
		for my $err (@errors) {
			print STDERR " - $err\n";
		}
		die ($is_author ? "Cannot continue.\n" : "Please contact your kit author for a fix.\n");
	}
}

# read the metadata for the given kit (and version)
# if no kit/version is given, assume 'dev'
sub read_kit_metadata {
	my ($kit, $version) = @_;
	my $metadata = LoadFile(kit_file($kit, $version, "kit.yml", 1));
	validate_kit_metadata($kit, $version, $metadata);
	return $metadata;
}

sub latest_kit_name_and_version {
	# use dev/, if we have it
	return (undef, undef) if -d "dev";

	# use latest available:
	my ($kit, @versions);
	for (glob(".genesis/kits/*.tar.gz")) {
		next unless m{^\.genesis/kits/(.*?)-(\d+(\.\d+(\.\d+([.-]rc[.-]?\d+)?)?)?).tar.gz$};
		my ($n, $v) = ($1, $2);
		if ($kit && $kit ne $n) {
			die "Found multiple different kits!\n";
		}
		$kit = $n;

		push @versions, [$v, semver($kit, $v)];
	}
	@versions > 0
		or die "No kits have been downloaded for use in this set of deployment environments.\nPlease download a kit via `genesis download kit-name[/version]`\n";
	my @sorted = reverse sort { $a->[1] <=> $b->[1] } @versions;
	return ($kit, $sorted[0][0]);
}

sub kit_name_and_version_for {
	my ($env) = @_;
	my $name = get_key($env, 'kit.name');
	my $vers = get_key($env, 'kit.version');
	return (undef, undef) if $name && $name eq 'dev';
	return ($name, $vers) if $name && $vers;
	return latest_kit_name_and_version();
}

sub check_kit_prereqs {
	my ($kit, $version) = @_;
	my $script = kit_file($kit, $version, "prereqs", 0);
	return unless -e $script;
	-x $script or die "Prereqs script $script was found, but is not executable...\n";
	qx(./dev/prereqs);
	$? == 0 or die "Some prerequisites for this Genesis Kit have not been met.\n";
}

sub prompt_for_subkits_alternates {
	my ($prompt) = @_;
	my $attempt;
	print "\n";

reprompt:
	$attempt = 0;
	print "$prompt->{prompt}\n\n";

	my $n = 0;
	for my $choice (@{ $prompt->{choices} }) {
		$n++;
		if ($choice->{default}) {
			print "  *${n}) $choice->{label} (default)\n";
		} else {
			print "   ${n}) $choice->{label}\n";
		}
	}
	print "\n";

again:
	$attempt++;
	print " choice? [1-$n]: ";
	my $answer = <STDIN>; defined $answer or die "unexpected EOF on standard input...\n";
	$answer =~ s/^\s+|\s+$//g;
	if ($answer && $answer >= 1 && $answer <= $n) {
		return $prompt->{choices}[$answer - 1]{subkit};
	}
	if ($answer) {
		print "'$answer' is an invalid choice...\n";
	}
	if ($attempt < 3) {
		goto again;
	}
	print "You can <CTRL-C> to exit setup...\n";
	goto reprompt;
}

sub resolve_params_ref {
	my ($key,$references) = @_;
	die("\$\{$key\} referenced but not found -- perhaps it hasn't been defined yet.  Contact your Kit author for a bugfix.\n")
		unless exists($references->{$key});
	return $references->{$key};
}

sub process_kit_params {
	my %opts = @_;
	my @answers;
	my $resolveable_params = {
		"params.vault_prefix" => $opts{vault_prefix},
		"params.env" => $opts{env}
	};
	for my $subkit ("base", @{$opts{subkits}}) {
		next unless defined $opts{params}{$subkit} && @{$opts{params}{$subkit}};
		my $kit_params_file = $subkit eq "base" ? "base/params.yml" : "subkits/$subkit/params.yml";
		my $defaults = LoadFile(kit_file($opts{kit}, $opts{version}, $kit_params_file, 1));
		for my $q (@{$opts{params}{$subkit}}) {
			my $answer;
			my $vault_path;
			next if ($q->{vault} && ! $opts{should_vault});
			# Expand any values from default and examples for vault prefix
			foreach (qw(description ask default example validate err_msg)) {
				$q->{$_} =~ s/\$\{([^}]*)\}/resolve_params_ref($1,$resolveable_params)/ge if defined($q->{$_});
			}
			if (defined($q->{validate}) && $q->{validate} eq 'vault_path') {
				if (defined($q->{default})) {
					while ($q->{default} =~ s#/[^/]+/\.\./#/#) {};
				}
				if (defined($q->{example})) {
					while ($q->{example} =~ s#/[^/]+/\.\./#/#) {};
				}
			}
			if ($q->{ask}) {
				$q->{type} ||= "string";
				print "\n";
				if ($q->{param}) {
					print csprintf("#y{Required parameter:} #W{$q->{param}}\n\n");
				} else {
					$vault_path = "secret/$opts{vault_prefix}/$q->{vault}";
					print csprintf("#y{Secret data required} -- will be stored in Vault under #W{$vault_path}\n\n");
				}
				print "$q->{description}\n";
				print "(e.g. $q->{example})\n\n" if defined $q->{example};
				if ($q->{param}) {
					my $type = $q->{type};
					if (defined($q->{validate}) && $q->{validate} eq "vault_path" && ! $opts{should_vault}) {
						print csprintf("#y{Warning:} Cannot validate vault path when --no-secrets option specified\n");
						$q->{validate}=undef;
					}
					if ($type eq 'boolean') {
						$answer = prompt_for_boolean($q->{ask},$q->{default});
					} elsif ($type eq 'string') {
						$answer = prompt_for_line($q->{ask},$q->{label},$q->{default},$q->{validate},$q->{err_msg});
					} elsif ($type =~ m/^(block|multi-?line)$/) {
						$answer = prompt_for_block($q->{ask},$q->{label},$q->{default});
					} elsif ($type eq 'list') {
						$answer = prompt_for_list('line',$q->{ask},$q->{label},$q->{min_count},$q->{max_count},$q->{validate},$q->{err_msg});
					} elsif ($type =~ m/^(block|multi-?line)-list$/) {
						$answer = prompt_for_list('block',$q->{ask},$q->{label},$q->{min_count},$q->{max_count});
					} else {
						die "Unsupported type '$type' for parameter '$q->{param}'. Please contact your kit author for a fix.\n";
					}
					print "\n";
				} else {
					my ($path, $key) = split /:/, $vault_path;
					if ($q->{type} =~ /^(boolean|string)$/) {
						system "safe", "prompt", $q->{ask}, "--", "set", $path, $key;
						die "Failed to save data to $vault_path in Vault\n" if ($? >> 8);
					} elsif ($q->{type} eq "multi-line") {
						$answer = prompt_for_block($q->{ask});
						my $tmpdir = workdir;
						open my $fh, ">", "$tmpdir/param" or die "Could not write to $tmpdir/param: $!\n";
						print $fh $answer;
						close $fh;
						my $err = qx(safe set "$path" "$key\@$tmpdir/param" 2>&1);
						die "$err\n\nFailed to save data to $vault_path in Vault\n" if ($? >> 8);
					} else {
						die "Unsupported parameter type '$q->{type}' for $q->{vault}. Please contact your kit author for a fix.\n";
					}
					print "\n";
					next;
				}
			}
			my @values;
			my $is_default = 0;
			if (! $q->{ask}) {
				$is_default = 1;
				if (defined $q->{param}) {
					$q->{params} = [$q->{param}];
				}
				for my $p (@{$q->{params}}) {
					# Should we throw an error here if the default value is
					# a spruce operator like (( param ))?
					push @values, { $p => $defaults->{params}{$p} };
					$resolveable_params->{"params.$p"} = $defaults->{params}{$p};
				}
			} else {
				push @values, { $q->{param} => $answer };
				$resolveable_params->{"params.$q->{param}"} = $answer;
			}

			push @answers, {
				comment => $q->{description},
				example => $q->{example},
				values  => \@values,
				default => $is_default,
			};
		}
	}
	return \@answers;
}

sub prompt_for_subkits_optional {
	my ($prompt) = @_;
	my $attempt = 0;
	print "\n";

again:
	$attempt++;
	print "$prompt->{prompt}\n";
	print $prompt->{default} ? "[Y/n]: " : "[y/n]: ";
	my $answer = <STDIN>; defined $answer or die "unexpected EOF on standard input...\n";
	$answer =~ s/^\s+|\s+$//g;

	return $prompt->{subkit} if !$answer && $prompt->{default};
	return $prompt->{subkit} if $answer =~ m{(y|yes)}i;
	return undef             if $answer =~ m{(n|no)}i;

	if ($answer) {
		print "'$answer' is an invalid choice; try 'yes' or 'no'...\n";
	}
	if ($attempt % 3 == 0) {
		print "You can <CTRL-C> to exit setup...\n";
	}
	goto again;
}

sub prompt_for_subkits {
	my @subkits;
	for my $prompt (@{$_[0]}) {
		my $subkit;

		if (exists $prompt->{choices}) {
			$subkit = prompt_for_subkits_alternates($prompt);
		} else {
			$subkit = prompt_for_subkits_optional($prompt);
		}

		push @subkits, $subkit if $subkit;
	}

	return @subkits;
}

sub active_credentials {
	my ($meta, $subkits) = @_;

	my $active = {};
	for my $sub (('base', @$subkits)) {
		next unless $meta->{credentials}{$sub};
		for my $path (keys %{ $meta->{credentials}{$sub} }) {
			if (exists $active->{$path} && ref $meta->{credentials}{$sub}{$path}) {
				for my $k (keys %{ $meta->{credentials}{$sub}{$path} }) {
					$active->{$path}{$k} = $meta->{credentials}{$sub}{$path}{$k};
				}
			} else {
				$active->{$path} = $meta->{credentials}{$sub}{$path};
			}
		}
	}
	return $active;
}

sub active_certificates {
	my ($meta, $subkits) = @_;

	my $active = {};
	for my $sub (('base', @$subkits)) {
		next unless $meta->{certificates}{$sub};
		for my $path (keys %{ $meta->{certificates}{$sub} }) {
			if (exists $active->{$path} && ref $meta->{certificates}{$sub}{path}) {
				for my $k (keys %{ $meta->{certificates}{$sub}{$path} }) {
					$active->{$path}{$k} = $meta->{certificates}{$sub}{$path}{$k};
				}
			} else {
				$active->{$path} = $meta->{certificates}{$sub}{$path};
			}
		}
	}
	return $active;
}

sub target_vault {
	my ($target) = @_;
	if ($target) {
		system(qw(safe target), $target) == 0 or exit 1;
	} else {
		system(qw(safe target -i)) == 0 or exit 1;
	}
}
# generate (and optionally rotate) credentials.
#
## just rotate credentials
# vaultify_secrets $kit_metadata,
#                  target       => "my-vault",
#                  env          => "us-east-sandbox",
#                  prefix       => "us/east/sandbox",
#                  scope        => 'rotate'; # or scope => '' or undef
#
## generate all credentials (including 'fixed' creds)
# vaultify_secrets $kit_metadata,
#                  target       => "my-vault",
#                  env          => "us-east-sandbox",
#                  prefix       => "us/east/sandbox",
#                  scope        => 'force';
#
## generate only missing credentials
# vaultify_secrets $kit_metadata,
#                  target       => "my-vault",
#                  env          => "us-east-sandbox",
#                  prefix       => "us/east/sandbox",
#                  scope        => 'add';
#
sub vaultify_secrets {
	my ($meta, %options) = @_;
	$options{env} or die "vaultify_secrets() was not given an 'env' option.\n";

	my $creds = active_credentials($meta, $options{subkits} || {});
	if (%$creds) {
		explain " - auto-generating credentials (in secret/$options{prefix})...\n";
		for (safe_commands $creds, %options) {
			system('safe', @$_);
			die "Failure autogenerating credentials.\n" if ($? >> 8);
		}
	} else {
		explain " - no credentials need to be generated.\n";
	}

	my $certs = active_certificates($meta, $options{subkits} || {});
	if (%$certs) {
		explain " - auto-generating certificates (in secret/$options{prefix})...\n";
		for (cert_commands $certs, %options) {
			system('safe', @$_);
			die "Failure autogenerating certificates.\n" if ($? != 0);
		}
	} else {
		explain " - no certificates need to be generated.\n";
	}
}

sub check_secrets {
	my ($meta, %options) = @_;
	$options{env} or die "check_secrets() was not given an 'env' option.\n";

	my @missing = ();
	for (safe_commands(active_credentials($meta, $options{subkits}||{}),%options)) {
		push @missing, check_secret($_, %options);
	}
	for (cert_commands(active_certificates($meta, $options{subkits}||{}),%options)) {
		push @missing, check_secret($_, %options);
	}
	if (@missing) {
		my $suf = scalar(@missing) == 1 ? '' : 's';
		printf "Missing %d credential%s or certificate%s:\n  * %s\n",
			scalar(@missing), $suf, $suf,
			join ("\n  * ", map {join " ", @$_} @missing);
		return 1;
	} else {
		print "All credentials and certificates present.\n";
		return 0;
	}
}

# build a columnar display of tabular data,
# tablify($headers, [$row1,$row2,...])
sub tablify {
	my ($headers_ref, $rows_ref) = @_;
	my @headers = @{$headers_ref};
	my @rows    = @{$rows_ref};
	my @widths  = map { length $_ } @headers;

	for my $row (@rows) {
		next unless $row;
		for (my $i = 0; $i < @$row; $i++) {
			my $l = length($row->[$i] || '');
			$widths[$i] = $l unless defined $widths[$i] and $widths[$i] > $l;
		}
	}
	@widths = map { $_ + 4 } @widths;

	for (my $i = 0; $i < @headers; $i++) {
		printf("%-*s", $widths[$i], $headers[$i]);
	}
	printf("\n");

	for (my $i = 0; $i < @headers; $i++) {
		printf("%-*s", $widths[$i], ("=" x length($headers[$i])));
	}
	printf("\n");

	for my $row (@rows) {
		if ($row) {
			for (my $i = 0; $i < @$row; $i++) {
				printf("%-*s", $widths[$i], $row->[$i]);
			}
		}
		printf("\n");
	}
}

# bosh_target_for $env
sub bosh_target_for {
	my ($env) = @_;
	if (defined($ENV{GENESIS_BOSH_ENVIRONMENT})) {
		`$BOSH "-e" $ENV{GENESIS_BOSH_ENVIRONMENT} "env" &>/dev/null`;
		return $ENV{GENESIS_BOSH_ENVIRONMENT} if ($? == 0);
		die "No such host: $ENV{GENESIS_BOSH_ENVIRONMENT} from GENESIS_BOSH_ENVIRONMENT environment variable for the BOSH Director.\n";
	}
	if (defined($ENV{BOSH_ENVIRONMENT})) {
		`$BOSH "-e" $ENV{BOSH_ENVIRONMENT} "env" &>/dev/null`;
		return $ENV{BOSH_ENVIRONMENT} if ($? == 0);
		die "No such host: $ENV{BOSH_ENVIRONMENT} from BOSH_ENVIRONMENT environment variable for the BOSH Director you are targeting at.\n";
	}
	my $bosh = get_key($env, 'params.bosh');
	if (defined($bosh)) {
		`$BOSH "-e" $bosh "env" &>/dev/null`;
		return $bosh if ($? == 0);
		die "No such host: $bosh for the BOSH Director which you configured in params.bosh.\n";
	 }
	$bosh = get_key($env, 'params.env');
	if (defined($bosh)) {
		`$BOSH "-e" $bosh "env" &>/dev/null`;
		return $bosh if ($? == 0);
		die "No such host: $bosh for the BOSH Director which you configured in params.env. You can specify your BOSH Director alias name in params.bosh.\n";
	}
	die "Could not find the `params.bosh' or `params.env' key in $env!\n";
}


###########################################################################

my ($COMMAND, %COMMAND, %USAGE);

sub usage {
	my ($rc, $msg, $cmd) = @_;
	$cmd = $COMMAND unless $cmd;
	print STDERR "$msg\n\n" if $msg;
	print STDERR $USAGE{$cmd} if $USAGE{$cmd};
	exit $rc;
}

our $GLOBAL_USAGE = <<EOF;
  -h, --help        Show this help screen.
  -D, --debug       Enable debugging, printing helpful message about what
                    Genesis is doing, to standard error.
  -T, --trace       Even more debugging, including debugging inside called
                    tools (like spruce and bosh).
  -C, --cwd         Effective working directory.  Defaults to '.'
  -e, --environment Which BOSH environment (aka director) to use.  If not
                    specified, it will use the value in params.bosh or
                    params.env in that order.  Can also be provided using either
                    \$GENESIS_BOSH_ENVIRONMENT or \$BOSH_ENVIRONMENT env variables.
EOF
sub options {
	my ($args, $options, @spec) = @_;
	$options->{color} = 1 unless exists $options->{color};
	GetOptionsFromArray($args, $options,
		(qw/
			help|h
			debug|D
			trace|T
			quiet|q
			offline
			cwd|C=s
			environment|e=s
			color!
		/,
		@spec))
			or usage(1);

	usage(0) if $options->{help};

	$ENV{QUIET}   = 'y' if  $options->{quiet};
	$ENV{DEBUG}   = 'y' if  $options->{debug};
	$ENV{TRACE}   = 'y' if  $options->{trace};
	$ENV{NOCOLOR} = 'y' if !$options->{color};
	$ENV{OFFLINE} = 'y' if  $options->{offline};

	debug("bosh env: ".($options->{environment} || "-same-as-env-file-"));

	$ENV{GENESIS_BOSH_ENVIRONMENT} = $options->{environment}
		if $options->{environment};
	chdir_or_fail $options->{cwd} if $options->{cwd};
}

sub command {
	my ($name, $usage, $fn) = @_;
	if (ref($name) ne 'ARRAY') {
		$name = [$name];
	}
	for my $cmd (@$name) {
		$USAGE{$cmd}   = $usage;
		$COMMAND{$cmd} = sub {
			$COMMAND = $cmd;
			$fn->(@_);
		};
	}
}


###########################################################################

# genesis help - print the help screen. {{{

command("help", <<EOF,
genesis v$VERSION
USAGE: genesis [OPTIONS] COMMAND [MORE OPTIONS]

OPTIONS
$GLOBAL_USAGE
COMMANDS
  create-kit       Create a new kit with default scaffolding.
  compile-kit      Create a distributable kit archive from dev.
  decompile-kit    Unpack a kit archive to dev.
  deploy           Generate a real manifest using Vault + Cloud Config, and deploy it to BOSH.
  describe         Describe a Concourse pipeline, in words.
  download         Download a Genesis Kit from the Internet.
  graph            Draw a Concourse pipeline.
  init             Initialize a new Genesis deployment.
  lookup           Find a key set in environment manifests.
  manifest         Generate a redacted BOSH deployment manifest for an environment.
  new              Create a new Genesis deployment environment.
  ping             See if the genesis binary is a real thing.
  repipe           Configure a Concourse pipeline for automating deployments.
  secrets          Re-generate / rotate credentials (passwords, keys, etc.).
  summary          Print a summary of defined environments.
  version          Print the version of genesis
  yamls            Print a list of the YAML files used for a single environment.

See `genesis COMMAND -h' for more specific, per-command usage information.
EOF
sub {
	usage(0);
});

# }}}
# genesis ping - see if the genesis binary is a real thing. {{{

command("ping", <<EOF,
genesis v$VERSION
USAGE: genesis ping

OPTIONS
$GLOBAL_USAGE
EOF
sub {
	check_prereqs(no_repo_needed => 1);
	print "PING!\n";
});

# }}}
# genesis version - Print the version of Genesis. {{{

command("version", <<EOF,
genesis v$VERSION
USAGE: genesis version

OPTIONS
$GLOBAL_USAGE
EOF
sub {
	print "Genesis v$VERSION\n";
});

# }}}
# genesis embed - embed Genesis in the repository {{{

command("embed", <<EOF,
genesis v$VERSION
USAGE: genesis embed

OPTIONS
$GLOBAL_USAGE
EOF
sub {
	my %options;
	options(\@_, \%options, qw/
	/);
	usage(1) if @_;
	check_prereqs;

	# FIXME: update .genesis/config with new version info
	mkdir_or_fail ".genesis/bin";
	copy_or_fail $0, ".genesis/bin/genesis";
	chmod_or_fail 0755, ".genesis/bin/genesis";
});
# }}}
#  genesis init - initialize a new Genesis repository {{{

command("init", <<EOF,
genesis v$VERSION
USAGE: genesis init [-k KIT/VERSION] [-d directory] [name]

OPTIONS
$GLOBAL_USAGE
  -k, --kit           Name (and optionally, version) of the Genesis Kit to base
                      these deployments on.  I.e.: shield/6.3.0.  If you do not
                      specify a kit, a dev directory will be created for you to
                      develop a local kit into.
  -L, --link-dev-kit  Instead of using a kit or initializing an empty dev
                      directory, this will link the specified directory to the
                      dev directory.
  -d, --directory     By default, the directory in which the Genesis deployment
                      will be created in will be named ./<name>-deployments.
                      Use this option to change it to something else.

  name                If the name argument is not specified, it will default to
                      the same name as the kit.  You must specify either name
                      or kit.
EOF
sub {
	my %options;
	options(\@_, \%options, qw/
		kit|k=s
		directory|d=s
		link-dev-kit|L=s
	/);
	usage(1) if @_ > 1; # name is now optional if kit specified
	check_prereqs(no_repo_needed => 1);

	my $abs_target;
	if ($options{'link-dev-kit'}) {
		usage(1,"Cannot specify both a kit (-k) and a link to a kit (-L)") if $options{kit};
		$abs_target = abs_path($options{'link-dev-kit'});
		my $pwd = Cwd::getcwd();
		die "Link target '$options{'link-dev-kit'}' cannot be found from $pwd!\n" unless $abs_target;
	}

	my ($name) = @_;
	unless ($name) {
		if ($options{kit}) {
			($name, $_) = extract_kit_name_and_version($options{kit});
		} elsif ($options{'link-dev-kit'}) {
			use File::Basename;
			$name = File::Basename::basename($options{'link-dev-kit'});
		} else {
			printf STDERR "You must specify a deployment name if you don't specify a kit or a dev link target.\n";
			usage(1);
		}
	}
	$name =~ s/-deployments//;

	validate_repo_name $name or die "Invalid Genesis repo name '$name'\n";

	debug "generating a new Genesis repo, named $name";

	debug "checking git config so can git commit later";
	execute 'git config user.name'
		or die 'Please setup git - git config --global user.name "Your Name" -';
	execute 'git config user.email'
		or die 'Please setup git - git config --global user.email your@email.com -';

	my $root = $options{directory} || "${name}-deployments";
	debug "in directory $root";
	if (-e $root) {
		die "Attempted to create new environment `$root' failed: Path already exists.\n";
	}
	mkdir_or_fail $root;
	mkdir_or_fail "$root/.genesis";
	put_file "$root/.genesis/config", <<EOF;
---
genesis: $VERSION
deployment_type: $name
EOF
	mkdir_or_fail "$root/.genesis/bin";
	copy_or_fail  $0, "$root/.genesis/bin/genesis";
	chmod_or_fail 0755, "$root/.genesis/bin/genesis";
	put_file "$root/README.md", <<EOF;
$name deployments
==============================

This repository contains the YAML templates that make up a series of
$name BOSH deployments, using the format prescribed by the
[Genesis][1] utility. These deployments are based off of the
[$name-genesis-kit][2].

Environment Naming
------------------

Each environment managed by this repository will have its own
deployment file, e.g. `us-east-prod.yml`. However, in many cases,
it can be desirable to share param configurations, or kit configurations
across all of the environments, or specific subsets. Genesis supports
this by splitting environment names based on hypthens (`-`), and finding
files with common prefixes to include in the final manifest.

For example, let's look at a scenario where there are three environments
deployed by genesis: `us-west-prod.yml`, `us-east-prod.yml`, and `us-east-dev.yml`.
If there were configurations that should be shared by all environments,
they should go in `us.yml`. Configurations shared by `us-east-dev` and `us-east-prod`
would go in `us-east.yml`.

To see what files are currently in play for an environment, you can run
`genesis <environment-name>`

Quickstart
----------

To create a new environment (called us-east-prod-$name):

    genesis new us-east-prod

To build the full BOSH manifest for an environment:

    genesis manifest us-east-prod

... and then deploy it:

    genesis deploy us-east-prod

To rotate credentials for an environment:

    genesis secrets us-east-prod
    genesis deploy us-east-prod

To update the Concourse Pipeline for this repo:

    genesis repipe

To download a new version of the kit, and deploy it:

    genesis download $name [version] # omitting version downloads the latest

    # update the environment yaml to use the desired kit version,
    # this might be in a different file if using CI to propagate
    # deployment upgrades (perhaps us.yml)
    vi us-east-prod.yml

    genesis deploy us-east-prod.yml # or commit + git push for CI to run through the upgrades

See the [Deployment Pipeline Documentation][3] for more
information on getting set up with Concourse deployment pipelines.

Helpful Links
-------------

- [$name-genesis-kit][2] - Details on the kit used in this repo,
  its subkits, prerequesites, and params.
- [Deployment Pipeline Documentation][3] - Docs on all the
  configuration options for `ci.yml`, and how the automated
  deployment pipelines behave.

[1]: https://github.com/starkandwayne/genesis
[2]: https://github.com/genesis-community/$name-genesis-kit
[3]: https://github.com/starkandwayne/genesis/blob/master/docs/PIPELINES.md

Repo Structure
--------------

Most of the meat of the deployment repo happens at the base level.
Envirionment YAML files, shared YAML files, and the CI
configuration YAML file will all be here.

The `.genesis/manifests` directory saves redacted copies of the
deployment manifests as they are deployed, for posterity, and to
keep track of any `my-env-name-state.yml` files from `bosh create-env`.

The `.genesis/cached` directory is used by CI to propagate changes
for shared YAML files along the pipelines. To aid in CI deploys, the
`genesis/bin` directory contains an embedded copy of genesis.

`.genesis/kits` contains copies of the kits that have been used in
this deployment. Once a kit is no longer used in any environment,
it can be safely removed (`genesis summary`).

`.genesis/config` is used internally by `genesis` to understand
what is being deployed, and how.
EOF

	chdir_or_fail $root;

	if ($options{'link-dev-kit'}) {
		debug "Kit: linking dev to $abs_target";
		symlink_or_fail $abs_target, "./dev";
	} elsif ($options{kit}) {
		debug "Kit: installing kit $options{kit}";
		my ($kit, $version) = extract_kit_name_and_version($options{kit});
		download_kit_tarball($kit, $version);
	} else {
		debug "Kit: creating empty ./dev kit directory";
		mkdir_or_fail "./dev";
	}

	execute 'git init'
		or die "Failed to initialize a git repository in $root/\n";
	execute 'git add .'
		or die "Failed to stage files to git, for initial commit, in $root/\n";
	execute 'git commit -m "Initial Genesis Repo"'
		or die "Failed to commit initial Genesis repository in $root/\n";

	exit 0;
});

# }}}
# genesis new - create a new Genesis deployment environment (YAML file) {{{

command("new", <<EOF,
genesis v$VERSION
USAGE: genesis new [--vault target] env-name[.yml]

OPTIONS
$GLOBAL_USAGE
      --vault        The name of a `safe' target (a Vault) to store newly
                     generated credentials in.

      --no-secrets   Do not generate secrets in the Vault.  You will have to
                     manually run `genesis secrets` yourself.

  -k, --kit          Name (and optionally, version) of the Genesis Kit to
                     use for this environment.  I.e.: shield/6.3.0
                     Defaults to latest.
EOF
sub {
	my %options = (
		secrets => 1,
	);
	options(\@_, \%options, qw/
		vault=s
		secrets!
		kit|k=s
	/);
	usage(1) if @_ != 1;

	my ($name) = @_;
	$name =~ s/\.ya?ml$//;

	validate_env_name $name or die "Invalid environment name '$name'\n";
	-f "$name.yml" and die "Environment '$name' already exists\n";

	at_exit(sub {
		# remove the env file if either prereqs check or vaultification fails
		unlink "$name.yml" unless $? == 0;
	});

	check_prereqs;
	explain "Generating new environment #C{$name}...\n";

	my ($kit, $version);
	if ($options{kit}) {
		($kit, $version) = extract_kit_name_and_version($options{kit});
	} else {
		($kit, $version) = latest_kit_name_and_version();
	}
	if ($kit && $kit ne "dev") {
		explain "Using $kit/$version kit...\n";
	} else {
		explain "Using dev/ (development version) kit...\n";
	}

	my $meta = read_kit_metadata($kit, $version);

	explain "Checking kit pre-requisites...\n";
	check_kit_prereqs($kit, $version);

	my @subkits = prompt_for_subkits($meta->{subkits} || []);
	@subkits = run_subkit_hook($kit, $version, @subkits);
	validate_subkits($kit, $version, $meta, @subkits);

	my $deployment = $name . "-" . deployment_suffix;
	(my $prefix = $name) =~ s|-|/|g;
	$prefix = "$prefix/".deployment_suffix;

	if ($options{secrets}) {
		target_vault($options{vault});
	}

	my $params = process_kit_params(kit          => $kit,
									version      => $version,
									env          => $name,
									vault_prefix => $prefix,
									should_vault => $options{secrets},
									params       => $meta->{params} || [],
									subkits      => \@subkits);
	$params = run_param_hook($kit, $version, $name, $prefix, $params, @subkits);

	new_environment($meta, $kit, $version, $name, $prefix, $params, @subkits);

	if ($options{secrets}) {
		explain "Generating secrets / credentials (in secret/$prefix)...\n";
		vaultify_secrets($meta, env          => $name,
		                        prefix       => $prefix,
		                        scope        => 'force',
		                        subkits      => [@subkits]);
	} else {
		explain "Skipping generation of secret / credentials.\n";
		explain "Don't forget to run `$0 secrets $name`\n";
	}

	explain "New environment $name provisioned.\n";
});

# }}}
# genesis deploy - Pull in Cloud Config, Generate a manifest, deploy {{{

command("deploy", <<EOF,
genesis v$VERSION
USAGE: genesis deploy [-n|--non-interactive] [--fix|--recreate] [--no-redact] env-name[.yml]

OPTIONS
$GLOBAL_USAGE
EOF
sub {
	my %options;
	options(\@_, \%options, qw/
		non-interactive|n
		no-redact
		fix
		recreate
	/);
	usage(1) if @_ != 1;
	check_prereqs;

	if ($options{fix} && $options{recreate}) {
		usage(1,"Cannot specify --fix and --recreate together");
	}

	if ($options{'non-interactive'}) {
		$ENV{BOSH_NON_INTERACTIVE}='true';
		delete $options{'non-interactive'};
	}

	my $rc = deploy_manifest($_[0], \%options);
	exit $rc;
});
# }}}
# genesis secrets - Generate / Rotate required credentials for an environment. {{{

command("secrets", <<EOF,
genesis v$VERSION
USAGE: genesis secrets [check|add|rotate [--force]][--vault target] deployment-env.yml

Checks, adds or rotates secrets for your deployment.

  * check:  Checks that all required secrets are present.  Returns a exit code
            of 1 if any are missing, and lists them, otherwise states all
            secrets are present and exits with 0.

  * add:    Generates any missing secrets required by the deployment.  Useful
            to generate credentials after upgrading kits or if `genesis new
            --no-secrets` was used to create the deployment.

  * rotate: Generates new secrets for your deployment. If any credentials were
            marked by the kit as `fixed', they are not updated unless the 
            `--force` option was also specified.

OPTIONS
$GLOBAL_USAGE
  -f, --force        Rotate *ALL* credentials, including any credentials that
                     the kit defined as `fixed'. This is very dangerous.  Only 
                     applies to `rotate`

      --vault        The name of a `safe' target (a Vault) to store newly
                     generated credentials in.

EOF
sub {
	my %options;
	options(\@_, \%options, qw/
		force|force-rotate-all|f
		vault=s
	/);

	my ($action,$name) = @_;
	if (@_ == 1) {
		$name = $action;
		$action = 'check';
	}
	usage(1) if @_ < 1 or @_ > 2;
    usage(1, "Must specify check, add or rotate, not $action")
		unless (grep {$_ eq $action} qw(check add rotate));
	if ($options{force}) {
		usage(1, "Can only specify --force with rotate") if $action ne 'rotate';
		$action = 'force';
	}

	check_prereqs;

	$name =~ s/\.ya?ml$//;
	my $deployment = $name . "-" . deployment_suffix;
	(my $prefix = $deployment) =~ s|-|/|g;

	my ($kit, $version) = kit_name_and_version_for($name);
	my $meta = read_kit_metadata($kit, $version);
	target_vault($options{vault});

	if ($action eq "check") {
		exit check_secrets(   $meta,
			env       => $name,
			prefix    => $prefix,
			subkits   => get_key($name, 'kit.subkits', [])
		);
	} else {
		vaultify_secrets($meta,
			env       => $name,
			prefix    => $prefix,
			subkits   => get_key($name, 'kit.subkits', []),
			scope     => $action
		);
	}
});

# }}}
# genesis yamls - Print a list of the YAML files used for a single environment. {{{

command("yamls", <<EOF,
genesis v$VERSION
USAGE: genesis yamls deployment-env.yml

OPTIONS
$GLOBAL_USAGE
EOF
sub {
	my %options;
	options(\@_, \%options, qw/
		rotate
	/);
	usage(1) if @_ != 1;
	check_prereqs;

	print "$_\n" for mergeable_yaml_files($_[0]);
});

# }}}
# genesis create-kit - Create the structure for a new kit {{{
#
command("create-kit", <<EOF,
genesis v$VERSION
USAGE: genesis create-kit -d|--dev -n NAME [SUBKIT1 ...]

OPTIONS
$GLOBAL_USAGE
  -d, --dev       create kit in ./dev directory instead of <name>-genesis-kit
  -n, --name      Name of the kit archive.
EOF
sub {
	my %options;
	options(\@_, \%options, qw/
		name|n=s
		dev|d
	/);
	usage(2) unless $options{name};
	check_prereqs(no_repo_needed => ! $options{dev}); # only require repo if in dev mode

	my $dir = ($options{cwd} || ".") . "/". ($options{dev} ? "dev" : "$options{name}-genesis-kit");

	die "$dir already exists, cowardly refusing to overwrite it\n"
	  if -d $dir;

	mkdir_or_fail $dir;
	mkdir_or_fail "$dir/base";

	mkfile_or_fail "$dir/base/params.yml", <<EOF;
---
# Contains the defaults for the parameters needed for the base $options{name} kit.
params: {}
EOF
	mkfile_or_fail "$dir/base/$options{name}.yml", <<EOF;
---
# Contains the configuration for base $options{name} kit.
instance_groups: {}
properties: {}

releases:
- name: $options{name}
  version:
  sha1:
  url:

EOF
	mkfile_or_fail "$dir/base/0-deployment.yml", <<EOF;
---
# Contains the instance_groups in install order, as well as the stemcells and
# update stanzas for the base $options{name} kit.
instance_groups:
- name: *jobname*
  instances: 1
  azs: (( grab params.availability_zones ))
  stemcell: default
  persistent_disk_pool: (( grab params.disk_pool ))
  networks:
  - name: (( grab params.network ))
    static_ips: (( static_ips(0) ))
  vm_type: (( grab params.vm_type ))
  update:
    max_in_flight: 1

stemcells:
- alias: default
  os: (( grab params.stemcell_os ))
  version: (( grab params.stemcell_version ))

meta:
  vault: (( concat "secret/" params.vault ))

update:
  serial: false
  canaries: 1
  canary_watch_time: 30000-600000
  update_watch_time: 5000-600000
  max_in_flight: 1
  max_errors: 1
EOF

	# Subkits
	mkdir_or_fail "$dir/subkits";
	my $subkit_groups="";
	my $subkit_param_groups="";
	my $subkit_prompts="";
	foreach my $subkit_req (@_) {
		my ($subkit,$prompt) = split("=",$subkit_req, 2);
		mkdir_or_fail "$dir/subkits/$subkit";
		$subkit_groups .= "  $subkit: {}\n";
		$subkit_param_groups .= "  $subkit: []\n";
		next if defined($prompt) && $prompt eq '-';
		$prompt ||= "Do you want to use subkit '$subkit'?";
		$subkit_prompts .= "- prompt: $prompt\n  subkit: $subkit\n";

		mkfile_or_fail "$dir/subkits/$subkit/params.yml", "---\nparams: {}\n";
		mkfile_or_fail "$dir/subkits/$subkit/$subkit.yml", "--- {}\n";
	}

	my $subkits = "";
	if ($subkit_prompts) {
		$subkits = "subkits:\n$subkit_prompts";
	} else {
		$subkits = "subkits: []\n";
	}

	chomp(my $user = qx'git config user.name');
	chomp(my $email = qx'git config user.email');
	mkfile_or_fail "$dir/kit.yml", <<EOF;
---
name: $options{name}
author: $user <$email>
homepage: https://github.com/cloudfoundry-community/$options{name}-boshrelease
github: https://github.com/genesis-community/$options{name}-genesis-kit

$subkits
params:
  base: []
$subkit_param_groups
credentials:
  base: {}
$subkit_groups
certificates:
  base: {}
$subkit_groups
EOF

	mkfile_or_fail "$dir/README.md", <<EOF;
$options{name} Genesis Kit
=================

FIXME: The kit author should have filled this in with details about
what this is, and what it provides. But they have not, and that is sad.
Perhaps a GitHub issue should be opened to remind them of this?

Quick Start
-----------

To use it, you don't even need to clone this repository! Just run
the following (using Genesis v2):

```
# create a $options{name}-deployments repo using the latest version of the $options{name} kit
genesis init --kit $options{name}

# create a $options{name}-deployments repo using v1.0.0 of the $options{name} kit
genesis init --kit $options{name}/1.0.0

# create a my-$options{name}-configs repo using the latest version of the $options{name} kit
genesis init --kit $options{name} -d my-$options{name}-configs
```

Once created, refer to the deployment repo's README for information on creating

Subkits
-------

FIXME: The kit author should have filled this in with details
about what subkits are defined, and how they affect the deployment. But they
have not, and that is sad. Perhaps a GitHub issue should be opened to remind
them of this?

Params
------

FIXME: The kit author should have filled this in with details about the params
present in the base kit, as well as each subkit defined. These should likely
be in different sections (one for base, one per subkit). Unfortunately,
the author has not done this, and that is sad. Perhaps a GitHub issue
should be opened to remind them of this?

Cloud Config
------------

FIXME: The kit author should have filled in this section with details about
what cloud config definitions this kit expects to see in play and how to
override them. Also useful are hints at default values for disk + vm sizing,
scaling considerations, and other miscellaneous IaaS components that the deployment
might require, like load balancers.

EOF

});

# }}}
# genesis compile-kit - Create a distributable kit archive from dev/. {{{

command("compile-kit", <<EOF,
genesis v$VERSION
USAGE: genesis compile-kit -v VERSION [-n NAME] [-d|--dev]

OPTIONS
$GLOBAL_USAGE

  -v, --version Version to package.

  -n, --name    Name of the kit archive.  If not provided, will take the name
                of the current (or specified with -C) directory before the
                suffix of -genesis-kit (standalone mode) or -deployments
                (dev mode).

  -d, --dev     Compile based off of a dev-kit (./dev). If not specified,
                genesis will compile based off of ./<name>-genesis-kit. 
                Automatically set if run from inside a genesis deployments directory.
EOF
sub {
	my %options;
	options(\@_, \%options, qw/
		dev|d
		name|n=s
		version|v=s
	/);
	usage(1) if @_ != 0;

	my $dir;
	unless ($options{name}) {
		my $pwd = abs_path($options{cwd} || getcwd);
		if ($pwd =~ /\/([^\/]*)-deployments(\/)?$/) {
		# Building from a dev inside a deployment repo - gleen the name
			$options{name} = $1;
			$dir = "$pwd/dev";
			$options{dev} = 1;
		} elsif ($pwd =~ /\/([^\/]*)-genesis-kit(\/)?$/) {
			$options{name} = $1;
			$dir = $pwd;
			die "Current directory is a kit -- cannot specify dev mode\n"
				if $options{dev};
		}
	}
	usage(1, "Missing name option, cannot determine from `pwd`") unless $options{name};
	usage(1) unless $options{version};
	check_prereqs(no_repo_needed => 1);

	unless ($dir) {
		if ($options{dev}) {
			$dir = ($options{cwd} || ".") . "/dev";
			die "$dir does not exist -- cannot continue compiling dev kit.\n" unless -d $dir;
		} else {
			$dir = ($options{cwd} || ".");
			$dir .= "/$options{name}-genesis-kit"
				if (! -f "$dir/kit.yml" && -d "/$options{name}-genesis-kit");
		}
	}

	validate_kit_files($dir);
	validate_kit_metadata($options{name},$options{version},LoadFile("$dir/kit.yml"),1);

	my $temp = tempdir(CLEANUP => 1);
	my $stem = "$options{name}-$options{version}";
	mkdir_or_fail "$temp/$stem";
	qx(cp -aH $dir/* $temp/$stem);

	qx(rm -rf $temp/.git $temp/.gitignore);

	qx(tar -czf $stem.tar.gz -C $temp $stem/);

	printf "Created $stem.tar.gz\n\n";
});

# }}}
# genesis decompile-kit - Unpack a kit archive to dev/. {{{

command("decompile-kit", <<EOF,
genesis v$VERSION
USAGE: genesis decompile-kit [NAME/VERSION | path/to/kit.tar.gz]

OPTIONS
$GLOBAL_USAGE
  -f, --force  Overwrite dev/, if it exists.
EOF
sub {
	my %options;
	options(\@_, \%options, qw/
		force|f
	/);
	usage(1) if @_ != 1;
	check_prereqs;

	if (-d "dev" && !$options{force}) {
		die "dev/ directory already exists (and --force not specified).  Bailing out.\n";
	}

	my $temp = tempdir(CLEANUP => 1);
	my $file = $_[0];
	if (! -f $file) {
		(my $stem = $file) =~ s|/|-|;
		$file = ".genesis/kits/$stem.tar.gz";
	}
	-f $file or die "Unable to find Kit archive $_[0]\n";

	qx(tar -xzf $file -C $temp && rm -rf dev && mv $temp/*/ dev/);
});

# }}}
# genesis manifest - Compile a deployment manifest. {{{

command("manifest", <<EOF,
genesis v$VERSION
USAGE: genesis manifest [--no-redact] [--cloud-config path.yml] deployment-env.yml

OPTIONS
$GLOBAL_USAGE

  -c, --cloud-config PATH    Path to your downloaded BOSH cloud-config

      --no-redact            Do not redact credentials in the manifest.
                             USE THIS OPTION WITH GREAT CARE AND CAUTION.
EOF
sub {
	my %options;
	options(\@_, \%options, qw/
		cloud-config|c=s
		no-redact
	/);
	usage(1) if @_ != 1;
	my ($env) = @_;
	check_prereqs;

	$ENV{REDACT} = 'true';
	$ENV{REDACT} = '' if $options{'no-redact'};

	my $create_env = is_create_env($env);

	# set offline since there's no director to talk to
	$ENV{OFFLINE} = 1 if ($create_env);

	if (!$options{'cloud-config'} && !$create_env) {
		if (!online) {
			error "You requested #B{offline} mode, but did not provide a #C{--cloud-config} to use.\n";
			error "In offline mode, Genesis is not allowed to talk to the BOSH director,\n";
			error "so you must provide a cloud config explicitly.\n";
			exit 1;
		}
		my $dir = workdir;
		bosh_download_cloud_config(bosh_target_for($env), "$dir/cloud.yml");
		$options{'cloud-config'} = "$dir/cloud.yml";
	}
	print merge_manifest($env, {
		'cloud-config' => $options{'cloud-config'},
		'create-env'   => $create_env,
	});
});

# }}}
# genesis repipe - Deploy a Concourse CI/CD deployment pipeline. {{{

command(["repipe", "push"], <<EOF,
genesis v$VERSION
USAGE genesis repipe [pipeline-layout]

OPTIONS
$GLOBAL_USAGE
  -t, --target     The name of your Concourse target (per `fly targets'),
                   if it differs from the pipeline layout name.

  -n, --dry-run    Generate the Concourse Pipeline configuration, but
                   refrain from actually deploying it to Concourse.
                   Instead, just print the YAML.

  -c, --config     Path to the pipeline configuration file, which specifies
                   Git parameters, notification settings, pipeline layouts,
                   etc.  Defaults to 'ci.yml'
EOF
sub {
	my %options;
	options(\@_, \%options, qw/
		dry-run|n
		target|t=s
		config|c=s
	/);
	check_prereqs;

	my $layout = $_[0] || "default";
	$options{target} ||= $layout;
	$options{config} ||= 'ci.yml';

	my $pipeline = parse_pipeline($options{config}, $layout);
	my $yaml = generate_pipeline_concourse_yaml($pipeline);
	if ($options{'dry-run'}) {
		print $yaml;
		exit 0;
	}

	my $dir = workdir;
	put_file("${dir}/pipeline.yml", $yaml);
	system_execute("fly -t $options{target} set-pipeline -p $pipeline->{pipeline}{name} -c ${dir}/pipeline.yml") or exit 1;
	system_execute("fly -t $options{target} unpause-pipeline -p $pipeline->{pipeline}{name}") or exit 1;
	if ($pipeline->{pipeline}{public}) {
		system_execute("fly -t $options{target} expose-pipeline -p $pipeline->{pipeline}{name}") or exit 1;
	} else {
		system_execute("fly -t $options{target} hide-pipeline -p $pipeline->{pipeline}{name}") or exit 1;
	}
	exit 0;
});
# }}}
# genesis graph - Draw a Concourse CI/CD deployment pipeline. {{{

command("graph", <<EOF,
genesis v$VERSION
USAGE genesis graph [pipeline-layout] | dot -Tpng > pipe.png

Note: This command outputs a directed, acyclic graph (a DAG) in the
      Graphviz language (http://www.graphviz.org/).  If you want a
      picture of the pipeline, you will need to pipe the output through
      one of the many Graphviz formatters, like `dot -Tpng > out.png`

OPTIONS
$GLOBAL_USAGE
  -c, --config     Path to the pipeline configuration file, which specifies
                   Git parameters, notification settings, pipeline layouts,
                   etc.  Defaults to 'ci.yml'
EOF
sub {
	my %options;
	options(\@_, \%options, qw/
		config|c=s
	/);
	check_prereqs;

	my $layout = $_[0] || "default";
	$options{config} ||= 'ci.yml';

	my $pipeline = parse_pipeline($options{config}, $layout);
	my $dot = generate_pipeline_graphviz_source($pipeline);
	print "$dot\n";
	exit 0;
});
# }}}
# genesis describe - Describe a Concourse CI/CD deployment pipeline. {{{

command("describe", <<EOF,
genesis v$VERSION
USAGE genesis describe [pipeline-layout]

OPTIONS
$GLOBAL_USAGE
  -c, --config     Path to the pipeline configuration file, which specifies
                   Git parameters, notification settings, pipeline layouts,
                   etc.  Defaults to 'ci.yml'
EOF
sub {
	my %options;
	options(\@_, \%options, qw/
		config|c=s
	/);
	check_prereqs;

	my $layout = $_[0] || "default";
	$options{config} ||= 'ci.yml';

	my $pipeline = parse_pipeline($options{config}, $layout);
	generate_pipeline_human_description($pipeline);
	exit 0;
});
# }}}
# genesis lookup - Find a key set in environment manifests. {{{

command("lookup", <<EOF,
genesis v$VERSION
USAGE genesis lookup key env-name default-value

OPTIONS
$GLOBAL_USAGE
EOF
sub {
	my %options;
	options(\@_, \%options, qw/
	/);
	usage(1) if @_ != 3;
	check_prereqs;

	my ($key, $env, $default) = @_;
	my $v = get_key($env, $key);
	$v = defined $v ? $v : $default;
	if (ref($v)) {
		print encode_json($v)."\n";
	} else {
		print "$v\n";
	}
	exit 0;
});
# }}}
# genesis download - Download a Genesis Kit from the Internet. {{{

command("download", <<EOF,
genesis v$VERSION
USAGE genesis download NAME[/VERSION] [...]

OPTIONS
$GLOBAL_USAGE
EOF
sub {
	my %options;
	options(\@_, \%options, qw/
	/);
	usage(1) if @_ < 1;
	check_prereqs;

	for (@_) {
		my ($name, $version) = extract_kit_name_and_version($_);
		download_kit_tarball($name, $version)
			or exit 1;
	}
	exit 0;
});
# }}}
# genesis summary - Print a summary of each environment. {{{

command("summary", <<EOF,
genesis v$VERSION
USAGE genesis summary

OPTIONS
$GLOBAL_USAGE
EOF
sub {
	my %options;
	options(\@_, \%options, qw/
	/);
	check_prereqs;

	my @rows;
	my $stem = undef;
	for my $env (standalone_environment_yaml_files(glob("*.yml"))) {
		$env =~ s/\.yml$//;
		my $kit = get_key($env, "kit.name");
		my $ver = get_key($env, "kit.version");

		# FIXME: look at last  time i deployed the manifest instead of this cache file
		# FIXME: show what is out of date, if anything
		my $last = "never";
		if (-f ".genesis/cached/$env/last") {
			my $ts = get_file(".genesis/cached/$env/last") + 0;
			if ($ts) { # in case `last' is corrupt (i.e. not a timestamp)
				$last = strftime(envdefault("GENESIS_TIME_FORMAT", "%Y-%m-%d %H:%M:%S%P (@@)"), localtime($ts));

				$last =~ s/@@/ago($ts)/ge;
			}
		}

		(my $tmp = $env) =~ s/-[^-]*$//;
		push @rows, undef if defined $stem && $stem ne $tmp;
		$stem = $tmp;

		push @rows, [$env, "$kit/$ver", $last];

	}
	tablify(['Environment', 'Kit/Version', 'Last Deployed'], \@rows);
	exit 0;
});
# }}}
# genesis vault-policies - Generate Vault policies for an environment {{{
command("vault-policies", <<EOF,
genesis v$VERSION
USAGE genesis vault-policies [pipeline-layout]

OPTIONS
$GLOBAL_USAGE
  -c, --config     Path to the pipeline configuration file, which specifies
                   Git parameters, notification settings, pipeline layouts,
                   etc.  Defaults to 'ci.yml'
EOF
sub {
	my %options;
	options(\@_, \%options, qw/
	/);
	check_prereqs;

	my $layout = $_[0] || "default";
	$options{config} ||= "ci.yml";

	$ENV{REDACT} = "true"; # we don't need vault creds for this, just pipeline layout
	my $pipeline = parse_pipeline($options{config}, $layout);
	for my $env (sort @{$pipeline->{envs}}) {
		my $create_env = is_create_env($env);
		# Always grab cloud config, since we're probably up and running if using this command
		# Posible issues we could run into are that the jumpbox doesn't have access to all
		# BOSH directors, or that someone is trying to build their vault policies before
		# anything is running. If we run into these cases, this can be changed, either by
		# somehow providing cloud configs for *all* boshes, or by making `spruce vaultinfo`
		# ignore static_ips?
		my $dir = workdir;
		if (!$create_env) {
			bosh_download_cloud_config(bosh_target_for($env), "$dir/cloud.yml");
		} else {
			write_stemcell_data("$dir/cloud.yml");
		}
		$options{'cloud-config'} = "$dir/cloud.yml";

		# get all files for a deployment
		my $vault_prefix = get_key($env, "params.vault", "");
		chomp $vault_prefix;
		$vault_prefix = "secret/$vault_prefix";
		die "Unable to find `params.vault' for environment `$env'. Cannot continue\n" unless $vault_prefix;
		print <<EOF;
path "$vault_prefix/*" {
    capabilities = [ "read", "list" ]
}

EOF
		for my $path (sort grep { chomp; $_ !~ m/^$vault_prefix/ } spruce_vault_paths(@{merge_files($env, \%options)})) {
			print <<EOF;
path "$path" {
    capabilities = [ "read", "list" ]
}

EOF
		}
	}
	print <<EOF;
path "secret/handshake" {
    capabilities = [ "read", "list" ]
}
EOF
});
# }}}
# genesis ci-pipeline-deploy - Deploy via the CI/CD Pipeline {{{

command("ci-pipeline-deploy", <<EOF,
genesis v$VERSION
USAGE genesis ci-pipeline-deploy

OPTIONS
$GLOBAL_USAGE
EOF
sub {
	my %options;
	options(\@_, \%options, qw/
	/);
	usage(1) if @_;
	check_prereqs(no_repo_needed => 1);

	# environment variables we should have
	#   CURRENT_ENV                - Name of the current environment
	#   PREVIOUS_ENV               - Name of previous environment (if applicable, for finding
	#
	#   VAULT_ROLE_ID              - Vault RoleID to authenticate to Vault with
	#   VAULT_SECRET_ID            - Vault SecretID to authenticate to Vault with
	#   VAULT_ADDR                 - URL of the Vault to use for credentials retrieval
	#   VAULT_SKIP_VERIFY          - Whether or not to enforce SSL/TLS validation
	#
	#   GIT_BRANCH                 - Name of the git branch to push commits to. post-deploy
	#   GIT_PRIVATE_KEY            - Private Key to use for pushing commits, post-deploy
	#
	#   WORKING_DIR - Path to the directory to deploy/work from
	#   OUT_DIR     - Path to the directory to output to
	#   CACHE_DIR   - Path to the directory our cache is in (required if PREVIOUS_ENV is present
	#
	# and unless we're a create-env based deploy, we should also have:
	#   BOSH_ENVIRONMENT           - URL of the BOSH director to deploy on
	#   BOSH_CA_CERT               - CA Certificate for the BOSH director
	#   BOSH_CLIENT                - Username or client ID (UAA-auth) to authenticate with
	#   BOSH_CLIENT_SECRET         - Password/Client-Secret to authenticate with

	my @undefined = grep { !$ENV{$_} }
		qw/CURRENT_ENV GIT_BRANCH GIT_PRIVATE_KEY
		   OUT_DIR WORKING_DIR
		   VAULT_ROLE_ID VAULT_SECRET_ID VAULT_ADDR/;
	push @undefined, "CACHE_DIR" if ($ENV{PREVIOUS_ENV} && ! $ENV{CACHE_DIR});

	# move to working dir prior to seeing if current env is bosh-init
	pushd $ENV{WORKING_DIR};
	push(@undefined, grep { !$ENV{$_} }
		qw/BOSH_ENVIRONMENT BOSH_CA_CERT
		   BOSH_CLIENT BOSH_CLIENT_SECRET/) unless is_create_env($ENV{CURRENT_ENV});

	if (@undefined) {
		error "The following #R{required} environment variables have not been defined:";
		error " - \$#Y{$_}" for @undefined;
		error;
		error;
		error "Please check your CI Pipeline configuration.";
		exit 1;
	}

	if ($ENV{PREVIOUS_ENV}) {
		system("rm -rf .genesis/config .genesis/kits .genesis/cached") == 0 or exit 1;
		system("cp -R ../$ENV{CACHE_DIR}/.genesis/cached .genesis/cached") == 0 or exit 1;
		system("cp -R ../$ENV{CACHE_DIR}/.genesis/config .genesis/config") == 0 or exit 1;
		system("cp -R ../$ENV{CACHE_DIR}/.genesis/kits .genesis/kits") == 0 or exit 1;
	}

	# don't set up a bosh alias if we're a create-env based deploy, no need, no data
	unless (is_create_env($ENV{CURRENT_ENV})) {
		my $target = bosh_target_for($ENV{CURRENT_ENV});
		bosh_alias($target); # exits on failure
	}

	vault_auth(vault       => $ENV{VAULT_ADDR},
	           skip_verify => envset("VAULT_SKIP_VERIFY"),
	           role_id     => $ENV{VAULT_ROLE_ID},
	           secret_id   => $ENV{VAULT_SECRET_ID});

	my $rc = deploy_manifest($ENV{CURRENT_ENV}); # exits if it fails
	if ($ENV{PREVIOUS_ENV}) {
		## rm cache dir
		## copy previous env cache dir
		system("rm -rf .genesis/config .genesis/kits .genesis/cached") == 0 or exit 1;
		system("git checkout .genesis/config"); # ignore failure for git checkout so that
		system("git checkout .genesis/kits");   # we don't cause problems if these files dont
		system("git checkout .genesis/cached"); # yet exist in the working tree (but did in the cache tree)
	}
	popd;
	commit_changes($ENV{WORKING_DIR}, $ENV{OUT_DIR}, $ENV{GIT_BRANCH}, $ENV{GIT_PRIVATE_KEY},
		"deployed to $ENV{CURRENT_ENV}");
	exit $rc;
});
# }}}
# genesis ci-stemcells - Upload stemcells to an environment via the CI/CD Pipeline {{{
command("ci-stemcells", <<EOF,
genesis v$VERSION
USAGE genesis ci-stemcells

OPTIONS
$GLOBAL_USAGE
EOF
sub {
	my %options;
	options(\@_, \%options, qw/
	/);
	usage(1) if @_;
	check_prereqs(no_repo_needed => 1);

	# environment variables we should have
	#   STEMCELLS - Path to the directory containing stemcells to upload
	#   BOSH_ENVIRONMENT           - URL of the BOSH director to deploy on
	#   BOSH_CA_CERT               - CA Certificate for the BOSH director
	#   BOSH_CLIENT                - Username or client ID (UAA-auth) to authenticate with
	#   BOSH_CLIENT_SECRET         - Password/Client-Secret to authenticate with
	#
	my @undefined = grep { !$ENV{$_} }
		qw/STEMCELLS BOSH_ENVIRONMENT BOSH_CA_CERT BOSH_CLIENT BOSH_CLIENT_SECRET/;
	if (@undefined) {
		error "The following #R{required} environment variables have not been defined:";
		error " - \$#Y{$_}" for @undefined;
		error;
		error;
		error "Please check your CI Pipeline configuration.";
		exit 1;
	}

	opendir(my $dh, $ENV{STEMCELLS})
		or die "Could not open `$ENV{STEMCELLS}' directory to find stemcells.\n";
	while (my $stemcell = readdir($dh)) {
		if ($stemcell !~ /^\./ && -d "$ENV{STEMCELLS}/$stemcell") {
			my $version = get_file "$ENV{STEMCELLS}/$stemcell/version";
			my $sha1    = get_file "$ENV{STEMCELLS}/$stemcell/sha1";
			my $url     = get_file "$ENV{STEMCELLS}/$stemcell/url";
			bosh_upload_stemcell($stemcell, $version, $sha1, $url);
		}
	}
	closedir $dh
});
# }}}
# genesis ci-generate-cache - Generate cache for an environment via the CI/CD Pipeline {{{
command("ci-generate-cache", <<EOF,
genesis v$VERSION
USAGE genesis ci-generate-cache

OPTIONS
$GLOBAL_USAGE
EOF
sub {
	my %options;
	options(\@_, \%options, qw/
	/);
	usage(1) if @_;
	check_prereqs(no_repo_needed => 1);

	# environment variables we should have
	#   CURRENT_ENV - Name of the current environment
	#   GIT_BRANCH                 - Name of the git branch to push commits to. post-deploy
	#   GIT_PRIVATE_KEY            - Private Key to use for pushing commits, post-deploy
	#   WORKING_DIR - Path to the directory to deploy/work from
	#   OUT_DIR     - Path to the directory to output to
	#
	my @undefined = grep { !$ENV{$_} }
		qw/CURRENT_ENV GIT_BRANCH GIT_PRIVATE_KEY
		   WORKING_DIR OUT_DIR/;
	if (@undefined) {
		error "The following #R{required} environment variables have not been defined:";
		error " - \$#Y{$_}" for @undefined;
		error;
		error;
		error "Please check your CI Pipeline configuration.";
		exit 1;
	}

	pushd $ENV{WORKING_DIR};
	mkdir_or_fail ".genesis/cached/$ENV{CURRENT_ENV}";
	for my $file (expand_tokens(split /\-/, $ENV{CURRENT_ENV})) {
		copy_or_fail "$file.yml", ".genesis/cached/$ENV{CURRENT_ENV}/$file.yml" if -f "$file.yml";
	}
	popd;
	commit_changes($ENV{WORKING_DIR}, $ENV{OUT_DIR}, $ENV{GIT_BRANCH}, $ENV{GIT_PRIVATE_KEY}, "generated cache for $ENV{CURRENT_ENV}");
});
# }}}
# genesis ci-pipeline-run-errand - Run arbitrary errands via the CI/CD Pipeline {{{

command("ci-pipeline-run-errand", <<EOF,
genesis v$VERSION
USAGE genesis ci-pipeline-run-errand

OPTIONS
$GLOBAL_USAGE
EOF
sub {
	my %options;
	options(\@_, \%options, qw/
	/);
	usage(1) if @_;
	check_prereqs(no_repo_needed => 1);

	# environment variables we should have
	#   CURRENT_ENV - Name of the current environment
	#   BOSH_ENVIRONMENT   - URL of the BOSH director to deploy on
	#   BOSH_CA_CERT       - CA Certificate for the BOSH director
	#   BOSH_CLIENT        - Username or client ID (UAA-auth) to authenticate with
	#   BOSH_CLIENT_SECRET - Password/Client-Secret to authenticate with
	#   ERRAND_NAME - Name of the Smoke Test errand to run

	my @undefined = grep { !$ENV{$_} }
		qw/CURRENT_ENV ERRAND_NAME
		   BOSH_ENVIRONMENT BOSH_CA_CERT
		   BOSH_CLIENT BOSH_CLIENT_SECRET/;
	if (@undefined) {
		error "The following #R{required} environment variables have not been defined:";
		error " - \$#Y{$_}" for @undefined;
		error;
		error;
		error "Please check your CI Pipeline configuration.";
		exit 1;
	}

	my $target = bosh_target_for($ENV{CURRENT_ENV});
	bosh_alias($target); # exits on failure

	my $deployment = "$ENV{CURRENT_ENV}-" . deployment_suffix;
	bosh_run_errand($target, $deployment, $ENV{ERRAND_NAME}); # exits on failure

	exit 0;
});
# }}}

###########################################################################

sub main {
	debug "genesis starting up...";

	$ENV{GENESIS} = $FindBin::Script;
	$ENV{GENESIS_INDEX} = "https://genesis.starkandwayne.com" unless $ENV{GENESIS_INDEX};

	# Check if we're in a v1 repo
	my $path = abs_path(getcwd);
	my $in_version = 0;
	if (in_repo_dir) {
		$in_version = 2;
	} else {
		while ($path ne "") {
			if (-d "$path/global" && -e "$path/global/deployment.yml") {
				$in_version = 1;
				last;
			}
			$path =~ s/\/[^\/]*$//;
		}
	}

	if ($in_version == 1) {
		# Make temp file for the script.
		die "Missing bin directory in the genesis deployment root -- required to run genesis v1\n"
			unless -d "$path/bin";
		my ($g1file,$g1filename) = tempfile("genesis-v1-XXXXXX",DIR =>"$path/bin/", UNLINK => 1);

		# Copy __DATA__ to tmpdir as "genesis-v1"
		my $g1script = do { local $/; <DATA> };

		# If this isn't the packaged version of genesis, bail
		die "ERROR: Attempting to use an unpackaged version of Genesis v2 in a v1 repository.\n"
		  unless $g1script;

		print $g1file $g1script;
		close $g1file;
		chmod 0755, $g1filename;

		# Set GENESIS_V1_PATH env var to shadow the obscure location
		($ENV{GENESIS_V2_VERSION} = $VERSION) =~ s/^\((.*)\)$/$1/;
		$ENV{GENESIS_V1_PATH_OVERRIDE} = $0;

		# Run v1 bash script
		$SIG{TERM} = sub {exit 3};
		$SIG{INT} = sub {exit 3};
		system($g1filename, @_);
		exit $? >> 8;
	}
	my ($cmd, @args);
	while (@_ > 0) {
		my $arg = shift @_;
		if ($cmd || $arg =~ m/^-+/) {
			push @args, $arg;
			push @args, shift @_ if $arg eq '-C';
		} else {
			$cmd = $arg;
		}
	}

	if ($cmd) {
		debug "running command '$cmd'";
		debug "arguments are [".join(', ', @args)."]";
		if (exists $COMMAND{$cmd}) {
			$COMMAND{$cmd}(@args);
			exit 0;
		}
		error "unrecognized command '$cmd'";
		usage(2, "", "help");
	}
	if (@args and $args[0] =~ m/^(-h|--help)$/) {
		$COMMAND{help}();
		exit 0;
	}
	if (@args and scalar(@args) == 1 && $args[0] =~ m/^(-v|--version)$/) {
		$COMMAND{version}();
		exit 0;
	}
	$COMMAND{help}();
	exit 2;
}

main(@ARGV);

__DATA__
#!/bin/bash
unset IFS
shopt -s nullglob

: <<'dox-overview:genesis'
USAGE
@~include=usage{"cmd":"<command> [options] [arguments]"}

DESCRIPTION
	Genesis is a tool built around a BOSH deployment paradigm that allows you to
	create and manage unified deployment manifests across multiple sites and
	environments.

	It does this by breaking up your BOSH configuration manifest along three
	logical strata: global, site and environment.  This allows you to work on
	small related blocks of elements, reducing complexity and redundancy, then
	package them up for deployment across different IaaS providers and target
	environments with properties appropriate for their needs.

CONCEPTS
@~include=topic{"category":"concept","leader":"    ","scope":"intro","desc":"block"}

	More details are available for each concept by running
	`<<SCRIPT_NAME>> help --concept <concept-name>`.

COMMON COMMANDS
@~include=topic{"category":"command","scope":"common","leader":"  <<SCRIPT_NAME>> ","desc":"inline"}

  For more details, run `<<SCRIPT_NAME>> help <command>`
dox-overview:genesis

: <<'dox-concept:Makefiles'
DESCRIPTION
	When Genesis provisions a new environment, it creates a Makefile that
	provides some easy "shortcut" command invocation targets to simplify the
	manifest generation process.

		make help
			Displays this help content.

		make version
			Displays the version and location of the `genesis` executable that will
			be used by the other make actions

		make refresh
			Pull in fresh copies of global and site YAML templates (into .global/ and
			.site/).  This is a shortcut for `<<SCRIPT_NAME>> refresh all`

		make manifest
			Build a new manifest for the environment by merging the template YAML
			files together.

		make deploy
			Build the manifest and attempt to deploy it.  This safely handles Vault'd
			credentials by creating a separate manifest yaml file that only exists
			for the duration of the deploy.

	Since this is a real Makefile, you can combine the two actions.  For example:

		make refresh manifest
			Refresh global / site configuration, and then build an up-to-date
			deployment manifest.

SEE ALSO
@~include=topic{"category":"concept","scope":"makefile","desc":"none","leader":"  <<SCRIPT_NAME>> help --concept "}

COMMANDS
@~include=topic{"category":"command","scope":"makefile","desc":"inline","leader":"  <<SCRIPT_NAME>> "}

dox-concept:Makefiles

VERSION="(development build)"
if [[ -n "$GENESIS_V2_VERSION" ]] ; then
  VERSION="1.x.x"
fi
SCRIPT_NAME="$(basename $0)"
if [[ -n "$GENESIS_V1_PATH_OVERRIDE" ]] ; then
  SCRIPT_NAME="$(basename "$GENESIS_V1_PATH_OVERRIDE")"
fi

USERNAME=$(whoami)
CANON_REPO=https://github.com/starkandwayne/genesis
API_REPO=https://api.github.com/repos/starkandwayne/genesis

GENESIS_INDEX=${GENESIS_INDEX:-https://genesis.starkandwayne.com}
GENESIS_INDEX=${GENESIS_INDEX%/}
if [[ ${GENESIS_INDEX} = "no" ]]; then
	GENESIS_INDEX=
fi

HAVE_TREE=
if [[ -n $(command -v tree 2>/dev/null) ]]; then
	HAVE_TREE=yes
fi

####################################################
# common functions used by other parts of Genesis

WORKDIR=""
need_a_workdir() {
	if [[ -z ${WORKDIR} ]]; then
		WORKDIR=$(mktemp -d -t genesis.XXXXXX)
		trap "rm -rf ${WORKDIR}" INT TERM QUIT EXIT
	fi
}

find_toplevel_root() {
	(while [[ $(pwd) != "/" && ! -d global/ && ! -f .deployment ]]; do
		cd ..
	 done
	 if [[ -d global || -f .deployment ]]; then
		pwd
	 fi)
}

all_sites() {
	setup
	for dir in ${DEPLOYMENT_ROOT}/*/; do
		site=${dir%%/}
		site=${site##*/}

		if [[ "${site}" != "global" && -d "${dir}/site" ]]; then
			echo ${site}
		fi
	done
}

all_pipeline_sites() {
	spruce json $(ci_pipeline_yaml) | jq -r ".sites | keys | .[]"
}

all_environments_for() {
	local site=${1:?all_environments_for() - no site name provided}
	setup
	for dir in ${DEPLOYMENT_ROOT}/${site}/*/; do
		env=${dir%%/}
		env=${env##*/}

		if [[ -f "${dir}/Makefile" ]]; then
			echo ${env}
		fi
	done
}

check_site() {
	local path=${1:?is_site() - no site argument provided}
	if [[ ! -d "${DEPLOYMENT_ROOT}/${path}" ]]; then
		echo >&2 "Site ${path} not found"
		exit 1
	fi
	if [[ ! -d "${DEPLOYMENT_ROOT}/${path}/site" ]]; then
		echo >&2 "${path} does not look like a valid site"
		exit 2
	fi
}

check_environment() {
	local path=${1:?check_environment() - no site/environment argument provided}
	if [[ ! -d "${DEPLOYMENT_ROOT}/${path}" ]]; then
		echo >&2 "Environment ${path} not found"
		exit 1
	fi
	if [[ ! -f "${DEPLOYMENT_ROOT}/${path}/Makefile" ]]; then
		echo >&2 "${path} does not look like a valid environment"
		exit 2
	fi
}

line() {
	echo
	echo "########################################################################"
	echo
}

version_checker() {
	if [[ $1 == $2 ]]
	then
		return 0
	fi
	local IFS=.
	local i actual=($1) expected=($2)
	# fill empty fields in actual with zeros
	for ((i=${#actual[@]}; i<${#expected[@]}; i++))
	do
		actual[i]=0
	done
	actual_numeric=0
	expected_numeric=0
	for ((i=0; i<${#actual[@]}; i++))
	do
		if [[ -z ${expected[i]} ]]
		then
			# fill empty fields in expected with zeros
			expected[i]=0
		fi
		actual_numeric=$((actual_numeric+${actual[i]}*1000**(${#actual[@]}-i)))
		expected_numeric=$((expected_numeric+${expected[i]}*1000**(${#expected[@]}-i)))
	done


	if [[ ${actual_numeric} -lt ${expected_numeric} ]]; then
		return 1
	fi
	return 0
}

setup() {
	if [[ ${DEPLOYMENT_ROOT:-unset} != "unset" ]]; then
		return
	fi

	DEPLOYMENT_ROOT=$(find_toplevel_root)
	if [[ -z ${DEPLOYMENT_ROOT:-} ]]; then
		echo >&2 "Unable to determine Genesis DEPLOYMENT_ROOT"
		exit 3
	fi

	if [[ -f ${DEPLOYMENT_ROOT}/.genesis_deps ]]; then
		errors=""
		while IFS='' read -r line || [[ -n "$line" ]]; do
			cmd=$(echo $line | perl -pe 's|^(.*?):.*$|$1|')
			ver=$(echo $line | perl -pe 's|^.*?: *v?(.*)$|$1|')

			if [[ ${cmd} == "genesis" ]] ; then
				cmd_version="${VERSION}"
			else
				if [[ -z $(command -v ${cmd}) ]] ; then
					errors="This Genesis deployment requires the '${cmd}' command\n${errors}"
					continue
				fi
				cmd_version=$(${cmd} -v 2>&1)
			fi

			if [[ ${ver} != "null" && ${ver} != '~' ]]; then
				dev_version=$(echo "${cmd_version}" | perl -pe 's/.*development.*/DEV/')
				if [[ ${dev_version} == "DEV" ]]; then
					echo "Treating 'development' version as up-to-date with ${ver}"
					continue
				fi

				# 1.x.x version of genesis is always the latest available (no further features being developed in the 1.x.x branch)
				if [[ "${cmd}" == "genesis" ]] ; then 
					major_ver="$(echo "$ver" | perl -pe 's|.*?(\d+)\.\d+(\.\d+)*.*$|$1.x.x|')"
					# == $cmd_version ]] ; then
					continue
				fi

				current_version=$(echo "${cmd_version}" | perl -pe 's|.*?(\d+\.\d+(\.\d+)*).*|$1|')
				if [[ -z ${current_version} || $(echo ${current_version} | egrep '[^0-9\.]') ]]; then
					errors="This Genesis deployment requires ${cmd} version ${ver}, but the current version could not be parsed\n${errors}"
					continue
				fi

				if ! version_checker ${current_version} ${ver}; then
					errors="This Genesis deployment requires ${cmd} version ${ver} (found ${current_version})\n${errors}"
					continue
				fi
			fi
		done < ${DEPLOYMENT_ROOT}/.genesis_deps
		if [[ -n ${errors} ]]; then
			echo -e ${errors}
			exit 1
		fi
	fi

	# What type of deployment is this?
	#
	#    normal    - A normal BOSH deployment
	#    bosh-init - A bosh-init BOSH deployment
	#
	DEPLOYMENT_TYPE=normal
	if [[ -f "${DEPLOYMENT_ROOT}/.deployment" ]]; then
		DEPLOYMENT_TYPE=$(cat "${DEPLOYMENT_ROOT}/.deployment")
	fi

	case ${DEPLOYMENT_TYPE} in
	(bosh) DEPLOYMENT_TYPE=bosh-init ;;
	(normal|bosh-init) ;;
	(*) echo >&2 "Unrecognized deployment type: ${DEPLOYMENT_TYPE}"
	    exit 3 ;;
	esac

	DEPLOYMENT_SITE=""
	DEPLOYMENT_ENVIRONMENT=""

	local relpath=${PWD##$DEPLOYMENT_ROOT/}
	if [[ ${relpath#global} == ${relpath} ]]; then
		# not in /global
		local site=${relpath%%/*}
		if [[ -n ${site} && -d "${DEPLOYMENT_ROOT}/${site}" && -d "${DEPLOYMENT_ROOT}/${site}/site" ]]; then
			DEPLOYMENT_SITE=${site}

			relpath=${relpath#$site/}
			local env=${relpath%%/*}
			if [[ -n ${env} && ${env} != "site" && -d "${DEPLOYMENT_ROOT}/${site}/${env}" ]]; then
				DEPLOYMENT_ENVIRONMENT=${env}
				if [[ -f "${DEPLOYMENT_ROOT}/${site}/${env}/.type" ]]; then
					DEPLOYMENT_TYPE=$(cat "${DEPLOYMENT_ROOT}/${site}/${env}/.type")
				fi
			fi
		fi
	fi

	SPRUCE_OPTS=""
	if [[ -n "${SPRUCE_TRACE}" ]]; then
		SPRUCE_OPTS="--debug --trace"
	elif [[ -n "${SPRUCE_DEBUG}" ]]; then
		SPRUCE_OPTS="--debug"
	fi

	DEPLOYMENT_NAME="${DEPLOYMENT_ROOT##*/}"
	DEPLOYMENT_NAME="${DEPLOYMENT_NAME%%-deployment*}"
	DEPLOYMENT_SITE_DIR="${DEPLOYMENT_ROOT}/${DEPLOYMENT_SITE}"
	DEPLOYMENT_ENV_DIR="${DEPLOYMENT_ROOT}/${DEPLOYMENT_SITE}/${DEPLOYMENT_ENVIRONMENT}"
}

actual_yaml_files() {
	while (($#)) ; do
		[[ -f "$1" ]] && echo $1
		shift
	done
}

ensure_yaml_file() {
	local path=${1:?ensure_yaml_file() - no path given}
	if [[ ! -s $path ]]; then
		echo "--- {}" > $path
	fi
}

ensure_ci_configuration() {
	ensure_yaml_file $(ci_pipeline_yaml)
}

ALL_VAULTED=""
need_a_vault() {
	if [[ -z ${ALL_VAULTED} ]]; then
		ALL_VAULTED=yes
		if [[ -n ${VAULT_ADDR} ]]; then
			echo "Authenticating to Vault at ${VAULT_ADDR}"
			if [[ -z $(command -v vault) ]]; then
				echo >&2 "\`vault' command not found in your \$PATH"
				echo >&2 "  ($PATH)"
				echo >&2 "You may need to install Vault in your task image"
				exit 1
			fi
			echo

			if [[ -n ${CI_SITE_ENV} ]]; then
				touch      ~/.vault
				chmod 0400 ~/.vault

				if [[ ${VAULT_SKIP_VERIFY} == '1' ]]; then
					skip_verify='-k'
				fi
				creds='{"user_id":"'${CI_VAULT_USER_ID:-generic-deployment-generic-userpipeline}'","app_id":"'${CI_VAULT_APP_ID:-concourse}'"}'
				if ! curl ${skip_verify} -Ls ${VAULT_ADDR}/v1/auth/app-id/login --data "${creds}" > ~/.vault; then
					echo >&2 "Failed to authenticate to the Vault app-id backend:"
					cat >&2 ~/.vault
					exit 2
				fi

				export VAULT_TOKEN=$(cat ~/.vault | jq -r '.auth.client_token')
				rm ~/.vault
				if ! vault status; then
					echo >&2 "Failed to authenticate to Vault at ${VAULT_ADDR}; bailing..."
					exit 2
				fi
			fi

			echo
			echo "Testing Vault authentication by retrieving secret/handshake"
			if ! vault read secret/handshake; then
				echo >&2 "Failed to retrieve secret/handshake; assuming authentication failed..."
				exit 3
			fi
			echo

		else
			echo >&2 "No VAULT_ADDR found in environment; skipping authentication step"
		fi
	fi
}

ask_bosh() {
	local url=$1

	need_a_workdir
	file="${WORKDIR}/bosh.$(echo "${url}" | checksum | awk '{print $1}')"
	if [[ ! -f ${file} ]]; then
		need_a_bosh
		curl -Lks -u "${DIRECTOR_CREDS}" "${DIRECTOR_URL}/${url}" > ${file}
	fi
	cat ${file}
}

need_a_bosh() {
	setup
	if [[ -n ${DIRECTOR_URL} ]]; then
		return
	fi

	# Interrogate bosh_config for director-y things
	if [[ -f ~/.bosh_config ]]; then
		DIRECTOR_URL=$(spruce json ~/.bosh_config | jq -r .target)
		DIRECTOR_CREDS=$(spruce json ~/.bosh_config | jq -r '.auth[.target].username + ":" + .auth[.target].password')
		DIRECTOR_UUID=$(curl -m${DIRECTOR_TIMEOUT:-3} -Lks -u "${DIRECTOR_CREDS}" ${DIRECTOR_URL}/info | jq -r .uuid)
	fi
}


####################################################
# checks and validating functions

need_command() {
	local cmd=${1:?need_command() - no command name given}

	if [[ ! -x "$(command -v $cmd)" ]]; then
		echo >&2 "${cmd} is not installed."
		if [[ "${cmd}" == "spruce" ]]; then
			echo >&2 "Please download it from https://github.com/geofffranks/spruce/releases"
		fi
		exit 2
	fi
}

check_site_name() {
	local site=${1:?check_site_name() - no site name provided}

	cleaned=$(echo -n ${site} | sed -e 's/[^a-z0-9_-]//')
	if [[ ${cleaned} != ${site} ]]; then
		echo >&2 "Error: Site name '${site}' contains invalid characters"
		exit 2
	fi
}

check_environment_name() {
	local env=${1:?check_environment_name() - no env name provided}

	case ${env} in
	(site|global)
		echo >&2 "Error: Environment name '${env}' is reserved"
		exit 2
		;;
	esac

	cleaned=$(echo -n ${env} | sed -e 's/[^a-z0-9_-]//')
	if [[ ${cleaned} != ${env} ]]; then
		echo >&2 "Error: Environment name '${env}' contains invalid characters"
		exit 2
	fi
}

must_be_in_a_site() {
	setup
	if [[ -z ${DEPLOYMENT_SITE} ]]; then
		echo >&2 "Error: Must be in a site directory to run this command"
		exit 2
	fi
}

must_be_in_an_environment() {
	setup
	if [[ -z ${DEPLOYMENT_ENVIRONMENT} ]]; then
		echo >&2 "Error: must be in an environment directory to run this command"
		exit 2
	fi
}

####################################################
# helper functions

env_root() {
	site=${1:?env_root() - No site given}
	name=${2:?env_root() - No environment given}

	setup
	echo "${DEPLOYMENT_ROOT}/${site}/${name}"
}

switch_to() {
	local site=${1}
	local name=${2}

	if [[ -z ${site} ]]; then
		cd ${DEPLOYMENT_ROOT}/global
	elif [[ -z ${name} ]]; then
		cd ${DEPLOYMENT_ROOT}/${site}/site
	else
		cd ${DEPLOYMENT_ROOT}/${site}/${name}
	fi

	unset DEPLOYMENT_ROOT
	setup
}

create_makefile() {
	path=${1:?create_makefile() - No path given}

	cat > ${path} <<EOF
# genesis, available at ${CANON_REPO}

save_VAULT_ADDR := \$(VAULT_ADDR)
VAULT_ADDR =
REDACT = yes

root_path := \$(realpath \$(dir \$(abspath \$(lastword \$(MAKEFILE_LIST))))../..)
ifdef USE_SYSTEM_GENESIS
	PATH := \$(PATH)
else
	PATH := \$(root_path)/bin:\$(PATH)
endif

help: check
	@PATH=\$(PATH) genesis help --concept Makefiles

version:
	@PATH=\$(PATH) echo "using \$\$(which genesis)"
	@PATH=\$(PATH) genesis version

manifest: check
	@REDACT=yes PATH=\$(PATH) genesis build

deploy: check
	@REDACT= VAULT_ADDR=\$(save_VAULT_ADDR) PATH=\$(PATH) genesis deploy

refresh: check
	@PATH=\$(PATH) genesis refresh

check:
	@PATH=\$(PATH) genesis ping >/dev/null 2>&1 || (echo >&2 "You need to install Genesis first (see ${CANON_REPO})" && exit 1)

.PHONY: help check manifest deploy refresh version
EOF
}

create_root_readme() {
	cat <<EOF
${DEPLOYMENT_NAME} Deployments
==============================

This repository contains the YAML templates that make up a series of
${DEPLOYMENT_NAME} BOSH deployments, using the format prescribed by the
[Genesis][1] utility.

The configuration is broken up into three logical strata: _global_,
_site_, and _environment_.  _Global_ defines the universal aspects of any
deployment, including overall job structure, constituent BOSH releases,
and invariant (or default) properties.  Each _site_ represents a single
IaaS (an AWS VPC, a vSphere cluster, etc.), and further refines the global
configuration for that infrastructure.  Each _environment_ represents a
single BOSH deployment, with specific network numbering, credentials,
domain names, etc.

For more information, see the READMEs scattered throughout this repository,
and check out \`genesis help\`.  You can download the Genesis program from
[Github][1]

Quickstart
----------

To create a new site:

    genesis new site NAME

To create a new environment

    cd site-name/
    genesis new environment NAME

To build the full BOSH manifest for an environment:

    cd site-name/env-name
    make manifest

... and then deploy it:

    cd site-name/env-name
    make deploy




[1]: ${CANON_REPO}
EOF
}

create_global_readme() {
	case ${DEPLOYMENT_TYPE} in
	(normal) # {{{
		cat <<EOF
Global Definitions

This directory contains templates that describe the common elements of this
deployment, to be shared (and possibly overridden) by sites and environments.
The templates are merged in the following order:

  global/jobs.yml             Specify what jobs will make up the canonical
                              deployment, and what templates to apply to them.

  global/deployment.yml       Define the global structure of all deployments
                              with the correct param calls to remind template
                              writers to override the correct things.

  global/properties.yml       Define the properties (global or per-job) for this
                              deployment.


NOTE: If you make changes to the templates in here, they will automatically
propagate to any newly-created environments, but you will need to run a
refresh for existing environments to receive those updates.
EOF
		;; # }}}
	(bosh-init) # {{{
		cat <<EOF
Global Definitions

This directory contains templates that describe the common elements of BOSH
deployments, to be shared (and possibly overridden) by sites and environments.
The templates are merged in the following order:

  global/jobs.yml             Specify what jobs will make up the BOSH deployment,
                              and what templates to apply to them.

  global/deployment.yml       Define the global structure of all BOSH deployments
                              with the correct param calls to remind template
                              writers to override the correct things.

  global/properties.yml       Define the properties (global or per-job) for the
                              BOSH deployment.


NOTE: If you make changes to the templates in here, they will automatically
propagate to any newly-created environments, but you will need to run a
refresh for existing environments to receive those updates.
EOF
		;; # }}}
	esac
}

create_site_readme() {
	local site=${1:?create_site_readme() - no site given}

	case ${DEPLOYMENT_TYPE} in
	(normal) # {{{
		cat <<EOF
Site Definitions (${site})

This directory contains templates that describe the infrastructure-specific
settings and site-wide properties.  The templates are merged in the following order:

  site/disk-pools.yml         If you need to, you can put disk pool
                              definitions in this file.

  site/update.yml             Specify job update parameters here, which can
                              change based on the cloud provider in use,
                              and its performance characteristics.

  site/jobs.yml               Here you can modify the list of jobs defined
                              at the global level, remove jobs (by setting
                              their instances: count to 0), and supply any
                              additional, site-wide job properties.

  site/networks.yml           Define what networks to use for all the
                              environments in this site (although you may
                              want to defer the actual numbering to the
                              environment level.

  site/resource-pools.yml     Set up the resource pools to use for job
                              virtual machines, and apply their cloud
                              properties (i.e. availability zones)

  site/properties.yml         Define properties (both globally and per-job),
                              that are specific to this environment.  These will
                              most likely override global properties.


NOTE: If you make changes to the templates in here, they will automatically
propagate to any newly-created environments, but you will need to run a
refresh for existing environments to receive those updates.
EOF
		;; # }}}
	(bosh-init) # {{{
		cat <<EOF
Site Definitions (${site})

This directory contains templates that describe the infrastructure-specific
settings and site-wide properties.  The templates are merged in the following order:

  site/disk-pools.yml         If you need to, you can put disk pool
                              definitions in this file.

  site/jobs.yml               Here you can modify the list of jobs defined
                              at the global level, remove jobs (by setting
                              their instances: count to 0), and supply any
                              additional, site-wide job properties.

  site/networks.yml           Define what networks to use for all the
                              environments in this site (although you may
                              want to defer the actual numbering to the
                              environment level.

  site/resource-pools.yml     Set up the resource pools to use for job
                              virtual machines, and apply their cloud
                              properties (i.e. availability zones)

  site/properties.yml         Define properties (both globally and per-job),
                              that are specific to this environment.  These will
                              most likely override global properties.


NOTE: If you make changes to the templates in here, they will automatically
propagate to any newly-created environments, but you will need to run a
refresh for existing environments to receive those updates.
EOF
# site/README
		;; # }}}
	esac
}

create_environment_readme() {
	local site=${1:?create_environment_readme() - no site given}
	local name=${2:?create_environment_readme() - no environment given}

	case ${DEPLOYMENT_TYPE} in
	(normal) # {{{
		cat <<EOF
Environment Definitions (${site}/${name})

This directory contains templates that describe the environment-specific
settings of a single deployment.  These templates will be combined with
the global and site templates to produce a single BOSH manifest for deployment
purposes.  The templates are merged in the following order:

  monitoring.yml              Configure whatever (external) monitoring system you
                              want to track the performance and health of your
                              deployment.

  networking.yml              Configure the network numbering for this deployment.

  director.yml                Identify the BOSH director UUID for this deployment.

  scaling.yml                 Define the scaling properties for this deployment,
                              including things like the number of instances, sizes
                              of persistent disks, resource pool limits, etc.

  properties.yml              Define properties (both globally and per-job),
                              that are specific to this environment.  These will
                              most likely override global and site properties.

  credentials.yml             Define passwords and credentials here, so that they
                              are centralized.  Keep in mind that commiting these
                              into version control incurs some security risk.

  cloudfoundry.yml            For deployments that integrate with Cloud Foundry
                              installations (i.e. as service brokers), you can
                              specify the integration details here, including
                              things like the CF API, credentials, domains, etc.

  name.yml                    Specify the name of this deployment.


This directory also contains a Makefile that makes it easier to build
the final BOSH manifest from all of the constituent templates.
Run \`make' to see some help, or \`make manifest' to just rebuild.
EOF
		;; # }}}
	(bosh-init) # {{{
		cat <<EOF
Environment Definitions (${site}/${name})

This directory contains templates that describe the environment-specific
settings of a single bosh-init deployment.  These templates will be combined
with the global and site templates to produce a single manifest suitable for
deployment via \`bosh-init'.  The templates are merged in the following order:

  networking.yml              Configure the network numbering for this BOSH.

  properties.yml              Define properties (both globally and per-job),
                              that are specific to this environment.  These will
                              most likely override global and site properties.

  credentials.yml             Define passwords and credentials here, so that they
                              are centralized.  Keep in mind that commiting these
                              into version control incurs some security risk.

  name.yml                    Specify the name of this deployment.


This directory also contains a Makefile that makes it easier to build
the final manifest from all of the constituent templates.
Run \`make' to see some help, or \`make manifest' to just rebuild.
EOF
		;; # }}}
	esac
}

create_deployment() {
	setup
	mkdir -p ${DEPLOYMENT_ROOT}/global
	mkdir -p ${DEPLOYMENT_ROOT}/global/releases

	create_root_readme   >${DEPLOYMENT_ROOT}/README.md
	create_global_readme >${DEPLOYMENT_ROOT}/global/README

	cat > ${DEPLOYMENT_ROOT}/global/deployment.yml <<EOF
---
name: (( param "Please define the deployment name in the environment templates" ))

resource_pools: (( param "Please define one or more resource pools for your BOSH deployment" ))
disk_pools:     (( param "Please define one or more disk pools for your BOSH deployment" ))
networks:       (( param "Please define one or more networks for your BOSH deployment" ))

update:
  canaries: 1
  max_in_flight: 1
  serial: true
EOF
	for file in jobs properties; do
		cat > ${DEPLOYMENT_ROOT}/global/${file}.yml <<EOF
--- {}
EOF
	done
}

refresh_global() {
	setup
	local site=${1:?refresh_global() - no site given}
	local env=${2:?refresh_global() - no environment given}
	local root="${DEPLOYMENT_ROOT}/${site}/${env}"

	local saved=0
	if [[ -d ${root}/.global ]]; then
		saved=1
		mv ${root}/.global ${root}/.global.old
	fi

	cp -a ${DEPLOYMENT_ROOT}/global ${root}/.global
	if [[ $? != 0 ]]; then
		if [[ ${saved} == 1 ]]; then
			mv ${root}/.global.old ${root}/.global
		fi
		echo >&2 "Error: failed to refresh global for ${site}/${env}"
		exit 2
	fi

	rm -fr ${root}/.global.old
}

create_site() {
	setup
	local site=${1:?create_site() - no site provided}

	check_site_name ${site}

	mkdir -p ${DEPLOYMENT_ROOT}/${site}
	mkdir -p ${DEPLOYMENT_ROOT}/${site}/site
	mkdir -p ${DEPLOYMENT_ROOT}/${site}/site/stemcell

	create_site_readme ${site} >${DEPLOYMENT_ROOT}/${site}/site/README

	cat > ${DEPLOYMENT_ROOT}/${site}/site/disk-pools.yml <<EOF
---
disk_pools: []
EOF
	cat > ${DEPLOYMENT_ROOT}/${site}/site/update.yml <<EOF
---
update:
  canary_watch_time: 1000-60000
  update_watch_time: 1000-60000
  max_in_flight: 1
EOF
	for file in networks resource-pools jobs properties; do
		cat > ${DEPLOYMENT_ROOT}/${site}/site/${file}.yml <<EOF
--- {}
EOF
	done

	(cd ${DEPLOYMENT_ROOT}/global/releases ; ls -1) > ${DEPLOYMENT_ROOT}/${site}/site/releases
}

refresh_site() {
	setup
	local site=${1:?refresh_site() - no site given}
	local env=${2:?refresh_site() - no environment given}
	local root="${DEPLOYMENT_ROOT}/${site}/${env}"

	local saved=0
	if [[ -d ${root}/.site ]]; then
		saved=1
		mv ${root}/.site ${root}/.site.old
	fi

	cp -a ${DEPLOYMENT_ROOT}/${site}/site ${root}/.site
	if [[ $? != 0 ]]; then
		if [[ ${saved} == 1 ]]; then
			mv ${root}/.site.old ${root}/.site
		fi
		echo >&2 "Error: failed to refresh site for ${site}/${env}"
		exit 2
	fi

	rm -fr ${root}/.site.old
}

run_env_hooks() {
	if [[ -d ${DEPLOYMENT_ROOT}/.env_hooks ]]; then
		for file in ${DEPLOYMENT_ROOT}/.env_hooks/*; do
			if [[ -f ${file} && -x ${file} ]]; then
				export VAULT_PREFIX DEPLOYMENT_NAME DEPLOYMENT_SITE DEPLOYMENT_ENVIRONMENT DEPLOYMENT_ROOT ENVIRONMENT_ROOT
				if ! ${file}; then
					echo
					echo
					echo "env_hook '${file##*/}' bailed (exit ${?})."
					echo "Tearing down ${DEPLOYMENT_SITE}/${DEPLOYMENT_ENVIRONMENT} environment..."
					rm -rf ${ENVIRONMENT_ROOT}
					exit 1
				fi
			fi
		done
	fi
}

create_normal_environment() {
	setup
	local site=${1:?create_normal_environment() - no site provided}
	local name=${2:?create_normal_environment() - no environment name provided}
	local root=$(env_root ${site} ${name})

	check_site_name ${site}
	check_environment_name ${name}

	if [[ ! -d "${DEPLOYMENT_ROOT}/${site}" ]]; then
		create_site ${site}
	fi

	mkdir -p ${root}
	create_makefile ${root}/Makefile
	create_environment_readme ${site} ${name} >${root}/README

	for file in cloudfoundry credentials director monitoring properties networking scaling; do
		cat > ${root}/${file}.yml <<EOF
--- {}
EOF
	done

	need_a_bosh
	if [[ -n ${DIRECTOR_UUID} ]]; then
		cat <<EOF > ${root}/director.yml
---
director_uuid: ${DIRECTOR_UUID}
EOF
	fi

	VAULT_PREFIX=secret/${site}/${name}/${DEPLOYMENT_NAME}
	DEPLOYMENT_SITE=${site}
	DEPLOYMENT_ENVIRONMENT=${name}
	ENVIRONMENT_ROOT=${DEPLOYMENT_ROOT}/${DEPLOYMENT_SITE}/${DEPLOYMENT_ENVIRONMENT}

	cat <<EOF > ${root}/name.yml
---
name: ${site}-${name}-${DEPLOYMENT_NAME}
meta:
  type: ${DEPLOYMENT_NAME}
  site: ${site}
  env:  ${name}
  vault_prefix: ${VAULT_PREFIX}
EOF

	run_env_hooks

	refresh_global ${site} ${name}
	refresh_site   ${site} ${name}

	if [[ -n $HAVE_TREE ]]; then
		echo "Created environment ${site}/${name}:"
		tree ${root}
	else
		echo "Created environment ${site}/${name}"
	fi
	echo
	echo
}

create_bosh_init_environment() {
	setup
	local site=${1:?create_bosh_init_environment() - no site provided}
	local name=${2:?create_bosh_init_environment() - no environment name provided}
	local root=$(env_root ${site} ${name})

	check_site_name ${site}
	check_environment_name ${name}

	if [[ ! -d "${DEPLOYMENT_ROOT}/${site}" ]]; then
		create_site ${site}
	fi

	mkdir -p ${root}
	create_makefile ${root}/Makefile
	create_environment_readme ${site} ${name} >${root}/README

	for file in credentials name properties networking; do
		cat > ${root}/${file}.yml <<EOF
--- {}
EOF
	done

	VAULT_PREFIX=secret/${site}/${name}/${DEPLOYMENT_NAME}
	DEPLOYMENT_SITE=${site}
	DEPLOYMENT_ENVIRONMENT=${name}
	ENVIRONMENT_ROOT=${DEPLOYMENT_ROOT}/${DEPLOYMENT_SITE}/${DEPLOYMENT_ENVIRONMENT}

	cat <<EOF > ${root}/name.yml
---
name: ${site}-${name}-${DEPLOYMENT_NAME}
meta:
  type: ${DEPLOYMENT_NAME}
  site: ${site}
  env:  ${name}
  vault_prefix: ${VAULT_PREFIX}
EOF

	run_env_hooks

	refresh_global ${site} ${name}
	refresh_site   ${site} ${name}

	if [[ -n $HAVE_TREE ]]; then
		echo "Created environment ${site}/${env}:"
		tree ${root}
	else
		echo "Created environment ${site}/${env}"
	fi
	echo
	echo
}

releases_from() {
	local file=${1:?releases_from() - file not provided}
	cat ${file} | sed 's/\s*#.*//'
}

releases_for_site() {
	setup
	local site=${1:?releases_for_environment() - no site name provided}

	releases_from "${DEPLOYMENT_ROOT}/${site}/site/releases"
}

releases_for_environment() {
	setup
	local site=${1:?releases_for_environment() - no site name provided}
	local name=${2:?releases_for_environment() - no environment name provided}

	releases_from "${DEPLOYMENT_ROOT}/${site}/${name}/.site/releases"
}

preflight_deployment() {
	if [[ -n ${DEPLOYMENT_OK} ]]; then
		return
	fi

	must_be_in_an_environment
	case ${DEPLOYMENT_TYPE} in
	(normal)    preflight_normal_deployment    ;;
	(bosh-init) preflight_bosh_init_deployment ;;
	esac
	DEPLOYMENT_OK=yes
}

skip_preflight() {
	DEPLOYMENT_OK=skipped
}

preflight_normal_deployment() {
	local stemcell_dir="${DEPLOYMENT_ENV_DIR}/.site/stemcell"
	if [[ ! -f "${stemcell_dir}/version" ]]; then
		echo >&2 "Error: no stemcell version specified for site"
		exit 2
	fi
	local stemcell_version=$(cat "${stemcell_dir}/version")
	if [[ ${stemcell_version} == "latest" ]]; then
		rm -f ${stemcell_dir}/url
		rm -f ${stemcell_dir}/sha1
	fi
	if [[ -f "${stemcell_dir}/alias" ]]; then
		if [[ ! -f "${stemcell_dir}/os" && ! -f "${stemcell_dir}/name" ]] ; then
			echo >&2 "Error: no stemcell os or name specified for site"
			exit 2
		fi
		# TODO: do we need to ensure cloud config knows about this alias?
	fi

	if [[ -f "${stemcell_dir}/name" ]]; then
		local stemcell_name=$(cat "${stemcell_dir}/name")
		ensure_present stemcell ${stemcell_name} ${stemcell_version}
	else
		echo >&2 "Error: no stemcell name or alias specified for site"
		exit 2
	fi

	if [[ ! -f "${DEPLOYMENT_ENV_DIR}/.site/releases" ]]; then
		echo >&2 "Error: no releases listed for site"
		exit 2
	fi
	local releases=$(releases_from "${DEPLOYMENT_ENV_DIR}/.site/releases")

	local rel_dir="${DEPLOYMENT_ENV_DIR}/.global/releases"
	for rel in ${releases}; do
		if [[ ! -d "${rel_dir}/${rel}" ]]; then
			echo >&2 "Error: release '${rel}' not defined globally"
			exit 2
		fi
		if [[ ! -f "${rel_dir}/${rel}/version" ]]; then
			echo >&2 "Error: no version specified for release '${rel}'"
			exit 2
		fi

		local release_version=$(cat ${rel_dir}/${rel}/version)
		if [[ ${release_version} == "latest" ]]; then
			rm -f ${rel_dir}/${rel}/url
			rm -f ${rel_dir}/${rel}/sha1
		fi
		ensure_present release ${rel} ${release_version}
	done
}

normal_site_metadata() {
	must_be_in_an_environment
	preflight_deployment

	cat <<EOF
---
meta:
  stemcell:
EOF

	# Stemcell bits (presence of required values confirmed in preflight_normal_deployment)
	for item in "alias" "name" "version" "url" "sha1" ; do
		local _file="${DEPLOYMENT_ENV_DIR}/.site/stemcell/${item}"
		[[ -f $_file ]] && echo "    $item: "'"'"$(cat $_file | head -n1 | sed 's/"/\\"/g')"'"'
	done
	echo 'update: (( param "Please specify update settings for your bosh deployment" ))'

	# Release bits
	echo "releases:"
	local releases=$(releases_from "${DEPLOYMENT_ENV_DIR}/.site/releases")
	for rel in ${releases}; do
		echo "  - name: ${rel}"
		for item in "version" "url" "sha1" ; do
			local _file="${DEPLOYMENT_ENV_DIR}/.global/releases/${rel}/${item}"
			[[ -f $_file ]] && echo "    $item: "'"'"$(cat $_file | head -n1 | sed 's/"/\\"/g')"'"'
		done
	done
	return 0
}

build_manifest() {
	must_be_in_an_environment
	need_command spruce
	preflight_deployment

	case ${DEPLOYMENT_TYPE} in
	(normal)
		normal_site_metadata > ${DEPLOYMENT_ENV_DIR}/.begin.yml || exit 2
		PRUNES="--prune meta --prune cloud_provider"
		;;
	(bosh-init)
		bosh_init_site_metadata > ${DEPLOYMENT_ENV_DIR}/.begin.yml || exit 2
		PRUNES="--prune meta --prune update"
		;;
	esac
	(cd ${DEPLOYMENT_ENV_DIR}
	 spruce $SPRUCE_OPTS merge ${PRUNES} \
	    .begin.yml \
	    $(actual_yaml_files \
	        .begin.yml \
	        \
	        .global/jobs.yml \
	        .global/deployment.yml \
	        .global/properties.yml \
	        \
	        .site/disk-pools.yml \
	        .site/update.yml \
	        .site/jobs.yml \
	        .site/networks.yml \
	        .site/resource-pools.yml \
	        .site/properties.yml \
	        \
	        monitoring.yml \
	        networking.yml \
	        director.yml \
	        scaling.yml \
	        properties.yml \
	        credentials.yml \
	        cloudfoundry.yml \
	        name.yml))

	rc=$?

	rm -f ${DEPLOYMENT_ENV_DIR}/.begin.yml

	if [[ $rc != 0 ]]; then
		echo >&2 "Failed to merge templates; bailing..."
		exit 5
	fi
}

have_blob() {
	local type=$1; shift
	local name=$1; shift
	local version=$1; shift

	need_a_bosh
	need_a_workdir
	ask_bosh /releases  > ${WORKDIR}/bosh.releases
	ask_bosh /stemcells > ${WORKDIR}/bosh.stemcells
	if [[ -n ${DIRECTOR_UUID} ]]; then
		case "${version}/${type}" in
		(latest/release)
			test -n "$(jq <${WORKDIR}/bosh.releases -r '.[]| select(.name == "'${name}'") | "ok"')"
			return $?
			;;

		(latest/stemcell)
			test -n "$(jq <${WORKDIR}/bosh.stemcells -r '.[]| select(.name == "'${name}'") | "ok"')"
			return $?
			;;

		(*/release)
			test -n "$(jq <${WORKDIR}/bosh.releases -r '.[] | select(.name == "'${name}'") | .release_versions[] | select(.version == "'${version}'") | "ok"')"
			return $?
			;;

		(*/stemcell)
			test -n "$(jq <${WORKDIR}/bosh.stemcells -r '.[]| select(.name == "'${name}'") | select(.version == "'${version}'") | "ok"')"
			return $?
			;;

		(*)
			echo >&2 "Error: Invalid type. This is a bug. Got ${type} but expected 'stemcell' or 'release'"
			exit 2
			;;
		esac
	else
		echo >&2 "Error: Could not contact your BOSH director to find release / stemcell information"
		exit 2
	fi
}

ensure_present() {
	local type=$1; shift
	local name=$1; shift
	local version=$1; shift
	if [[ ${version} != "track" ]]; then
		if have_blob ${type} ${name} ${version}; then
			echo >&2 "Found ${type} ${name} ${version} on director"
			return 0
		else
			local root=""
			case ${type} in
			(stemcell)
				root=${DEPLOYMENT_ENV_DIR}/.site/stemcell
				;;
			(release)
				root=${DEPLOYMENT_ENV_DIR}/.global/releases/${name}
				;;
			(*)
				echo >&2 "Invalid type '${type}' given to check_index.  Please file a bug"
				exit 2
				;;
			esac

			# if sha1 + url are specified, let bosh handle the uploads
			if [[ ! -f ${root}/sha1 && ! -f ${root}/url ]]; then
				echo >&2 "Uploading ${type} ${name}/${version} as it is required, but not present"
				upload_blob ${type} ${name} ${version}
			fi
		fi
	else
		echo >&2 ${type} ${name} ${version} is set to track from the index
		check_index ${type} ${name} ${version}
	fi
}

upload_blob() {
	local type=$1; shift
	local name=$1; shift
	local version=$1; shift

	if [[ -z ${GENESIS_INDEX} ]]; then
		echo >&2 "Error: ${type} ${name}/${version} is not present on the BOSH director."
		echo >&2 "       Please either \`bosh upload ${type}\` manually, or enable the"
		echo >&2 "       Genesis index by setting the GENESIS_INDEX environment variable."
		exit 2
	fi

	need_a_workdir

	if [[ $version != "latest" ]]; then
		version="v/${version}"
	fi

	echo >&2 "  checking ${GENESIS_INDEX} for details on ${type} ${name}/${version}"
	if ! curl --fail -Lsk ${GENESIS_INDEX}/v1/${type}/${name}/${version} > ${WORKDIR}/index; then
		echo >&2 "Unable to upload ${type} ${name}/${version} - could not find details on Genesis index"
		echo >&2 "(at $GENESIS_INDEX)"
		exit 2
	fi

	url=$(jq -r ".url" <${WORKDIR}/index)
	if [[ -z ${url} ]]; then
		echo >&2 "No URL found in the Genesis index for ${type}/${name}/${version}"
		echo >&2 "(at $GENESIS_INDEX)"
		echo >&2 "Either upload the ${type} manually, or add ${name} to the Genesis index."
		exit 2
	fi

	desired_uuid=$(spruce json director.yml | jq -r '.director_uuid')
	current_uuid=$(bosh status --uuid)
	if [[ $desired_uuid != $current_uuid ]]; then
		echo >&2 "Director UUID mismatch detected. You do not appear to be targeting"
		echo >&2 "the director for this deployment (expected $desired_uuid, got $current_uuid)"
		exit 2
	fi
	echo >&2 "Could not find ${type} ${name}/${version} on the director, uploading it for you"
	if ! bosh upload "${type}" "${url}" >&2; then
		echo >&2 "Failed to upload ${type} ${name}/${version}. Bailing out"
		exit 2
	fi
}

preflight_bosh_init_deployment() {
	if [[ ! -f "${DEPLOYMENT_ENV_DIR}/.site/stemcell/name" ]]; then
		echo >&2 "Error: no stemcell name specified for site"
		exit 2
	fi
	local stemcell_name=$(cat "${DEPLOYMENT_ENV_DIR}/.site/stemcell/name")

	if [[ ! -f "${DEPLOYMENT_ENV_DIR}/.site/stemcell/version" ]]; then
		echo >&2 "Error: no stemcell version specified for site"
		exit 2
	fi
	local stemcell_version=$(cat "${DEPLOYMENT_ENV_DIR}/.site/stemcell/version")
	if [[ ${stemcell_version} == "latest" ]]; then
		echo >&2 "Error: bosh-init deployments cannot use 'latest' as a stemcell version"
		echo >&2 "       (you probably want 'track', so that Genesis uses the Index)"
		exit 2
	fi
	check_index stemcell ${stemcell_name} ${stemcell_version}

	if [[ ! -f "${DEPLOYMENT_ENV_DIR}/.site/stemcell/url" ]]; then
		echo >&2 "Error: no stemcell URL listed for site"
		exit 2
	fi
	local stemcell_url=$(cat "${DEPLOYMENT_ENV_DIR}/.site/stemcell/url")
	if [[ ! -f "${DEPLOYMENT_ENV_DIR}/.site/stemcell/sha1" ]]; then
		echo >&2 "Error: no stemcell sha1 listed for site"
		exit 2
	fi
	local stemcell_sha1=$(cat "${DEPLOYMENT_ENV_DIR}/.site/stemcell/sha1")

	if [[ ! -f "${DEPLOYMENT_ENV_DIR}/.site/releases" ]]; then
		echo >&2 "Error: no releases listed for site"
		exit 2
	fi
	local releases=$(releases_from "${DEPLOYMENT_ENV_DIR}/.site/releases")

	for rel in ${releases}; do
		if [[ ! -d "${DEPLOYMENT_ENV_DIR}/.global/releases/${rel}" ]]; then
			echo >&2 "Error: release '${rel}' not defined globally"
			exit 2
		fi
		if [[ ! -f "${DEPLOYMENT_ENV_DIR}/.global/releases/${rel}/version" ]]; then
			echo >&2 "Error: no version specified for release '${rel}'"
			exit 2
		fi

		local release_version=$(cat ${DEPLOYMENT_ENV_DIR}/.global/releases/${rel}/version)
		if [[ ${release_version} == "latest" ]]; then
			echo >&2 "Error: bosh-init deployments cannot use 'latest' as release versions [for ${rel}]"
			echo >&2 "       (you probably want 'track', so that Genesis uses the Index)"
			exit 2
		fi
		check_index release ${rel} ${release_version}

		if [[ ! -f "${DEPLOYMENT_ENV_DIR}/.global/releases/${rel}/url" ]]; then
			echo >&2 "Error: no url specified for '${rel}'"
			exit 2
		fi
		if [[ ! -f "${DEPLOYMENT_ENV_DIR}/.global/releases/${rel}/sha1" ]]; then
			url=$(cat "${DEPLOYMENT_ENV_DIR}/.global/releases/${rel}/url")
			echo >&2 "retrieving ${url}"
			sha1=$(curl -LSs "${url}" | checksum | sed -e 's/ .*//')
			if [[ -z "${sha1}" ]]; then
				echo >&2 "Error: failed to download and verify ${rel} release"
				echo >&2 "       (from $url)"
				exit 2
			fi
			echo "$sha1" > "${DEPLOYMENT_ENV_DIR}/.global/releases/${rel}/sha1"
		fi
	done
}

bosh_init_site_metadata() {
	must_be_in_an_environment
	preflight_deployment

	local stemcell_name=$(cat "${DEPLOYMENT_ENV_DIR}/.site/stemcell/name")
	local stemcell_url=$(cat "${DEPLOYMENT_ENV_DIR}/.site/stemcell/url")
	local stemcell_sha1=$(cat "${DEPLOYMENT_ENV_DIR}/.site/stemcell/sha1")
	cat <<EOF
---
meta:
  stemcell:
    url: ${stemcell_url}
    sha1: ${stemcell_sha1}

cloud_provider:
  template: (( param "Please define the Cloud Provider to use for your BOSH deployment" ))
  properties: (( param "Please define the configuration for your BOSH Cloud Provider" ))

releases:
EOF

	local releases=$(releases_from "${DEPLOYMENT_ENV_DIR}/.site/releases")
	for rel in ${releases}; do
		echo "  - name: ${rel}"
		echo "    url:  $(cat ${DEPLOYMENT_ENV_DIR}/.global/releases/${rel}/url)"
		echo "    sha1: $(cat ${DEPLOYMENT_ENV_DIR}/.global/releases/${rel}/sha1)"
	done
}

####################################################
# multi-call handlers

: <<'dox-command:version'
USAGE
@~include=usage

DESCRIPTION
	Displays the version and checksum of the genesis executable.

SEE ALSO
@~include=related{"items":["command:update","command:embed"]}
dox-command:version
cmd_version() {
	s=$(cat ${BASH_SOURCE[0]} | checksum)
	ver_str="genesis v${VERSION} (${s:0:12})"
	if [[ -n "$GENESIS_V2_VERSION" ]] ; then
		ver_str="${ver_str} - embedded in ${GENESIS_V2_VERSION}"
	fi
	echo "$ver_str"
	exit 0
}

: <<'dox-command:update'
USAGE
@~include=usage

DESCRIPTION
  Updates the version of the genesis executable to the latest release from the
  genesis repo.

SEE ALSO
@~include=related{"items":["command:version","command:embed"]}
dox-command:update
cmd_update() {
	if [[ -n "$GENESIS_V2_VERSION" ]] ; then
		echo >&2 "Cannot update the version of Genesis v1 embedded in Genesis v2."
		echo >&2 "Please update Genesis v2 to get the latest embedded v1 version."
		exit 1
	fi
	need_a_workdir
	curl -Ls $(curl -s ${API_REPO}/releases/latest | jq -r '.assets[] | select(.name | test("genesis")) | .browser_download_url') > ${WORKDIR}/bin
	chmod 0755 ${WORKDIR}/bin
	if ! ${WORKDIR}/bin ping >/dev/null 2>&1; then
		echo >&2 "Download failed / corrupt; NOT proceeding with update..."
		echo >&2 "sha1:$(checksum ${WORKDIR}/bin | awk '{print $1}')"
		${WORKDIR}/bin ping >&2
		exit 1
	fi
	cp ${WORKDIR}/bin $0
	exit $?
}

: <<'dox-command:embed'
USAGE
@~include=usage

DESCRIPTION
	Embeds the version of `genesis' installed in your $PATH into your deployment
	repo under /bin, so it can be used via the Makefile and Concourse tasks.
	This will replace any version already embedded.

SEE ALSO
@~include=related{"items":["command:version","command:update"]}
dox-command:embed
cmd_embed() {
  [[ -z $1 ]] || bad_usage_no_args

  echo "Embedding genesis script into repository"
  setup

  mkdir -p ${DEPLOYMENT_ROOT}/bin
  cp ${BASH_SOURCE[0]} ${DEPLOYMENT_ROOT}/bin/genesis
  chmod 755 ${DEPLOYMENT_ROOT}/bin/genesis

  ${DEPLOYMENT_ROOT}/bin/genesis version
}

: <<'dox-concept:Structure'
DESCRIPTION
  Genesis organizes the files used to build your manifests into logical
  locations based on hierarchial and functional scope.

  Each genesis-generated deployment repository contains the YAML templates that
  contain the details required to create the BOSH deployment manifest across
  one or more sites and environments.

  The configuration is broken up into three logical strata: global,
  site, and environment:

    global:
      Defines the universal aspects of any deployment, including overall job
      structure, constituent BOSH releases, and invariant (or default)
      properties.

    site:
      represents a single IaaS (an AWS VPC, a vSphere cluster, etc.), and
      further refines the global configuration for that infrastructure.

    environment:
      represents a single BOSH deployment, with specific network numbering,
      credentials, domain names, etc.

  Directory Structure
  -------------------

  <software>-deployments
  |-- README.md
  |-- bin
  |   `-- genesis
  |-- global
  |   |-- README
  |   |-- deployment.yml
  |   |-- jobs.yml
  |   |-- properties.yml
  |   `-- releases
  |       |-- <release-name-1>
  |       |   |-- sha1
  |       |   |-- url
  |       |   `-- version
  |       `-- <release-name-2>
  |           `-- version
  `-- <site-name-1>
      |-- <environment-name-1>
      |   |-- Makefile
      |   |-- README
      |   |-- cloudfoundry.yml
      |   |-- credentials.yml
      |   |-- director.yml
      |   |-- manifests
      |   |   `-- manifest.yml
      |   |-- monitoring.yml
      |   |-- name.yml
      |   |-- networking.yml
      |   |-- properties.yml
      |   `-- scaling.yml
      `-- site
          |-- README
          |-- disk-pools.yml
          |-- jobs.yml
          |-- networks.yml
          |-- properties.yml
          |-- releases
          |-- resource-pools.yml
          |-- stemcell
          |   |-- name
          |   `-- version
          `-- update.yml

  Global Definitions
  ------------------

  The `global` directory contains templates that describe the common elements
  of all deployments for this software, to be shared (and possibly overridden)
  by sites and environments.  The templates are merged in the following
  order:

    jobs.yml:       Specify what jobs will make up the canonical deployment,
                    and what templates to apply to them.

    deployment.yml: Define the global structure of all deployments with the
                    correct param calls to remind template writers to override
                    the correct things.

    properties.yml: Define the properties for this deployment.  This can be
                    done on a per-job basis, or under the top-level properties
                    key.

    releases:       This directory contains a directory for each release used
                    by the deployment.  These should not be modified by hand,
                    but instead using the `(add|set|use) release` commands. See
                    help for `Releases` for more information.

  NOTE:
    If you make changes to the templates in here, they will automatically
    propagate to any newly-created environments, but you will need to run a
    refresh for existing environments to receive those updates.

  Site Definitions
  ----------------

  All directories found at the root of the repository that themselves contain
  a directory called `site` are considered sites.  This is usually used to
  describe infrastructure-specific settings and site-wide properties, although
  you can have multiple sites that run under the same infrastructure.  The
  templates are merged in the following order:

    disk-pools.yml:     If you are using disk pools, put disk pool definitions
                        in this file.

    update.yml:         Specify job update parameters here, which can change
                        based on the cloud provider in use, and its performance
                        characteristics.

    jobs.yml:           Here you can modify the list of jobs defined at the
                        global level, remove jobs (by setting their instances:
                        count to 0), and supply any additional, site-wide job
                        properties.

    networks.yml:       Define what networks to use for all the environments in
                        this site (although you may want to defer the actual
                        numbering to the environment level.

    resource-pools.yml: Set up the resource pools to use for job virtual
                        machines, and apply their cloud properties (i.e.
                        availability zones)

    properties.yml:     Define properties (both globally and per-job), that are
                        specific to this environment.  These will most likely
                        override global properties.

  NOTE:
    If you make changes to the templates in here, they will automatically
    propagate to any newly-created environments, but you will need to run a
    refresh for existing environments to receive those updates.

  Environment Definitions
  -----------------------

  All other directories that are siblings to the `site` directory represent a
  single environment to be deployed.  Each one contains templates that describe
  the environment-specific settings of a single deployment.  These templates
  will be combined with the global and site templates to produce a single BOSH
  manifest for deployment purposes.  The templates are merged in the following
  order:

    monitoring.yml:   Configure whatever (external) monitoring system you want
                      to track the performance and health of your deployment.

    networking.yml:   Configure the network numbering for this deployment.

    director.yml:     Identify the BOSH director UUID for this deployment.

    scaling.yml:      Define the scaling properties for this deployment,
                      including things like the number of instances, sizes of
                      persistent disks, resource pool limits, etc.

    properties.yml:   Define properties (both globally and per-job), that are
                      specific to this environment.  These will most likely
                      override global and site properties.

    credentials.yml:  Define passwords and credentials here, so that they are
                      centralized.  Keep in mind that commiting these into
                      version control incurs some security risk.

    cloudfoundry.yml: For deployments that integrate with Cloud Foundry
                      installations (i.e. as service brokers), you can specify
                      the integration details here, including things like the
                      CF API, credentials, domains, etc.

    name.yml:         Specify the name of this deployment.

  This directory also contains a Makefile that makes it easier to build the
  final BOSH manifest from all of the constituent templates.  See help for
  `Makefiles`for more information.

COMMANDS
@~include=topic{"category":"command","scope":"structure","leader":"  <<SCRIPT_NAME>> ","desc":"inline"}

dox-concept:Structure

: <<'dox-concept:Structure-bosh-init'
DESCRIPTION
  Genesis can be used to create manifests that can standup a BOSH director
  using bosh-init.

	TODO:
	Explain the difference between normal and bosh-init structures, and how
	to build a bosh-init manifest and deploy it.
dox-concept:Structure-bosh-init

: <<'dox-partial:new'
DESCRIPTION
  Creates new things, with all the right files in all the right places.
dox-partial:new

: <<'dox-command:new-deployment'
USAGE
@~include=usage{"args":"[-t <type>] [-T <template>] [-r <dir>] <name>"}

DESCRIPTION
	Create a new deployment directory, with all the necessary files for deploying
	with Genesis.

	Specifying `--template' tells genesis to create your deployment directory
	based on the specified template repo.

OPTIONS
	-t, --type <type>
		Generate a different type of deployment.  Valid values are 'normal' and
		'bosh' (or 'bosh-init'). The default is 'normal'.

	-T, --template <name>
		Base the deployment off of an upstream Genesis template, by cloning a
		repository from github.com and using that.

		Templates can be specified as qualified name containing the Github org/user
		and repository name, i.e. "jhunt/bolo", or as a simple name, i.e. "shield",
		which will be inferred to belong to the starkandwayne organization.

	-r, --root <dirname>
		The root directory under which to create the new deployment structure.
		Defaults to the current directory.

ARGUMENTS
	name
		The name of the deployment to be created.  This will result in a directory
		called <name>-deployments

SEE ALSO
@~include=related{"items":["command:new site","command:new environment"]}

@~include=related{"items":["concept:Structure","concept:Structure bosh-init"]}

@~scope=common,structure
dox-command:new-deployment

cmd_new_deployment() {
	local dtype="normal"
	local root=$(pwd)
	local name=""
	local template=""

	while (( $# )); do
		arg=$1 ; shift
		case ${arg} in
		(-t|--type)
			check_opt_usage "$arg" "$1"
			dtype=$1
			shift
			;;
		(-T|--template)
			check_opt_usage "$arg" "$1"
			template=$1
			shift
			;;
		(-r|--root)
			check_opt_usage "$arg" "$1"
			root=$1
			shift
			;;
		(-*) bad_usage_invalid_opt "$arg" ;;
		(*)
			[[ -z $name ]] || bad_usage_extra "$arg" "name" "$name"
			name=${arg%-deployment*}
			;;
		esac
	done

	if [[ -n ${template} ]]; then
		if [[ ${template} != ?*/?* ]]; then
			template="starkandwayne/${template}"
		fi
		template="${template%%-deployment*}-deployment"

		if [[ -z ${name} ]]; then
			name=${template##*/}
			name=${name%%-deployment*}
		fi
	fi
	[[ -n ${name:-} ]] || bad_usage_missing "deployment name"

	if [[ ! -d ${root} ]]; then
		echo >&2 "Error: root directory ${root} does not exist"
		exit 1
	fi

	if [[ -d "${root}/${name}-deployments" ]]; then
		echo >&2 "Error: target directory ${root}/${name}-deployments already exists!"
		exit 1
	fi

	if [[ -n ${template} ]]; then
		local url=https://github.com/${template}
		set -e
		echo "cloning from template ${url}"
		git clone --origin upstream ${url} ${root}/${name}-deployments
		cd ${root}/${name}-deployments
		git config --remove-section branch.master

		cmd_embed
		git add bin/genesis

		create_root_readme   >README.md
		create_global_readme >global/README

		git add .
		git commit -m "Initial clone of templated ${name} deployment"
		exit 0
	fi

	case ${dtype} in
		(normal|bosh-init) ;;
		(bosh) dtype=bosh-init ;;
		(*)
			echo >&2 "Error: unrecognized deployment type '${dtype}'"
			exit 1
			;;
	esac

	DEPLOYMENT_TYPE=${dtype}
	DEPLOYMENT_NAME=${name}
	DEPLOYMENT_ROOT="${root}/${name}-deployments"
	mkdir ${DEPLOYMENT_ROOT}

	case ${DEPLOYMENT_TYPE} in
	(normal)
		echo "normal" > ${DEPLOYMENT_ROOT}/.deployment
		;;
	(bosh-init)
		echo "bosh-init" > ${DEPLOYMENT_ROOT}/.deployment
		;;
	esac
	create_deployment

	cmd_embed >/dev/null

	cat > ${DEPLOYMENT_ROOT}/.gitignore <<EOF
.begin.yml
.deploy.yml
EOF

	if git symbolic-ref HEAD 2>&1 | grep -qE 'fatal: Not a git repository|fatal: Unable to read current working directory'; then
		(cd ${DEPLOYMENT_ROOT}
		 git init
		 git add .
		 git commit -m "Initial commit of ${name}-deployments")
	fi
	exit 0
}

: <<'dox-command:new-site'
USAGE
@~include=usage{"args":"[-T <template>] <name>"}

DESCRIPTION
	Sets up the files and directories for a new site.

	When run, this command creates a new site with the given name, and set up the
	necessary directories and blank template files for defining the parts of a
	BOSH manifest that map to infrastructural and site-wide things.

	Specifying `--template' tells genesis to create the
	site directory based on the specified IaaS templates.

OPTIONS
	-T, --template <name>
		Base the new site off of a site template.  This generally only works if you
		generated the deployment from an upstream Genesis template (via
		'--template')

		See the `.templates' directory at the root of your
		deployment repo for valid options.

ARGUMENTS
	name
		The name of the site being created.  This is usually discriptive of a data
		center or cloud provider, such as `aws-us-east` or `myOrg-myDC-vsphere`

SEE ALSO
@~include=related{"items":["command:new deployment","command:new environment"]}

@~scope=common,structure
dox-command:new-site

cmd_new_site() {
	local name=""
	local template=""

	while (( $# )); do
		arg=$1 ; shift
		case ${arg} in
		(-T|--template)
			check_opt_usage "$arg" "$1"
			template=$1
			shift
			;;
		(-*)
			bad_usage_invalid_opt "$arg"
			;;
		(*)
			name=${arg}
			;;
		esac
	done
	[[ -n ${name} ]] || bad_usage_missing "site name"

	setup
	if [[ -d "${DEPLOYMENT_ROOT}/${name}" ]]; then
		echo "Site ${name} already exists"
		exit 0
	fi

	if [[ -n ${template} ]]; then
		if [[ ! -d ${DEPLOYMENT_ROOT}/.templates/${template} ]]; then
			echo >&2 "Site template '${template}' not found..."
			exit 2
		fi

		mkdir -p ${DEPLOYMENT_ROOT}/${name}
		cp -a ${DEPLOYMENT_ROOT}/.templates/${template} ${DEPLOYMENT_ROOT}/${name}/site
		create_site_readme ${name} >${DEPLOYMENT_ROOT}/${name}/README
		if [[ -n $HAVE_TREE ]]; then
			echo "Created site ${name} (from template ${template}):"
			tree "${DEPLOYMENT_ROOT}/${name}"
		else
			echo "Created site ${name} (from template ${template})"
		fi

	else
		create_site ${name}
		if [[ -n $HAVE_TREE ]]; then
			echo "Created site ${name}:"
			tree "${DEPLOYMENT_ROOT}/${name}"
		else
			echo "Created site ${name}"
		fi
	fi

	echo
	echo
	exit 0
}

: <<'dox-command:new-environment'
USAGE
@~include=usage{"args":"[-t <type>] <site> <name>","cmd":"new env[ironment]"}
@~alias=new-env

DESCRIPTION
	Set up the files and directories for a new environment.

	When run, this command creates a new environment with the given name, in the
	specified site, and set up the directories and template files for local,
	environment-specific things.

	Specifying `--type' of `bosh-init' will tell genesis to treat this specific
	environment as a bosh-init type deployment. Useful if you need to use
	bosh-init for some environments, but regular BOSH deployments for others.

OPTIONS
	-t, --type <type>
		Generate a different type of deployment.  Valid values are 'bosh-init' for
		a bosh-init environment, 'bosh' which is an abreviation for 'bosh-init',
		and 'normal' for standard bosh deployments (the default is 'normal') .

ARGUMENTS
	site (optional if in a site directory, required otherwise)
		The name of the site under which the environment is being created.
	name
		The name of the environment being created.  This is usually discriptive of
		a data center or cloud provider, such as `aws-us-east` or
		`myOrg-myDC-vsphere`

SEE ALSO
@~include=related{"items":["command:new deployment","command:new site"]}

@~scope=common,structure
dox-command:new-environment

cmd_new_environment() {
	local dtype site name
	while (( $# )); do
		arg=$1 ; shift
		case ${arg} in
		(-t|--type)
			check_opt_usage "$arg" "$1"
			dtype=$1
			case ${dtype} in
			(normal|bosh-init) ;;
			(bosh) dtype=bosh-init ;;
			(*) echo >&2 "unrecognized deployment type: ${dtype}"
			    exit 1 ;;
			esac
			shift
			;;
		(-*) bad_usage_invalid_opt "$arg" ;;
		(*)
			if [[ -z ${site} ]]; then
				site=${arg}
			elif [[ -z ${name} ]]; then
				name=${arg}
			else
				bad_usage_extra "$arg"
			fi
			;;
		esac
	done

	setup
	if [[ -n ${DEPLOYMENT_SITE} && -z ${name} ]]; then
		name=${site}
		site=${DEPLOYMENT_SITE}
	fi

	case ${dtype:-$DEPLOYMENT_TYPE} in
		(normal)    create_normal_environment ${site} ${name} ;;
		(bosh-init) create_bosh_init_environment ${site} ${name} ;;
	esac

	if [[ -n ${dtype} ]]; then
		echo ${dtype} > ${DEPLOYMENT_ROOT}/${site}/${name}/.type
	fi

	exit 0
}

check_index() {
	local type=${1:?check_index() - no type given}
	local name=${2:?check_index() - no name given}
	local version=${3:?check_index() - no version given}

	# if the caller wants "latest", that means latest
	# available on the BOSH director, so there's nothing
	# we can / should do about that.
	if [[ ${version} == "latest" ]]; then
		return
	fi

	local root=""
	case ${type} in
	(stemcell)
		root=${DEPLOYMENT_ENV_DIR}/.site/stemcell
		;;
	(release)
		root=${DEPLOYMENT_ENV_DIR}/.global/releases/${name}
		;;
	(*)
		echo >&2 "Invalid type '${type}' given to check_index.  Please file a bug"
		exit 2
		;;
	esac

	# if the operator wants us to track, but we are likewise
	# instructed not to contact the index, we should bail out
	if [[ -z ${GENESIS_INDEX} && ${version} == "track" ]]; then
		echo >&2 "Unable to check the Genesis Index for the latest version of ${type} ${name}!"
		echo >&2 "(GENESIS_INDEX environment variable is either not set, or"
		echo >&2 " set explicitly to 'no', disabling access to the Index)"
		exit 2
	fi

	if [[ -n ${GENESIS_INDEX} ]]; then
		need_a_workdir
		if [[ ${version} == "track" ]]; then
			echo >&2 "  checking ${GENESIS_INDEX} for details on latest ${type} ${name}"
			if ! curl --fail -Lsk ${GENESIS_INDEX}/v1/${type}/${name}/latest > ${WORKDIR}/index; then
				echo >&2 "Failed to access the Genesis Index"
				echo >&2 "(at $GENESIS_INDEX)"
				echo >&2 "Unable to track the latest version of ${type} ${name}"
				exit 2
			fi
		else
			echo >&2 "  checking ${GENESIS_INDEX} for details on ${type} ${name}/${version}"
			curl -Lsk ${GENESIS_INDEX}/v1/${type}/${name}/v/${version} > ${WORKDIR}/index
		fi

		for thing in url sha1 version; do
			v=$(jq -r ".${thing} // \"\"" <${WORKDIR}/index)
			if [[ -n ${v} ]]; then
				echo "${v}" > ${root}/${thing}
			fi
		done
	fi
}

: <<'dox-concept:Releases'
DESCRIPTION
	Genesis manages the association and uploading of the releases used by your
	deployment manifests.

	Deployment manifests require BOSH releases for the software they are
	deploying.  Typically, a deployment has one eponymous release, and usually a
	few support releases.  For example, concourse-deployment requires the
	concourse release as well as garden-runc, and may optionally include
	cf-haproxy, shield, slack-notification-resource and others.

	To add a release to the deployment, use the `genesis add release` command to
	provide the name and version.  The version can be upgraded using the `genesis
	set release` command.  This sets the release as available for any site and
	environment in the deployment repo.

	To enable a release for a site, use the `genesis use release <name>` command.
	Only a single version of a resource is supported across all sites that use it,
	but through global and site caching, the version can be locked down in an
	environment until it is ready to be upgraded to the latest available in the
	deployment repository.

AUTOMATIC UPLOAD TO BOSH
	Genesis uses an index for open-source BOSH releases so that if the version
	you specify is not available on the BOSH director, it will automatically be
	uploaded.  You can also set the version to 'track' to use the latest version
	of that release found in the Genesis index.  This index is maintained by
	Stark & Wayne, and regularly updates version availability.

	Alternatively, if you set the version to 'latest', it will use the latest
	version of that release ALREADY PRESENT on the BOSH director.  Of course,
	there has to be at least one version present, which would need to be uploaded
	manually prior to deploying the manifest.

COMMANDS
@~include=topic{"category":"command","scope":"releases","desc":"inline","leader":"  <<SCRIPT_NAME>> "}

SEE ALSO
@~include=topic{"category":"concept","partial":"Cached-Definitions","desc":"inline","leader":"  "}
@~include=topic{"category":"concept","partial":"CI","desc":"inline","leader":"  "}
@~scope=releases
dox-concept:Releases

: <<'dox-command:releases'
USAGE
@~include=usage{"args":"[<site> [<env>]]","cmd":"release[s]"}
@~alias=release

DESCRIPTION
	Lists the release name and version in use by the specified site or
	environment. If no arguments are specified, you must be in a site/environment
	directory.

ARGUMENTS
	site (optional)
		if this is the sole argument, the releases used by the named
		site will be displayed.  This is identical to the behaviour when run in
		a site directory with no arguments.

		Note: If in an environment directory, and just the site argument is
		supplied, it will display the releases for the environment of the same
		name as the current environment directory under the given site.

	env (optional)
		will show the releases used by the specified environment
		under the given site.  This is identical to if no arguments are given
		when run from an environment directory.

SEE ALSO
@~include=related{"items":["concept:Releases","command:add release","command:set release", "command:use release"]}
@~scope=common,releases
dox-command:releases
cmd_releases() {
	local site env
	while (( $# )); do
		arg=$1 ; shift
		case ${arg} in
		(-*) bad_usage_no_opts ;;
		(*)
			if [[ -z ${site} ]]; then  site=${arg}
			elif [[ -z ${env} ]]; then env=${arg}
			else bad_usage_extra "$arg"
			fi
			;;
		esac
	done

	setup
	site=${site:-$DEPLOYMENT_SITE}
	env=${env:-$DEPLOYMENT_ENVIRONMENT}

	if [[ -n ${env} ]]; then
		for rel in $(releases_for_environment ${site} ${env}); do
			vers=$(cat ${DEPLOYMENT_ROOT}/${site}/${env}/.global/releases/${rel}/version)
			printf "%s/%s\n" ${rel} ${vers}
		done
		return
	fi

	if [[ -n ${site} ]]; then
		for rel in $(releases_for_site ${site}); do
			vers=$(cat ${DEPLOYMENT_ROOT}/global/releases/${rel}/version)
			printf "%s/%s\n" ${rel} ${vers}
		done
		return
	fi

	bad_usage
	exit 1
}
: <<'dox-command:add-release'
USAGE
@~include=usage{"args":"<name> [<version> [<url>]]"}

DESCRIPTION
	 Adds release definitions to the global configurations for the specified
	 release and optionally, its version.

ARGUMENTS
	name
		This is the name of the release

	version (optional)
		The version of the release that is to be used.  If not specified, it will
		default to `latest`.  The valid values are:

			`latest`:  use the latest version that is already available on the BOSH
								 director.  this may not be the latest version that exists for
								 this release at its source.

			`track`:   use the version specified in the Genesis Index, which tracks
								 accepted release versions.

			<version>: A cardinal or SemVer value for the exact release you want to
								 use, without any prefix such as 'v'

	url
		Specify the URL where the release is found, including the schema and the
		version.  For example:
		  https://bosh.io/d/github.com/myorg/mystuff-boshrelease?v=1.2.3

SEE ALSO
@~include=related{"items":["concept:Releases","command:releases","command:set release","command:use release"]}
@~scope=common,releases
dox-command:add-release

cmd_add_release() {
	local release version url

	while (( $# )); do
		arg=$1 ; shift
		case ${arg} in
		(-*) bad_usage_no_opts ;;
		(*)
			if [[ -z ${release} ]]; then   release=${arg}
			elif [[ -z ${version} ]]; then version=${arg}
			elif [[ -z ${url} ]]; then     url=${arg}
			else bad_usage_extra "$arg"
			fi
			;;
		esac
	done
	[[ -n ${release} ]] || bad_usage_missing "name"
	version=${version:-latest}

	setup
	if [[ -d ${DEPLOYMENT_ROOT}/global/releases/${release} ]]; then
		echo >&2 "Release ${release} already exists in global/releases/"
		exit 1
	fi
	mkdir -p ${DEPLOYMENT_ROOT}/global/releases/${release}
	echo ${version} > ${DEPLOYMENT_ROOT}/global/releases/${release}/version

	if [[ -n ${url} ]]; then
		echo ${url} > ${DEPLOYMENT_ROOT}/global/releases/${release}/url
	fi

	case ${version} in
	(latest)
		echo "Using the latest version of ${release} available on your BOSH director"
		;;
	(track)
		echo "Using the latest version of ${release} available via the Genesis Index"
		;;
	(*)
		echo "Using v${version} of ${release}"
		;;
	esac
	exit 0
}

: <<'dox-command:set-release'
USAGE
@~include=usage{"args":"<name> [<version> [<url>]]"}

DESCRIPTION
	Updates the specified release to the specified version at the global level.

ARGUMENTS
	name
		This is the name of the release

	version (optional)
		The version of the release that is to be used.  If not specified, it will
		default to `latest`.  The valid values are:

			`latest`:  use the latest version that is already available on the BOSH
								 director.  this may not be the latest version that exists for
								 this release at its source.

			`track`:   use the version specified in the Genesis Index, which tracks
								 accepted release versions.

			<version>: A cardinal or SemVer value for the exact release you want to
								 use, without any prefix such as 'v'

	url
		Specify the URL where the release is found, including the schema and the
		version.  For example:
		  https://bosh.io/d/github.com/myorg/mystuff-boshrelease?v=1.2.3

SEE ALSO
@~include=related{"items":["concept:Releases","command:releases","command:add release","command:use release"]}
@~scope=common,releases
dox-command:set-release
cmd_set_release() {
	local release version

	while (( $# )); do
		arg=$1 ; shift
		case ${arg} in
		(-*)
			bad_usage
			;;
		(*)
			if [[ -z ${release} ]]; then   release=${arg}
			elif [[ -z ${version} ]]; then version=${arg}
			elif [[ -z ${url} ]]; then     url=${arg}
			else bad_usage_extra "$arg"
			fi
			;;
		esac
	done
	[[ -n ${release} ]] || bad_usage_missing "name"
	version=${version:-track}

	setup
	mkdir -p ${DEPLOYMENT_ROOT}/global/releases/${release}
	rm -rf   ${DEPLOYMENT_ROOT}/global/releases/${release}/*
	echo ${version} > ${DEPLOYMENT_ROOT}/global/releases/${release}/version

	[[ -n ${url} ]] && echo ${url} > ${DEPLOYMENT_ROOT}/global/releases/${release}/url

	case ${version} in
	(latest)
		echo "Using the latest version of ${release} available on your BOSH director"
		;;
	(track)
		echo "Using the latest version of ${release} available via the Genesis Index"
		;;
	(*)
		echo "Using v${version} of ${release}"
		;;
	esac
	exit 0
}

bad_set() {
	local arg=${1}
	cat >&2 <<EOF
USAGE: genesis set release
EOF
	exit 1
}

: <<'dox-command:use-release'
USAGE
@~include=usage{"args":"<name>"}

DESCRIPTION
	 When inside a site or environment directory, takes the provided release
	 name, and configures the site to include the release when deploying to
	 environments in that site.

ARGUMENTS
	name
		This is the name of the release to use.  Do not include the version.

SEE ALSO
@~include=related{"items":["concept:Releases","command:releases","command:add release","command:set release"]}

@~scope=common,releases
dox-command:use-release
cmd_use_release() {
	local release

	while (( $# )); do
		arg=$1 ; shift
		case ${arg} in
		(-*) bad_usage_invalid_opt "$arg" ;;
		(*)
			[[ -z ${release} ]] || bad_usage_extra "$arg" "name" "$release"
			release=${arg}
			;;
		esac
	done
	[[ -n ${release} ]] || bad_usage_missing "release name"

	must_be_in_a_site
	if [[ ! -d ${DEPLOYMENT_ROOT}/global/releases/${release} ]]; then
		echo >&2 "Release ${release} is not defined globally."
		echo >&2 "(Do you need to \`genesis add release ${release}' first?)"
		exit 1
	fi

	relfile=${DEPLOYMENT_SITE_DIR}/site/releases
	if grep -q "^${release}$" $relfile >/dev/null 2>&1; then
		echo "Site ${DEPLOYMENT_SITE} is already set to use release ${release}"
	else
		echo "${release}" >> $relfile
		echo "Site ${DEPLOYMENT_SITE} is now using release ${release}"
	fi
	exit 0
}

: <<'dox-concept:Stemcells'
DESCRIPTION
	Stemcells used by each deployment are managed by Genesis to ensure version
	upgrades propagate correctly through environment deployments.

	TODO: Include details on:
	* adding stemcells
	* automatic upload of stemcells using url/sha1
	* propagating stemcell upgrades

COMMANDS
@~include=topic{"category":"command","scope":"stemcells","desc":"inline","leader":"  <<SCRIPT_NAME>> "}
@~scope=stemcells

SEE ALSO
@~include=topic{"category":"concept","partial":"Cached-Definitions","desc":"inline","leader":"  "}
dox-concept:Stemcells

: <<'dox-command:stemcells'
USAGE
	<<SCRIPT_NAME>> stemcells [<site> [<env>]]

DESCRIPTION
	Lists the stemcell name + version in use by the specified site or
	environment.  If no arguments are specified, you must be in a
	site/environment directory.

ARGUMENTS
	site (optional)
		if this is the sole argument, the stemcell used by the named site will be
		displayed.  This is identical to the behaviour when run in a site directory
		with no arguments.

		Note: If in an environment directory, and just the site argument is
		supplied, it will display the stemcell for the environment of the same name
		as the current environment directory under the given site.

	env (optional)
		will show the stemcell used by the specified environment under the given
		site.  This is identical to if no arguments are given when run from an
		environment directory.

SEE ALSO
@~include=related{"items":["concept:Stemcells","command:use stemcell"]}
@~scope=common,stemcells
dox-command:stemcells

cmd_stemcells() {
	local site env
	while (( $# )); do
		arg=$1 ; shift
		case ${arg} in
		(-*) bad_usage_no_opts ;;
		(*)
			if [[ -z ${site} ]]; then  site=${site}
			elif [[ -z ${env} ]]; then env=${arg}
			else bad_usage_extra "$arg"
			fi
			;;
		esac
	done

	setup
	site=${site:-$DEPLOYMENT_SITE}
	env=${env:-$DEPLOYMENT_ENVIRONMENT}
	local path=""
	if [[ -n ${env} ]]; then
		path="${DEPLOYMENT_ROOT}/${site}/${env}/.site/stemcell"
	elif  [[ -n ${site} ]]; then
		path="${DEPLOYMENT_ROOT}/${site}/site/stemcell"
	else
		bad_usage_missing "site and/or env, or not in correct directory"
	fi

	if [[ -f "${path}/alias" ]] ; then # v2 Style
		local sc_alias="$(cat ${path}/alias)"
		local name
		if [[ -f "${path}/os" ]] ; then
			name="OS:$(cat ${path}/os)"
		else
			name="$(cat ${path}/name)"
		fi

		printf "%s/%s (v2 Manifest alias: %s)\n" "$name" $(cat "${path}/version") "$sc_alias"
	elif [[ -f "${path}/name" ]] ; then # v1 Style
		printf "%s/%s\n" $(cat ${path}/name) $(cat ${path}/version)
	else
		echo "ERROR: No stemcell found."
		exit 2
	fi
}
: <<'dox-command:use-stemcell'
USAGE
@~include=usage{"args":"[-a|--alias <alias> [--os]] <name> [<version>]"}

DESCRIPTION
	When inside a site or environment directory, takes the provided stemcell
	name, and updates the site directory to use that stemcell. You can
	optionally specify the version of the stemcell to be used as a second
	argument after the stemcell name.

	For v1 manifests that do not use cloud config, you only specify name and
	optionally version.

	To generate v2-compatible manifests, you must also specify --alias <alias>
	and optionally the --os option.

ARGUMENTS
	name
		This is the full name of the stemcell, or a shorthand of the name (see the
		table below).  If the --os option is specified, this name is the name of
		the os (ie ubuntu-trusty)

	--os
		This changes the meaning of the name argument, from the name of the stem-
		cell to the name of the OS.  This can only be used if you also specify the
		--alias option.

	-a|--alias <alias>
		Used to specify the stemcell alias as used by v2-style manifests to refer
		to a stemcell specified in the cloud config on the BOSH Director.

	version
		The version of the stemcell to be used.  If omitted, it will default to
		`latest`.  Other valid versions are an explicit numerical version or
		`track` to indicate the most recent version found in the Genesis Index.
		Note: you cannot track against OS, only named stemcells.

STEMCELL SHORTHAND NAMES
	aws:       bosh-aws-xen-hvm-ubuntu-trusty-go_agent
	azure,
	hyperv:    bosh-azure-hyperv-ubuntu-trusty-go_agent
	openstack: bosh-openstack-kvm-ubuntu-trusty-go_agent
	vcloud:    bosh-vcloud-esxi-ubuntu-trusty-go_agent
	vsphere:   bosh-vsphere-esxi-ubuntu-trusty-go_agent
	warden,
	bosh-lite: bosh-warden-boshlite-ubuntu-trusty-go_agent"

SEE ALSO
@~include=related{"items":"concept:Stemcells"}

@~scope=common,stemcells
dox-command:use-stemcell
cmd_use_stemcell() {
	local name version sc_alias os

	while (( $# )); do
		arg=$1 ; shift
		case ${arg} in
		(-a|--alias)
			check_opt_usage "$arg" "$1"
			sc_alias=$1
			shift
			;;
		(--os)
			os=true
			;;
		(-*)
			bad_usage_invalid_opt "$arg"
			;;
		(*)
			if [[ -z ${name} ]]; then
				name=${arg}
			elif [[ -z ${version} ]]; then
				version=${arg}
			else
				bad_usage
			fi
			;;
		esac
	done

	[[ $os && -z $sc_alias ]] && bad_usage "Cannot specify --os without --alias <alias>"
	[[ $os && "${name}" == "track" ]] && bad_usage "Cannot track against OS"
	[[ -n ${name} ]] || bad_usage_missing "name"
	version=${version:-latest}

	must_be_in_a_site

	if [[ "$DEPLOYMENT_TYPE" == 'bosh-init' && -n "$sc_alias" ]] ; then
		bad_usage "bosh-init cannot use v2-style manifests"
	fi

	# resolve aliases
	case ${name} in
		(aws)              name="bosh-aws-xen-hvm-ubuntu-trusty-go_agent"     ;;
		(azure|hyperv)     name="bosh-azure-hyperv-ubuntu-trusty-go_agent"    ;;
		(openstack)        name="bosh-openstack-kvm-ubuntu-trusty-go_agent"   ;;
		(vcloud)           name="bosh-vcloud-esxi-ubuntu-trusty-go_agent"     ;;
		(vsphere)          name="bosh-vsphere-esxi-ubuntu-trusty-go_agent"    ;;
		(warden|bosh-lite) name="bosh-warden-boshlite-ubuntu-trusty-go_agent" ;;
	esac

	echo "Site ${DEPLOYMENT_SITE} stemcell:"
	mkdir -p ${DEPLOYMENT_SITE_DIR}/site/stemcell
	rm       "${DEPLOYMENT_SITE_DIR}/site/stemcell/*" >/dev/null 2>&1
	local name_file="name"
	if [[ -n "$sc_alias" ]] ; then
		echo "  - v2 manifest alias '$sc_alias'"
		echo "${sc_alias}" > "${DEPLOYMENT_SITE_DIR}/site/stemcell/alias"
		[[ $os ]] && name_file="os"
	fi
	echo "${name}"    > "${DEPLOYMENT_SITE_DIR}/site/stemcell/$name_file"
	echo "${version}" > "${DEPLOYMENT_SITE_DIR}/site/stemcell/version"
	echo "  - ${name_file} '${name}'";
	case ${version} in
	(latest)
		echo "  - using the latest version on BOSH director"
		;;
	(track)
		echo "  - tracking the latest version via the Genesis Index"
		;;
	(*)
		echo "  - version ${version}"
		;;
	esac
	exit 0
}

: <<'dox-command:build'
USAGE
@~include=usage{"args":"[<manifest-file>]"}

DESCRIPTION
	Compiles all of the YAML templates down to a single BOSH manifest for the
	current environment.

ARGUMENTS
  manifest-file (optional, default: manifest.yml)
		The file into which the manifest YAML document is written.

@~scope=make
dox-command:build
cmd_build() {
	local target
	while (( $# )); do
		arg=$1 ; shift
		case ${arg} in
		(-*) bad_usage_invalid_opt "$arg"	;;
		(*)
			[[ -z ${target} ]] || bad_usage_extra "$arg" "manifest-file" "$target"
			target=${arg}
			;;
		esac
	done
	target=${target:-manifest.yml}
	must_be_in_an_environment
	mkdir -p ${DEPLOYMENT_ENV_DIR}/manifests
	build_manifest > ${DEPLOYMENT_ENV_DIR}/manifests/${target}
	exit 0
}

: <<'dox-concept:Cached-Definitions'
DESCRIPTION
	Global and site definitions are cached in each environment in order to
	mitigate premature changes impacting other environments prematurely.

	As explained in the Structure concept documents, Genesis organizes the parts
	of the manifest definitions into those that apply globally, site-wide and to
	a specific environment.  However, since deployments are capable of changing
	over time (upgrades, bug fixes, expanded functionality), how do you ensure
	changes propagate correctly.

	To solve this, the shared global and site level definitions are cached in
	each environment, under .global and .site directories respectively.  This
	allows that environment to deploy environment level changes (ie scaling)
	without worrying that the global and site definitions haven't changed.

	When making global and/or site level changes, they can be applied to specific
	environments by using the `genesis refresh` command (or the associated
	`make refresh`).  This allows controlled deployment of these changes across
	environments.  This can be automated by using the built-in CI functionality.

COMMANDS
@~include=topic{"category":"command","scope":"refresh","desc":"inline","leader":"  <<SCRIPT_NAME>> "}

SEE ALSO
@~include=related{"items":["concept:Structure","concept:Makefiles","concept:CI"]}
@~scope=makefile
dox-concept:Cached-Definitions

: <<'dox-partial:refresh'
USAGE
@~include=usage{"args":"[(global|site|all|makefile|readme)]"}

DESCRIPTION
	Refresh the cached copies of site and/or global definitions inside the current
	environment directory.  Can also be used to recreate the Makefile and readme
	files after a Genesis upgrade.  If run without a subcommand, it will default
	to 'all'.
dox-partial:refresh

: <<'dox-command:refresh-all'
USAGE
@~include=usage{"cmd":"refresh [all]"}

DESCRIPTION
	Refresh (or create) the cached copies of site and global definitions inside
	the current environment directory.  This is the default action if no refresh
	subcommand is specified.

@~group=refresh
@~scope=make
dox-command:refresh-all
cmd_refresh_all() {
	[[ -z $1 ]] || bad_usage_no_args

	must_be_in_an_environment
	echo "Refreshing site definitions for ${DEPLOYMENT_SITE}/${DEPLOYMENT_ENVIRONMENT}"
	refresh_site   ${DEPLOYMENT_SITE} ${DEPLOYMENT_ENVIRONMENT}
	echo "Refreshing global definitions for ${DEPLOYMENT_SITE}/${DEPLOYMENT_ENVIRONMENT}"
	refresh_global ${DEPLOYMENT_SITE} ${DEPLOYMENT_ENVIRONMENT}
	exit 0
}

: <<'dox-command:refresh-global'
USAGE
@~include=usage

DESCRIPTION
	Create or refresh the files in the .global cached directory in the current
	environment directory from the files in the ../../global directory.

@~group=refresh
@~scope=make
dox-command:refresh-global
cmd_refresh_global() {
	[[ -z $1 ]] || bad_usage_no_args

	must_be_in_an_environment
	echo "Refreshing global definitions for ${DEPLOYMENT_SITE}/${DEPLOYMENT_ENVIRONMENT}"
	refresh_global ${DEPLOYMENT_SITE} ${DEPLOYMENT_ENVIRONMENT}
	exit 0
}

: <<'dox-command:refresh-site'
USAGE
@~include=usage

DESCRIPTION
	Create or refresh the files in the .site cached directory in the current
	environment directory from the files in the ../site directory.

@~group=refresh
@~scope=make
dox-command:refresh-site
cmd_refresh_site() {
	[[ -z $1 ]] || bad_usage_no_args

	must_be_in_an_environment
	echo "Refreshing site definitions for ${DEPLOYMENT_SITE}/${DEPLOYMENT_ENVIRONMENT}"
	refresh_site ${DEPLOYMENT_SITE} ${DEPLOYMENT_ENVIRONMENT}
	exit 0
}

: <<'dox-command:refresh-makefile'
USAGE
@~include=usage

DESCRIPTION
	Rebuild the Makefile for an environment, which can be useful to bring old
	deployments in-line with newer versions of Genesis.

@~group=refresh
@~scope=makefile
dox-command:refresh-makefile
cmd_refresh_makefile() {
	[[ -z $1 ]] || bad_usage_no_args

	must_be_in_an_environment
	echo "Refreshing Makefile for ${DEPLOYMENT_SITE}/${DEPLOYMENT_ENVIRONMENT}"
	create_makefile "${DEPLOYMENT_ENV_DIR}/Makefile"
}

: <<'dox-command:refresh-readmes'
USAGE
@~include=usage

DESCRIPTION
	Rebuild the various README files for the top-level and 'global' directories,
	and all sites and environments, which can be useful to bring old deployments
	in-line with newer versions of Genesis.

@~group=refresh
@~scope=make
dox-command:refresh-readmes
cmd_refresh_readmes() {
	[[ -z $1 ]] || bad_usage_no_args

	setup
	echo "Refreshing README for the whole repository"
	rm -f ${DEPLOYMENT_ROOT}/README*
	create_root_readme >${DEPLOYMENT_ROOT}/README.md

	echo "Refreshing README for global definitions"
	create_global_readme >${DEPLOYMENT_ROOT}/global/README
	for site in $(all_sites); do
		echo "  Refreshing README for site '${site}'"
		create_site_readme ${site} >${DEPLOYMENT_ROOT}/${site}/README
		for env in $(all_environments_for ${site}); do
			echo "    Refreshing README for environment '${site}/${env}'"
			create_environment_readme ${site} ${env} >${DEPLOYMENT_ROOT}/${site}/${env}/README
		done
	done
}

: <<'dox-command:deploy'
USAGE
@~include=usage

DESCRIPTION
	When run from inside of an environment directory, builds and deploys your
	BOSH manifest. A redacted copy is left in the repo for posterity. The copy
	deployed is non-redacted.

@~group=build
@~scope=make
dox-command:deploy
cmd_deploy() {
	[[ -z $1 ]] || bad_usage_no_args

	must_be_in_an_environment
	preflight_deployment

	case ${DEPLOYMENT_TYPE} in
	(normal)
		(VAULT_ADDR= REDACT=y cmd_build manifest.yml) || exit 3
		(            REDACT=  cmd_build .deploy.yml)  || exit 4
		[[ -n $DEBUG_LEAVE_THE_CREDS_THERE ]] || \
			trap "rm -f ${DEPLOYMENT_ENV_DIR}/manifests/.deploy.yml" QUIT TERM INT EXIT

		bosh -d ${DEPLOYMENT_ENV_DIR}/manifests/.deploy.yml deploy
		exit $?
		;;

	(bosh-init)
		(VAULT_ADDR= REDACT=y cmd_build manifest.yml) || exit 3
		(            REDACT=  cmd_build .deploy.yml)  || exit 4
		[[ -n $DEBUG_LEAVE_THE_CREDS_THERE ]] || \
			trap "rm -f ${DEPLOYMENT_ENV_DIR}/manifests/.deploy.yml" QUIT TERM INT EXIT

		if [[ ! -f "${DEPLOYMENT_ENV_DIR}/manifests/.deploy-state.json" ]]; then
			echo "No existing genesis-created bosh-init statefile detected. Please help genesis find it."
			read -e -p "Path to existing bosh-init statefile (leave blank for new deployments): " statefile
			while [[ -n "${statefile}" && ! -f "${statefile}" ]]; do
				echo "Invalid path."
				read -e -p "Path to existing bosh-init statefile (leave blank for new deployments): " statefile
			done
			if [[ -n "${statefile}" ]]; then
				mv "${statefile}" ${DEPLOYMENT_ENV_DIR}/manifests/.deploy-state.json
			fi
		fi

		bosh-init deploy ${DEPLOYMENT_ENV_DIR}/manifests/.deploy.yml
		exit $?
		;;
	esac
}

### CI SUPPORT FUNCTIONS

ci_smoke_test() {
	local smoke_test=$(spruce json $(ci_pipeline_yaml) | jq -r '.smoke_test')

	if [[ ${smoke_test} != 'null' ]]; then
		echo ${smoke_test}
	fi
}

ci_environment_type() {
	local site=${1:?ci_environment_type() - no site given}
	local env=${2:?ci_environment_type() - no environment given}

	local alpha=$(spruce json $(ci_pipeline_yaml) | jq -r ".alpha")
	if [[ "${site}/${env}" == $alpha ]]; then
		echo "alpha"
		return
	fi

	local beta=$(spruce json $(ci_pipeline_yaml) | jq -r ".sites[\"${site}\"].beta")
	if [[ "${env}" == $beta ]]; then
		echo "beta"
		return
	fi

	# otherwise, is it automatically updatable?
	local auto=$(spruce json $(ci_pipeline_yaml) | jq -r ".sites[\"${site}\"].auto[\"${env}\"] // \"\"")
	if [[ -n ${auto} ]]; then
		echo "gamma"
	else
		echo "omega"
	fi
}

ci_alpha_environment() {
	spruce json $(ci_pipeline_yaml) | jq -r ".alpha"
}

ci_beta_environment_for() {
	local site=${1:?ci_beta_environment_for() - no site given}
	local env=$(spruce json $(ci_pipeline_yaml) | jq -r ".sites[\"${site}\"].beta // \"\"")
	if [[ -n ${env} ]]; then
		echo "${site}/${env}"
	fi
}


ci_parent_environment_for() {
	local site=${1:?ci_parent_environment_for() - no site given}
	local env=${2:?ci_parent_environment_for() - no env given}
	local parent=$(spruce json $(ci_pipeline_yaml) | jq -r ".sites[\"${site}\"][\"${env}\"].parent // \"\"")

	if [[ -n ${parent} ]]; then
		echo "${site}/${parent}"
	else
		ci_beta_environment_for ${site}
	fi
}

ci_gamma_environments_for() {
	local site=${1:?ci_gamma_environments_for() - no site given}
	local beta=$(ci_beta_environment_for ${site})
	local alpha=$(ci_alpha_environment)
	for env in $(all_environments_for $site); do
		if [[ "${site}/${env}" == "${beta}" || "${site}/${env}" == "${alpha}" ]]; then
			continue
		fi
		local auto=$(spruce json $(ci_pipeline_yaml) | jq -r ".sites[\"${site}\"].auto[\"${env}\"] // \"\"")
		if [[ -n ${auto} ]]; then
			echo ${site}/${env}
		fi
	done
}

ci_name() {
	tr / - <<<"$1"
}

ci_check_configuration() {
	setup
	local rc=0

	mkdir -p ${DEPLOYMENT_ROOT}/ci
	if [[ ! -f $(ci_boshes_yaml) ]]; then
		cat >$(ci_boshes_yaml) <<EOF
---
auth: (( param "Please define your BOSH directors in ci/boshes.yml (and remove this line)" ))
aliases:
  # NOTE: if you're making use of `meta.pause_for_existing_bosh_tasks`, you will
  #       also need to add aliases for the name of the bosh deployment -> addr
  #       (e.g. vsphere-prod-bosh -> https://10.4.16.4:25555)
  target: (( param "Please define aliases for your BOSH directors (uuid -> addr)" ))


# BOSH directors are specified by \`url: username / password\`
# (just like in ~/.bosh_config's auth section), i.e.:
#
#aliases:
#  target:
#    DIRECTOR-UUID: https://ip.ad.dr.ess:25555
#    DIRECTOR-NAME: https://ip.ad.dr.ess:25555
#auth:
#  https://ip.ad.dr.ess:25555:
#    username: admin
#    password: (( vault "this/should/probably/be/in/vault" ))
#
EOF
	fi
	if [[ ! -f $(ci_settings_yaml) ]]; then
		cat >$(ci_settings_yaml) <<EOF
--- {}
# This is where you will configure your Genesis CI deployment pipeline
# (everything goes under 'meta')
#
#meta:
#  # This is the name of your pipeline
#  name: $DEPLOYMENT_NAME
#
#  # Should genesis wait for existing BOSH tasks to complete prior to deploying?
#  # This should be set to 'true' for any pipelines that deploy/update BOSH itself
#  pause_for_existing_bosh_tasks: false
#
#  # This is where you set your visibility of the pipeline
#  public_pipeline: # set to true or false
#
#  # This is the name of your fly target
#  target: proto
#
#  # A map of name:value environment variables
#  # that will be made available to the script
#  env:
#    VAULT_ADDR: https://va.ul.t.ip:8200
#  # VAULT_SKIP_VERIFY: 1
#
#  github:
#    owner: github-user
#    repo:  repository-name
#
#    private_key: |
#      ssh-private-key
#      (PEM-encoded)
#
#    # Optional branch to track for changes.
#    # (defaults to "master")
#    #branch: master
#
#  slack:
#    webhook: https://slack/web/hook/url
#    channel: '#name' # or '@user'
#
#    # Optional name/icon to use for posting the notification.
#    #username: runwaybot
#    #icon: http://ip.ad.dr.ess/of/icon.gif
#
EOF
	fi

	local alpha=""
	ensure_ci_configuration
	for site in $(all_pipeline_sites); do
		local beta=""
		local numenvs=0
		for env in $(all_environments_for ${site}); do
			local type="$(ci_environment_type ${site} ${env})"
			case ${type} in
			(alpha)
				if [[ -n "${alpha}" ]]; then
					echo >&2 "Multiple alpha environments detected: ${alpha} and ${site}/${env}"
					rc=1
				fi
				alpha="${site}/${env}"
				;;

			(beta)
				if [[ -n "${beta}" ]]; then
					echo >&2 "Multiple beta environments detected for ${site}: ${beta} and ${site}/${env}."
					rc=1
				fi
				beta="${site}/${env}"
				;;
			(*)
				numenvs=$(( numenvs + 1 ))
				;;
			esac
		done

		if [[ -z "${beta}" && $numenvs -gt 0 ]]; then
			echo >&2 "No beta environment found for ${site}."
			rc=1
		fi
	done

	if [[ -z "${alpha}" ]]; then
		echo >&2 "No alpha environment found."
		rc=1
	fi

	if [[ ${GENESIS_CI_ALLOW_TRACK} != "true" ]]; then
		for site in $(all_sites); do
			if [[ $(cat ${site}/site/stemcell/version) == "track" ]]; then
				echo >&2 "Stemcell for site '${site}' is set to version 'track'. If desired, set GENESIS_CI_ALLOW_TRACK=true to override."
				rc=1
			fi
		done

		pushd global/releases >/dev/null
			for release in *; do
				if [[ $(cat ${release}/version) == "track" ]]; then
					echo >&2 "Release '${release}' is set to version 'track'. If desired, set GENESIS_CI_ALLOW_TRACK=true to override."
					rc=1
				fi
			done
		popd > /dev/null
	fi

	if [[ $rc -ne 0 ]]; then
		echo >&2 "Configuration issues with CI found.  Please address the above."
		exit 1
	fi
}

ci_update() {
	# emulate:
	#   echo "some: change" | spruce merge -i $(ci_pipeline_yaml)

	ensure_ci_configuration

	need_a_workdir
	cat > ${WORKDIR}/update.yml
	ensure_yaml_file ${WORKDIR}/update.yml

	if spruce merge "$@" $(ci_pipeline_yaml) ${WORKDIR}/update.yml > ${WORKDIR}/.ci.yml; then
		mv ${WORKDIR}/.ci.yml $(ci_pipeline_yaml)
	fi
}

need_ci_git_access() {
	[ -z ${GIT_USERNAME} ] && GIT_USERNAME="Concourse Bot"
	[ -z ${GIT_EMAIL}    ] && GIT_EMAIL="concourse@$(hostname -f)"
	if [[ -z $(git config --global user.email) ]]; then
		git config --global user.email ${GIT_EMAIL}
	fi
	if [[ -z $(git config --global user.name) ]]; then
		git config --global user.name ${GIT_USERNAME}
	fi

	if [[ ! -f ~/.ssh/key && -n ${CI_PRIVATE_KEY} ]]; then
		mkdir -p ~/.ssh
		cat > ~/.ssh/key <<EOF
${CI_PRIVATE_KEY}
EOF
		chmod 0400 ~/.ssh/key
		eval $(ssh-agent) >/dev/null 2>&1
		trap "kill $SSH_AGENT_PID" 0

		cat >~/.ssh/askpass <<EOF
#!/bin/sh
echo "Looks like there is something wrong with your SSH private key (for accessing the repository)" >&2
exit 1
EOF
		chmod 0755 ~/.ssh/askpass
		SSH_ASKPASS=~/.ssh/askpass DISPLAY= ssh-add ~/.ssh/key >/dev/null
	fi

	if [[ ! -f ~/.ssh/config ]]; then
		mkdir -p ~/.ssh
		cat > ~/.ssh/config <<EOF
StrictHostKeyChecking no
LogLevel quiet
EOF
		chmod 0600 ~/.ssh/config
	fi
}

ci_commit() {
	local msg=${1:?ci_commit() - no commit message given}
	if [[ -n $(git status --porcelain) ]]; then
		need_ci_git_access
		git add -A
		git status
		git --no-pager diff --cached
		git commit -m "${msg}"
	fi
}

ci_pipeline_yaml() {
	if [[ -n ${CI_PIPELINE:-} ]]; then
		echo ${DEPLOYMENT_ROOT}/.ci.${CI_PIPELINE}.yml
	else
		echo ${DEPLOYMENT_ROOT}/.ci.yml
	fi
}

ci_boshes_yaml() {
	if [[ -n ${CI_PIPELINE:-} ]]; then
		echo ${DEPLOYMENT_ROOT}/ci/boshes.${CI_PIPELINE}.yml
	else
		echo ${DEPLOYMENT_ROOT}/ci/boshes.yml
	fi
}

ci_settings_yaml() {
	if [[ -n ${CI_PIPELINE:-} ]]; then
		echo ${DEPLOYMENT_ROOT}/ci/settings.${CI_PIPELINE}.yml
	else
		echo ${DEPLOYMENT_ROOT}/ci/settings.yml
	fi
}

pipeline_yaml() {
	if [[ -n ${CI_PIPELINE:-} ]]; then
		echo pipeline.${CI_PIPELINE}.yml
	else
		echo pipeline.yml
	fi
}


: <<'dox-concept:CI'
DESCRIPTION
  When making a change to a deployment, you want to make sure it causes the
  least impact and has the highest chance of catching an issue early.  Genesis
  provides an integrated CI/CD solution that is built on Concourse to ensure
  that changes to your deployments can propagate through your environments
  safely.

  Changes come to the manifest from the sources:  global changes that impact
  all deployments, site changes that only impact all environments in that site
  and changes that are isolated to a specific environment.

  Changes at the global level are called alpha changes.  These can be tested on
  a single isolated environment to ensure that they can be deployed with golden
  configuration for site and env.

  Changes at the site level are called beta changes.  They are applied on top
  of the last known-good alpha chagnes that passed.  One environment for the
  site is picked as a `beta environment` on which the deployment is tested.

  Environment changes need to be applied to the target environment, and will be
  applied over the known-good beta changes.

WORKFLOW
  The CI pipeline is created as follows:

                   .-------.
  global changes ->| alpha |--+--+--+
                   '-------'  |  |  |
      .-SITE-C----------------|--|--v---------------------------------------.
    .-SITE-B------------------|--v----------------------------------------. |
  .-SITE-A--------------------|-----------------------------------------. | |
  |                  .--------'                                         | | |
  |                  |  .---------.                                     | | |
  |                  '->| beta:   |---.                                 | | |
  | site changes ------>| SITE-A/ |-. |  .---------.        .---------. | | |
  | 'sandbox' changes ->| sandbox | | +->| notify: |- - - ->| manual: | | | |
  |                     '---------' +-|->| SITE-A/ |- - - ->| SITE-A/ | | | |
  | 'dev' changes ------------------|-|->| dev     |- - - ->| dev     | | | |
  |                                 | |  '---------'        '---------' | | |
  |                                 | |  .---------.        .---------. | | |
  |                                 | '->| auto    |---+--->| auto:   | | | |
  |                                 '--->| SITE-A/ |-+-|--->| SITE-A/ | | | |
  | 'qa' changes ----------------------->| qa      | | | .->| live    | | | |
  |                                      '---------' | | |  '---------' | | |
  | 'live' changes ----------------------------------|-|-'              | | |
  |                                 .----------------' |                | | |
  |                                 | .----------------'                | | |
  |                                 | |  .---------.        .---------. | | |
  |                                 ' '->| notify: |- - - ->| manual: | | | |
  |                                 '--->| SITE-A/ |- - - ->| SITE-A/ | | | |
  | 'prod' changes --------------------->| prod    |- - - ->| prod    | | |-'
  |                                      '---------'        '---------' |-'
  '---------------------------------------------------------------------'

  In the example pipeline above, there are three sites: SITE-A, SITE-B and
  SITE-C.  Let's walk through what happens:

	alpha
  * Any changes to /global will trigger a deployment on the alpha environment.
		A successful deployment will be used as a triggering input for the beta
		environments on each site.  We will focus on SITE-A, but all sites will
		operate the same way.

	beta:SITE-A/sandbox
	* A successful deployment on the alpha site will trigger a deployment on
		beta: SITE-A/sandbox environment using the global changes that just passed
		and the last known good SITE-A site changes as well.

	* Any changes to SITE-A/site will also trigger a deployment on
		beta:SITE-A/sandbox, which will use the last passed global changes as well.

	* A change to the SITE-A/sandbox directory will also trigger a deployment on
		beta:SITE-A/sandbox environment using the last known good global and site
		changes.  However, a successful deployment will NOT trigger any downstream
		deployments.

	REMAINING ENVIRONMENTS

	The four remaining environments in SITE-A are dev, qa, live and prod.  They
	are configured as:
		qa:   'auto' environment.
		dev:  'manual' environment.
		live: 'auto' environment, with SITE-A/qa as parent.
		prod: 'manual' environment, with SITE-A/qa as parent.

	notify:SITE-A/dev + manual:SITE-A/dev
	* Because 'dev' is manual, the successful deployment of beta:SITE-A/sandbox
		does not trigger the deployment on SITE-A/dev.  Instead, it sends out a
		notification that SITE-A/dev is ready to be deployed.  This notification
		will instruct the receiver to visit the Concourse link for SITE-A/dev and
		click the (+) button, which will manually start the deployment.

	* A change to SITE-A/dev environment directory will also trigger a
		notification instead of starting the deployment.

	auto:SITE-A/qa
	* Because 'qa' is auto, a deployment will be triggered by a successful
		deployment of beta/SITE-A/sandbox that was due to global or site changes.

	* Changes to SITE-A/qa directory will also trigger a deployment on
		auto:SITE-A/qa, but its success will not trigger further downstream
		deployments.

	auto:SITE-A/live
	* This operates similar to SITE-A/qa, but instead of being triggered by a
		successful deployment of beta:SITE-A/sandbox, it is triggered by a
		successful deployment of auto:SITE-A/qa (for site or global changes).

	notify:SITE-A/prod + manual:SITE-A/prod
	* Similar to SITE-A/dev in behaviour, except its notification istriggered on
		a successful deployment due to global or site changes on auto:SITE-A/qa

SEE ALSO
@~include=topic{"category":"command","desc":"inline","leader":"  ","partial":"ci"}
dox-concept:CI

: <<'dox-partial:ci'
DESCRIPTION
  Manages the CI pipeline configurations.
dox-partial:ci

### CI API Commands

: <<'dox-command:ci-alpha'
USAGE
@~include=usage{"args":"[-p|--pipeline <name>] [<site>/<env>]"}

DESCRIPTION
	Sets the specified or current environment as the alpha enviroment in the
	specified or default pipeline.

ARGUMENTS
	-p|--pipeline <name>
		the name of the pipeline to be configured.  Defaults to the deployment name

	<site>/<env>
		This is the path to the environment relative to the deployment root
		directory.  If this command is issued within an environment directory, it
		defaults to the current directory; otherwise, it is required.

SEE ALSO:
@~include=related{"items":["concept:CI","command:ci-beta","command:ci-auto","command:ci-manual","command:ci-parent","command:ci-repipe","command:ci-flow"]}
@~scope=ci
dox-command:ci-alpha
cmd_ci_alpha() {
	local site_env

	while (( $# )); do
		arg=$1 ; shift
		case ${arg} in
		(-*) bad_usage_no_opts ;;
		(*)
			[[ -z ${site_env} ]] || bad_usage_extra "$arg" "<site>/<env>" "$site_env"
			site_env=${arg}
			;;
		esac
	done

	setup
	if [[ -z "${site_env}" ]]; then
		must_be_in_an_environment
		site_env="${DEPLOYMENT_SITE}/${DEPLOYMENT_ENVIRONMENT}"
	fi

	check_environment $site_env
	local site=${site_env%%/*}
	local env=${site_env##*/}
	ci_update <<EOF
---
alpha: ${site_env}
sites:
  ${site}:
    auto:
      ${env}: y
EOF
}

: <<'dox-command:ci-beta'
USAGE
@~include=usage{"args":"[-p|--pipeline <name>] [<site>/<env> [... <siteN>/<envN>]]"}

DESCRIPTION
	Sets the specified or current environment as the beta enviroment for its
	associated site in the specified or default pipeline.

ARGUMENTS
	-p|--pipeline <name>
		the name of the pipeline to be configured.  Defaults to the deployment name

	<site>/<env>
		This is the path to the environment relative to the deployment root
		directory.  If this command is issued within an environment directory, it
		defaults to the current directory; otherwise, it is required.

		You can specify 0 or more <site>/<env> pairs in a single call.

SEE ALSO:
@~include=related{"items":["concept:CI","command:ci-alpha","command:ci-auto","command:ci-manual","command:ci-parent","command:ci-repipe","command:ci-flow"]}
@~scope=ci
dox-command:ci-beta
cmd_ci_beta() {

	site_envs=()
	while (( $# )); do
		arg=$1 ; shift
		case ${arg} in
		(-*) bad_usage_no_opts ;;
		(*)  site_envs+=($arg) ;;
		esac
	done

	setup
	if [[ ${#site_envs} -eq 0 ]]; then
		must_be_in_an_environment
		site_envs+=("${DEPLOYMENT_SITE}/${DEPLOYMENT_ENVIRONMENT}")
	fi
	for site_env in "${site_envs[@]}"; do
		check_environment $site_env
		local site=${site_env%%/*}
		local env=${site_env#*/}
		ci_update <<EOF
---
sites:
  ${site}:
    beta: ${env}
    auto:
      ${env}: y
EOF
	done
}


: <<'dox-command:ci-auto'
USAGE
@~include=usage{"args":"[-p|--pipeline <name>] [<site>/<env> [... <siteN>/<envN>]]"}

DESCRIPTION
	Sets the specified or current environment as an automatically triggered
	enviroment within its associated site in the specified or default pipeline.

ARGUMENTS
	-p|--pipeline <name>
		the name of the pipeline to be configured.  Defaults to the deployment name

	<site>/<env>
		This is the path to the environment relative to the deployment root
		directory.  If this command is issued within an environment directory, it
		defaults to the current directory; otherwise, it is required.

		You can specify 0 or more <site>/<env> pairs in a single call.

SEE ALSO:
@~include=related{"items":["concept:CI","command:ci-alpha","command:ci-beta","command:ci-manual","command:ci-parent","command:ci-repipe","command:ci-flow"]}
@~scope=ci
dox-command:ci-auto
cmd_ci_auto() {
	site_envs=()
	while (( $# )); do
		arg=$1 ; shift
		case ${arg} in
		(-*) bad_usage_no_opts ;;
		(*)  site_envs+=($arg) ;;
		esac
	done

	setup
	if [[ ${#site_envs} -eq 0 ]]; then
		must_be_in_an_environment
		site_envs+=("${DEPLOYMENT_SITE}/${DEPLOYMENT_ENVIRONMENT}")
	fi
	for site_env in "${site_envs[@]}"; do
		check_environment $site_env
		local site=${site_env%%/*}
		local env=${site_env##*/}
		ci_update <<EOF
---
sites:
  ${site}:
    auto:
      ${env}: y
EOF
	done
}

: <<'dox-command:ci-manual'
USAGE
@~include=usage{"args":"[-p|--pipeline <name>] [<site>/<env> [... <siteN>/<envN>]]"}

DESCRIPTION
	Sets the specified or current environment as an manually triggered
	enviroment within its associated site in the specified or default pipeline.

ARGUMENTS
	-p|--pipeline <name>
		the name of the pipeline to be configured.  Defaults to the deployment name

	<site>/<env>
		This is the path to the environment relative to the deployment root
		directory.  If this command is issued within an environment directory, it
		defaults to the current directory; otherwise, it is required.

		You can specify 0 or more <site>/<env> pairs in a single call.

SEE ALSO:
@~include=related{"items":["concept:CI","command:ci-alpha","command:ci-beta","command:ci-auto","command:ci-parent","command:ci-repipe","command:ci-flow"]}
@~scope=ci
dox-command:ci-manual
cmd_ci_manual() {
	site_envs=()
	while (( $# )); do
		arg=$1 ; shift
		case ${arg} in
		(-*) bad_usage_no_opts ;;
		(*)  site_envs+=($arg) ;;
		esac
	done

	setup
	if [[ ${#site_envs} -eq 0 ]]; then
		must_be_in_an_environment
		site_envs+=("${DEPLOYMENT_SITE}/${DEPLOYMENT_ENVIRONMENT}")
	fi
	for site_env in "${site_envs[@]}"; do
		check_environment $site_env
		local site=${site_env%%/*}
		local env=${site_env##*/}
		case "$(ci_environment_type ${site} ${env})" in
		(alpha)
			cat >&2 <<EOF
${site}/${env} is currently the Alpha CI environment.

Alpha environments are automatically updated in response to changes made to global/,
new BOSH releases, stemcells, etc.

If you want to require manual approval for updates to ${site}/${env},
please first select a different Alpha environment.
EOF
			exit 2
			;;

		(beta)
			cat >&2 <<EOF
${site}/${env} is currently the Beta CI environment for ${site}.

Beta environments are automatically updated in response to changes made to global/,
${site}/site/, new BOSH releases, stemcells, etc.

If you want to require manual approval for updates to ${site}/${env},
please first select a different Beta environment for ${site}.
EOF
			exit 2
			;;
		esac
		ci_update --prune "sites[${site}].auto[${env}]" </dev/null
	done
}

: <<'dox-command:ci-parent'
USAGE
@~include=usage{"args":"[-p|--pipeline <name>] [<site>/<env>] <parent_env>"}
@~include=usage{"args":"[-p|--pipeline <name>] [<site>/<env>] -c|--clear"}

DESCRIPTION
	Sets the parent environment for specified or current environment in the
	specified or default pipeline.  If no parent is set, the beta environment
	for the site is assumed.

ARGUMENTS
	-p|--pipeline <name>
		the name of the pipeline to be configured.  Defaults to the deployment name

	<site>/<env>
		This is the path to the environment relative to the deployment root
		directory.  If this command is issued within an environment directory, it
		defaults to the current directory; otherwise, it is required.

SEE ALSO:
@~include=related{"items":["concept:CI","command:ci-alpha","command:ci-beta","command:ci-auto","command:ci-manual","command:ci-repipe","command:ci-flow"]}
@~scope=ci
dox-command:ci-parent
cmd_ci_parent() {
	local target parent_env clear_parent
	while (( $# )); do
		arg=$1 ; shift
		case ${arg} in
		(-c|--clear) clear_parent=1 ;;
		(-*) bad_usage_invalid_opt "$arg" ;;
		(*/*)
			[[ -z $target_site ]] || bad_usage_extra "$arg" "site/env" "$target_site/$target_env"
			target="${arg}"
			;;
		(*)
			[[ -z $parent_env ]] || bad_usage_extra "$arg" "parent-env" $parent_env
			parent_env="${arg}"
			;;
		esac
	done

	[[ -n $clear_parent && -n $parent_env ]] && bad_usage "Cannot specify -c|--clear and parent_env"

	setup
	local target_site=${target%%/*}
	local target_env=${target#*/}

	target_site=${target_site:-$DEPLOYMENT_SITE}
	target_env=${target_env:-$DEPLOYMENT_ENVIRONMENT}
	[[ -n $target_env ]] || bad_usage "<site>/<env> must be specified when not in an environment directory"
	check_environment "${target_site}/${target_env}"

	if [[ -n $clear_parent ]] ; then
		ci_update --prune "sites.[${target_site}].[${target_env}]" </dev/null
		echo "Task for $target_site/$target_env will be started after beta environment."
	else
		check_environment "${target_site}/${parent_env}"
		ci_update <<EOF
---
sites:
  ${target_site}:
    ${target_env}:
      parent: ${parent_env}
EOF
		echo "Task for $target_site/$target_env will be started after $target_site/$parent_env"
	fi
}
: <<'dox-command:ci-smoke-test'
USAGE
@~include=usage{"args":"[-p|--pipeline <name>] <errand>"}

DESCRIPTION
	Sets the smoke test errand for the specified or default pipeline.

ARGUMENTS
	-p|--pipeline <name>
		the name of the pipeline to be configured.  Defaults to the deployment name

	<errand>
		This is the name of the errand to run as a smoke test.

SEE ALSO:
@~include=related{"items":["concept:CI","command:ci-repipe","command:ci-flow"]}
@~scope=ci
dox-command:ci-smoke-test

cmd_ci_smoke_test() {
	local errand_name=
	while (( $# )); do
		arg=$1 ; shift
		case ${arg} in
		(-*) bad_usage_invalid_opt "$arg" ;;
		(*)
			[[ -z $errand_name ]] || bad_usage_extra "$arg" "errand" "$errand_name"
			errand_name="${arg}"
			;;
		esac
	done
	[[ -z ${errand_name} ]] && bad_usage_missing 'errand'

	setup
	ci_update <<EOF
---
smoke_test: ${errand_name}
EOF
}

ci_repipe_proto_job() {
	local job_name=${1:?ci_repipe_proto_job() - no job name given}

	cat <<EOF
jobs:
  - name: ${job_name}
    public: (( grab meta.public_pipeline ))
    serial: true
    plan:
      - aggregate:
          - get: world-changes
            resource: (( param "looks like genesis forgot to override the resource name" ))
          - get: local-changes
            resource: (( param "looks like genesis forgot to override the resource name" ))
      - task: (( param "looks like genesis forgot to override the task name" ))
        tags: (( param "looks like genesis forgot to override the task tags" ))
        config:
          platform: linux
          image_resource:
            type: docker-image
            source:
              repository: starkandwayne/concourse
              tag: latest
          inputs:
            - name: world-changes
            - name: local-changes
          outputs:
            - name: out
          run:
            path: world-changes/bin/genesis
            args: [ci, stage1]
          params:
            .: (( inject meta.env ))

            CI_PIPELINE:       (( grab \$CI_PIPELINE || "" ))
            CI_VAULT_APP_ID:   concourse
            CI_VAULT_USER_ID:  (( grab meta.secret ))

            CI_SITE_ENV:    (( param "looks like genesis forgot to override the CI_SITE_ENV variable" ))
            CI_BRANCH:      (( grab resources.git.source.branch ))
            CI_PRIVATE_KEY: (( grab resources.git.source.private_key ))
            CI_WAIT_FOR_CLEAN_BOSH: (( grab meta.pause_for_existing_bosh_tasks ))

            LOCAL_CHANGES:  local-changes
            WORLD_CHANGES:  world-changes
            WORKING_DIR:    out/git

            CI_BOSHES: |
EOF
	ci_bosh_configs
}

ci_tags_for() {
	local tag=${1?ci_tags_for() - no site_env_name given}
	if [[ -z $CI_TAGGED ]]; then
		echo "~"
	else
		echo "[${tag}]"
	fi
}

ci_bosh_configs() {
	need_a_vault

	local config=$(ci_boshes_yaml)
	if [[ -n $(spruce json ${config} | jq -r '.auth // ""') ]]; then
		spruce merge ${config} | sed -e 's/^/              /' || exit $?
	else
		need_a_workdir
		spruce merge ${config} | spruce json | jq -r '.["'"${site_env_name}"'"] // {}' > ${WORKDIR}/.bosh.yml
		spruce merge ${WORKDIR}/.bosh.yml | sed -e 's/^/              /' || exit $?
	fi
}

ci_repipe_smoke_test() {
	local job_name=${1:?ci_repipe_smoke_test() - no job name given}
	local errand_name=${2:?ci_repipe_smoke_test() - no errand name given}

	cat <<EOF
jobs:
  - name: ${job_name}
    plan:
      - (( append ))
      - task: smoke-test
        tags: $(ci_tags_for $site_env_name)
        config:
          platform: linux
          image_resource:
            type: docker-image
            source:
              repository: starkandwayne/concourse
              tag: latest
          inputs: [{name: out}]
          run:
            path: out/git/bin/genesis
            args: [ci, stage-smoke-test]
          params:
            .: (( inject meta.env ))

            WORKING_DIR: out/git
            CI_SITE_ENV: ${site_env}
            ERRAND_NAME: ${errand_name}

            CI_PIPELINE:       (( grab \$CI_PIPELINE || ""))
            CI_VAULT_APP_ID:   concourse
            CI_VAULT_USER_ID:  (( grab meta.secret ))
            CI_BOSHES: |
EOF
	ci_bosh_configs
}


ci_repipe_build_base() {
	need_a_workdir

	cat >${WORKDIR}/$(pipeline_yaml) <<EOF
---
meta:
  name: (( param "Please name this deployment pipeline (in ci/settings.yml)" ))
  public_pipeline: false
  pause_for_existing_bosh_tasks: false
  secret: (( concat meta.name "-pipeline" ))

  env: {}

  github:
    uri:          (( concat "git@github.com:" meta.github.owner "/" meta.github.repo ))
    owner:        (( param "Please specify the name of the user / organization that owns the Github repository (in ci/settings.yml)" ))
    repo:         (( param "Please specify the name of the Github repository (in ci/settings.yml)" ))
    branch:       master
    private_key:  (( param "Please generate an SSH Deployment Key for this repo and specify it in ci/settings.yml" ))

  slack:
    webhook:  (( param "Please provide a Slack Integration WebHook (in ci/settings.yml)" ))
    channel:  (( param "Please specify the channel (#name) or user (@user) to send messages to (in ci/settings.yml)" ))
    username: runwaybot
    icon:     http://cl.ly/image/3e1h0H3H2s0P/concourse-logo.png

resources:
  - name: git
    type: git
    source:
      uri:         (( grab meta.github.uri ))
      branch:      (( grab meta.github.branch ))
      private_key: (( grab meta.github.private_key ))
EOF

	if [[ -z $CI_SKIP_UPKEEP ]]; then
		cat >> ${WORKDIR}/$(pipeline_yaml) <<EOF
groups:
  - name: '*'
    jobs:
      - stemcells

  - name: upkeep
    jobs:
      - stemcells

jobs:
  - name: stemcells
    public: true
    serial: true
    plan:
      - aggregate:
        - get: git
      - task: update
        config:
          inputs:
            - name: git
          outputs:
            - name: out
          platform: linux
          image_resource:
            type: docker-image
            source:
              repository: starkandwayne/concourse
          run:
            path: git/bin/genesis
            args: [ ci, stemcells ]
          params:
            STEMCELLS: stemcells
            REPO_OUT:  out/git
      - put: git
        params:
          rebase: true
          repository: out/git
EOF
	fi
}

ci_repipe_build_environments() {
	local alpha_env=$(ci_alpha_environment)
	local alpha_name=$(ci_name ${alpha_env})
	local alpha_site=${alpha_env%%/*}

	need_a_workdir
	workdir="${WORKDIR}/repipe"
	mkdir -p ${workdir}
	cat <<EOF >${workdir}/09-all.yml
---
groups:
  - name: '*'
    jobs:
      - (( append ))
EOF
	cat <<EOF >${workdir}/08-groups.yml
---
groups:
  - name: '*'
  - name: α
    jobs:
      - $alpha_name

  - name: β
    jobs:
      - $alpha_name
EOF

	local rc=0
	for site in $(all_pipeline_sites); do
		if [[ ! -f ${DEPLOYMENT_ROOT}/${site}/site/stemcell/name ]]; then
			echo >&2 "Site ${site} has no defined stemcell"
			rc=1
		fi
	done
	if [[ $rc -ne 0 ]]; then
		exit $rc
	fi


	for site in $(all_pipeline_sites); do
		local site_name=$(ci_name ${site})
		local beta_env=$(ci_beta_environment_for ${site})
		local beta_name=$(ci_name ${beta_env})

		if [[ -n ${beta_name} ]]; then
			echo "      - ${beta_name}" >> ${workdir}/08-groups.yml
		fi

		local stemcell_alias=
		local stemcell_name=$(cat ${DEPLOYMENT_ROOT}/${site}/site/stemcell/name 2>/dev/null)
		case $stemcell_name in
		(*vsphere*) stemcell_alias=vsphere-stemcell ;;
		(*aws*hvm*) stemcell_alias=aws-hvm-stemcell ;;
		(*aws*)     stemcell_alias=aws-stemcell     ;;
		(*warden*)  stemcell_alias=warden-stemcell  ;;
		("")        stemcell_alias=empty            ;;
		(*)         stemcell_alias=${stemcell_name} ;;
		esac
		if [[ -z $CI_SKIP_UPKEEP ]]; then
			cat >${workdir}/77-${stemcell_alias}.yml <<EOF
---
resources:
  - name: ${stemcell_alias}
    type: bosh-io-stemcell
    source: { name: ${stemcell_name} }

jobs:
  - name: stemcells
    plan:
      - (( inline ))
      - aggregate:
        - (( append ))
        - get: ${stemcell_alias}
          trigger: true
          params: { tarball: true }
      - task: update
        config:
          inputs:
            - (( append ))
            - name: ${stemcell_alias}
              path: stemcells/${stemcell_name}
EOF
		fi

		if [[ -n ${beta_name} ]]; then
			cat >${workdir}/10-${site}.yml <<EOF
---
groups:
  - name: $site_name
    jobs:
      - $alpha_name # alpha
      - $beta_name  # beta
EOF
		fi

		local smoke_test=$(ci_smoke_test)

		for env in $(all_environments_for ${site}); do
			local env_type=$(ci_environment_type ${site} ${env})
			local env_name=$(ci_name ${env})
			local site_env=${site}/${env}
			local site_env_name=$(ci_name ${site_env})
			local parent_env=$(ci_parent_environment_for ${site} ${env})
			local parent_env_name=$(ci_name ${parent_env})

			cat >>${workdir}/09-all.yml <<EOF
      - $site_env_name
EOF

			if [[ -n ${smoke_test} ]]; then
				ci_repipe_smoke_test ${site_env_name} ${smoke_test} > ${workdir}/59-${site_env_name}.yml
			fi

			ci_repipe_proto_job ${site_env_name} > ${workdir}/50-${site_env_name}.yml || exit 5
			case ${env_type} in
			(alpha)
				cat >${workdir}/51-${site_env_name}.yml <<EOF
---
resources:
  # changes that trigger the alpha environment

  ##########################################################################
  #
  #   global-changes      Changes made to the global/ definitions,
  #                       (and the alpha environment's site, for continuity)
  #
  - name: global-changes
    .: (( inject resources.git ))
    source:
      paths:
        - bin/genesis
        - global

  ##########################################################################
  #
  #   {env}-changes     Changes that only affect the current environment
  #                     (i.e. property changes, re-IPing, creds, etc.)
  #
  - name: ${alpha_name}-changes
    .: (( inject resources.git ))
    source:
      paths:
        - ${alpha_site}/site
        - ${alpha_env}
        - ${alpha_env}/*.yml

  ##########################################################################
  #
  #   α-changes         Changes that come from previous steps in the
  #                     pipeline, from a successful build in alpha.
  #                     (this will trigger beta builds)
  #
  - name: α-changes
    .: (( inject resources.git ))
    source:
      paths:
        - ${alpha_env}/.global

jobs:
  # alpha environment
  - name: ${site_env_name}
    plan:
      - (( inline ))
      - aggregate:
        - (( merge on get ))

        - get: world-changes
          resource: global-changes
          trigger: true

        - get: local-changes
          resource: ${alpha_name}-changes
          trigger: true

      - task: ${site_env_name}
        tags: $(ci_tags_for $site_env_name)
        config:
          params:
            CI_SITE_ENV: ${site_env}
        # PUT to the beta inputs
      - put: α-changes
        params: { repository: out/git, rebase: true }
EOF
				;;

			(beta)
				cat >${workdir}/51-${site_env_name}.yml <<EOF
---
resources:
  # changes that trigger the beta environment

  ##########################################################################
  #
  #   {site}-changes    Changes that only affect the current environment
  #                     (i.e. property changes, re-IPing, creds, etc.)
  #
  - name: ${site}-changes
    .: (( inject resources.git ))
    source:
      paths:
        - ${site}/site
        - ${beta_env}
        - ${beta_env}/*.yml

  ##########################################################################
  #
  #   {site}-β-changes  Changes that come from previous steps in the
  #                     pipeline, from a successful build in alpha.
  #
  - name: ${site}-β-changes
    .: (( inject resources.git ))
    source:
      paths:
        - ${beta_env}/.site
        - ${beta_env}/.global

jobs:
  # beta environment
  - name: ${site_env_name}
    plan:
      - (( inline ))
      - aggregate:
        - (( merge on get ))

        - get: world-changes
          resource: α-changes
          trigger: true
          passed: [${alpha_name}]

        - get: local-changes
          resource: ${site}-changes
          trigger: true

      - task: ${site_env_name}
        tags: $(ci_tags_for $site_env_name)
        config:
          params:
            CI_SITE_ENV: ${site_env}
        # PUT to the gamma inputs
      - put: ${site}-β-changes
        params: { repository: out/git, rebase: true }
EOF
				;;

			(gamma)
				cat >>${workdir}/10-${site}.yml <<EOF
      - $site_env_name # gamma
EOF
				cat >${workdir}/51-${site_env_name}.yml <<EOF
---
resources:
  # changes that trigger the gamma environment

  ##########################################################################
  #
  #   {env}-changes     Changes that only affect the current environment
  #                     (i.e. property changes, re-IPing, creds, etc.)
  #
  - name: ${site_env_name}-changes
    .: (( inject resources.git ))
    source:
      paths:
        - ${site_env}
        - ${site_env}/*.yml

jobs:
  # gamma environment
  - name: ${site_env_name}
    plan:
      - (( inline ))
      - aggregate:
        - (( merge on get ))

        - get: world-changes
          resource: ${site}-β-changes
          trigger: true
          passed: [${parent_env_name}]

        - get: local-changes
          resource: ${site_env_name}-changes
          trigger: true

      - task: ${site_env_name}
        tags: $(ci_tags_for $site_env_name)
        config:
          params:
            CI_SITE_ENV: ${site_env}
        # PUT to git
      - put: git
        params: { repository: out/git, rebase: true }
EOF
				;;

			(omega)
				cat >>${workdir}/09-all.yml <<EOF
      - ${site_env_name}-notif
EOF
				cat >>${workdir}/10-${site}.yml <<EOF
      - $site_env_name # omega
      - ${site_env_name}-notif
EOF
				cat >${workdir}/51-${site_env_name}.yml <<EOF
---
resources:
  # changes that trigger the omega environment

  ##########################################################################
  #
  #   {env}-changes     Changes that only affect the current environment
  #                     (i.e. property changes, re-IPing, creds, etc.)
  #
  - name: ${site_env_name}-changes
    .: (( inject resources.git ))
    source:
      paths:
        - ${site_env}
        - ${site_env}/*.yml

jobs:
  # omega environment
  - name: ${site_env_name}-notif
    plan:
      - aggregate:
        - get: world-changes
          resource: ${site}-β-changes
          passed: [${parent_env_name}]
          trigger: true

        - get: local-changes
          resource: ${site_env_name}-changes
          trigger: true

      - task: draft-message
        tags: $(ci_tags_for $site_env_name)
        config:
          platform: linux
          image_resource:
            type: docker-image
            source:
              repository: starkandwayne/concourse
              tag: latest
          inputs:
            - name: world-changes
            - name: local-changes
          outputs:
            - name: out
          run:
            path: world-changes/bin/genesis
            args: [ci, draft-message]
          params:
            LOCAL_CHANGES:  local-changes
            WORLD_CHANGES:  world-changes
            CI_SITE_ENV:    ${site_env}
            DRAFT_FILE:     out/notif

  - name: ${site_env_name}
    plan:
      - (( inline ))
      - aggregate:
        - (( merge on get ))

        - get: world-changes
          resource: ${site}-β-changes
          passed: [${site_env_name}-notif]
          trigger: false

        - get: local-changes
          resource: ${site_env_name}-changes
          passed: [${site_env_name}-notif]
          trigger: false

      - task: ${site_env_name}
        tags: $(ci_tags_for $site_env_name)
        config:
          params:
            CI_SITE_ENV: ${site_env}
        # PUT to git
      - put: git
        params: { repository: out/git, rebase: true }
EOF
				case $CI_NOTIFICATION_SCHEME in
				(email)
					cat >${workdir}/52-${site_env_name}.yml <<EOF
meta:
  slack: (( empty hash ))
resources:
  - name: build-email
    type: script
    source:
      filename: run
      body: |
        #!/bin/bash
        mkdir -p email
        rm -rf email/*
        echo "X-Concourse-Site-Env: ${CI_SITE_ENV}" >>email/header
        head -n1 out/notif > email/subject
        sed -e 's/\`\`\`//' out/notif > email/body

  - name: send-email
    type: email
    source:
      to:   (( grab meta.email.to ))
      from: (( grab meta.email.from ))
      smtp:
        host:     (( grab meta.email.smtp.host ))
        port:     (( grab meta.email.smtp.port ))
        username: (( grab meta.email.smtp.username ))
        password: (( grab meta.email.smtp.password ))

resource_types:
  - name: script
    type: docker-image
    source:
      repository: cfcommunity/script-resource

  - name: email
    type: docker-image
    source:
      repository: pcfseceng/email-resource

jobs:
  # omega environment
  - name: ${site_env_name}-notif
    plan:
    - (( append ))
    - do:
      - get: build-email
      - task: write-email-body
        config:
          platform: linux
          image_resource:
            type: docker-image
            source:
              repository: ubuntu

          inputs:
          - name: build-email
          - name: out
          outputs:
          - name: email

          run:
            path: build-email/run
            args: []

      - put: send-email
        params:
          body:    email/body
          headers: email/header
          subject: email/subject
EOF
				  ;;
				(slack)
					cat >${workdir}/52-${site_env_name}.yml <<EOF
meta:
  email: (( empty hash ))
resources:
  - name: notification
    type: slack-notification
    source:
      url: (( grab meta.slack.webhook ))

resource_types:
  - name: slack-notification
    type: docker-image
    source:
      repository: cfcommunity/slack-notification-resource

jobs:
  # omega environment
  - name: ${site_env_name}-notif
    plan:
      - (( append ))
      - put: notification
        params:
          text_file: out/notif
          username: (( grab meta.slack.username ))
          channel:  (( grab meta.slack.channel ))
          icon_url: (( grab meta.slack.icon ))
EOF
				  ;;
				esac
				;;
			esac
		done
	done
}

ci_repipe_merge() {
	target=${1:-$(pipeline_yaml)}
	mkdir -p ${DEPLOYMENT_ROOT}/ci

	need_command spruce
	spruce $SPRUCE_OPTS merge --prune meta \
	       ${WORKDIR}/$(pipeline_yaml) \
	       ${WORKDIR}/repipe/*.yml \
	       $(actual_yaml_files $(ci_settings_yaml)) > ${DEPLOYMENT_ROOT}/ci/${target}
}

: <<'dox-command:ci-repipe'
USAGE
@~include=usage{"args":"[-p|--pipeline <name>] [-d|--draft]"}

DESCRIPTION
  Generate the given or default CI pipeline and push it to Concourse.

ARGUMENTS
	-p|--pipeline <name>
		the name of the pipeline to be configured.  Defaults to the deployment name

  -d|--draft
		Don't push the pipeline, instead output it to STDOUT

SEE ALSO
@~include=related{"items":["concept:CI","command:ci-alpha","command:ci-beta","command:ci-auto","command:ci-manual","command:ci-parent","command:ci-flow"]}
@~scope=ci
dox-command:ci-repipe
cmd_ci_repipe() {

	local draft=""
	while (( $# )); do
		arg=$1 ; shift
		case ${arg} in
		(-d|--draft) draft=1 ;;
		(-*)         bad_usage_invalid_opt "$arg" ;;
		(*)          bad_usage_extra       "$arg" ;;
		esac
	done

	setup
	ci_check_configuration
	need_a_workdir
	need_a_vault

	CI_TAGGED=$(     spruce json $(ci_settings_yaml) | jq -r '.meta.tagged // ""')
	CI_SKIP_UPKEEP=$(spruce json $(ci_settings_yaml) | jq -r '.meta.skip_upkeep // ""')
	CI_NOTIFICATION_SCHEME=none
	for scheme in slack email; do
		if [[ -n $(spruce json $(ci_settings_yaml) | jq -r '.meta.'"$scheme"' // ""') ]]; then
			CI_NOTIFICATION_SCHEME=$scheme
		fi
	done

	ci_repipe_build_base
	VAULT_ADDR= REDACT=y ci_repipe_build_environments || exit 2
	VAULT_ADDR= REDACT=y ci_repipe_merge $(pipeline_yaml) || exit 3

	            REDACT=  ci_repipe_build_environments || exit 4
	            REDACT=  ci_repipe_merge .deploy.yml  || exit 5
	[[ -n $DEBUG_LEAVE_THE_CREDS_THERE ]] || \
		trap "rm -f ${DEPLOYMENT_ROOT}/ci/.deploy.yml" QUIT TERM INT EXIT

	CI_TARGET_NAME=$(spruce json $(ci_settings_yaml) | jq -r '.meta.target // ""')
	CI_PIPE_NAME=$(  spruce json $(ci_settings_yaml) | jq -r '.meta.name // ""')

	echo
	if [[ -z $draft ]] ; then
		echo "Configuring pipeline at ${CI_TARGET_NAME} (${CI_TARGET_URL})"
		fly -t ${CI_TARGET_NAME:-concourse} set-pipeline -p ${CI_PIPE_NAME:-pipeline} -c ${DEPLOYMENT_ROOT}/ci/.deploy.yml
		exit $?
	else
		cat "${DEPLOYMENT_ROOT}/ci/.deploy.yml"
	fi
}


: <<'dox-command:ci-flow'
USAGE
@~include=usage{"args":"[-p|--pipeline <name>] [-d|--draft]"}

DESCRIPTION
	Generate the given or default CI pipeline and push it to Concourse.

ARGUMENTS
	-p|--pipeline <name>
		the name of the pipeline to be configured.  Defaults to the deployment name

SEE ALSO
@~include=related{"items":["concept:CI","command:ci-alpha","command:ci-beta","command:ci-auto","command:ci-manual","command:ci-parent","command:ci-repipe"]}
@~scope=ci
dox-command:ci-flow
cmd_ci_flow() {
	[[ -z $1 ]] || bad_usage

	setup
	# FIXME: ascii diagram!
	local yaml_file="$(ci_pipeline_yaml)"
	if [[ -f "${yaml_file}" ]] ; then
		cat "${yaml_file}"
	else
		echo 'No CI defined.  See `genesis help CI` for more information'$'\n'
		exit 1
	fi
}

# Commands that are used by Concourse pipelines themselves

cmd_ci_stemcells() {
	[[ -z $1 ]] || bad_usage "ci stemcells"

	if [[ -z ${STEMCELLS} ]]; then
		echo >&2 "!! ERROR: Your Concourse Pipeline seems to be MISCONFIGURED !!"
		echo >&2
		echo >&2 "The \$STEMCELLS environment variable was not set."
		echo >&2
		echo >&2 "This environment variable tells genesis where to find the"
		echo >&2 "downloaded stemcells, for checksumming and version querying."
		exit 2
	fi
	if [[ ! -d ${STEMCELLS} ]]; then
		echo >&2 "!! ERROR: Your Concourse Pipeline seems to be MISCONFIGURED !!"
		echo >&2
		echo >&2 "The \$STEMCELLS environment variable seems to be incorrect."
		echo >&2
		echo >&2 "Failed to find stemcell path '${STEMCELLS}',"
		echo >&2 "starting from '$(pwd)'..."
		exit 2
	fi

	REPO_IN=$(cd $(dirname ${BASH_SOURCE[0]})/..; pwd)
	for dir in ${STEMCELLS}/*; do
		local name=${dir##*/}
		local vers=$(cat ${dir}/version)
		local sha1=$(cat ${dir}/stemcell.tgz | checksum | awk '{print $1}')
		local url=$(cat ${dir}/url)

		pushd ${REPO_IN} >/dev/null
			for site in */site; do
				if [[ $(cat ${site}/stemcell/name 2>/dev/null) == ${name} ]]; then
					echo ${vers} > ${site}/stemcell/version
					echo ${sha1} > ${site}/stemcell/sha1
					echo ${url} > ${site}/stemcell/url
				fi
			done
		popd >/dev/null
	done

	pushd ${REPO_IN} >/dev/null
		ci_commit "upgrade stemcells via pipeline"
	popd >/dev/null
	[ -n ${REPO_OUT} ] && cp -a ${REPO_IN} ${REPO_OUT}/
	exit 0
}

cmd_ci_stage1() {
	[[ -z $1 ]] || bad_usage "ci stage1"

	if [[ -z ${WORKING_DIR} ]]; then
		echo >&2 "!! ERROR: Your Concourse Pipeline seems to be MISCONFIGURED !!"
		echo >&2
		echo >&2 "The \$WORKING_DIR environment variable was not set."
		echo >&2
		echo >&2 "This environment variable tells genesis where to find the"
		echo >&2 "committed changes to this deployment manifest, so that Concourse"
		echo >&2 "can push the updatees back to origin properly."
		exit 2
	fi

	cp -a ${LOCAL_CHANGES} ${WORKING_DIR}
	if [[ ! -d ${WORKING_DIR} ]]; then
		echo >&2 "Failed to copy the git working copy from"
		echo >&2 "${LOCAL_CHANGES}"
		echo >&2 "to"
		echo >&2 "${WORKING_DIR}"
		echo >&2
		exit 2
	fi

	line
	echo "Pulling in latest copy of ${CI_BRANCH}"
	echo "(this avoids spurious git conflicts later)"
	echo
	pushd ${WORKING_DIR}/${CI_SITE_ENV} >/dev/null
		need_ci_git_access
		git pull origin ${CI_BRANCH} # in case we want to test...
	popd

	line
	echo "Invoking stage2 of the Genesis CI pipeline"
	echo
	exec ${WORKING_DIR}/bin/genesis ci stage2
}

cmd_ci_stage2() {
	[[ -z $1 ]] || bad_usage "ci stage2"

	line
	echo "Setting up .bosh_config with values from ci/boshes.yml"
	echo
	cat >~/.bosh_config<<EOF
${CI_BOSHES}
EOF
	ls -l ~/.bosh_config
	echo

	local target=$(spruce json ${WORKING_DIR}/${CI_SITE_ENV}/director.yml | jq -r '.director_uuid')
	line
	echo "Targeting BOSH director ${target}"
	echo
	bosh target ${target}

	if [[ $? != 0 ]]; then
		echo "Could not target BOSH director"
		exit 1
	fi

	line
	echo "Probing environment for information..."
	# figure out our environment type
	pushd ${WORKING_DIR}/${CI_SITE_ENV} >/dev/null
		CI_SITE=$(setup; must_be_in_an_environment; echo $DEPLOYMENT_SITE)
		CI_ENV=$( setup; must_be_in_an_environment; echo $DEPLOYMENT_ENVIRONMENT)

		local env_type=$(setup; must_be_in_an_environment;
			ci_environment_type ${DEPLOYMENT_SITE} ${DEPLOYMENT_ENVIRONMENT})

		local alpha_env=$(setup; must_be_in_an_environment;
			ci_alpha_environment)

		local beta_env=$(setup; must_be_in_an_environment;
			ci_beta_environment_for ${CI_SITE})
	popd
	echo "        CI_SITE_ENV: ${CI_SITE_ENV}"
	echo "            CI_SITE: ${CI_SITE}"
	echo "             CI_ENV: ${CI_ENV}"
	echo "   Environment Type: ${env_type}"
	echo "  Alpha Environment: ${alpha_env}"
	echo "   Beta Environment: ${beta_env}"
	echo

	line
	echo "Updating .site and .global copies from known good values"

	rm -rf ${WORKING_DIR}/${CI_SITE_ENV}/.global
	rm -rf ${WORKING_DIR}/${CI_SITE_ENV}/.site
	case ${env_type} in
	(alpha)
		echo "... in ALPHA environment"
		echo
		echo "copy world/global -> ${CI_SITE_ENV}/.global"
		echo "copy local/${CI_SITE}/site -> ${CI_SITE_ENV}/.site"
		echo
		cp -a ${WORLD_CHANGES}/global                ${WORKING_DIR}/${CI_SITE_ENV}/.global
		cp -a ${LOCAL_CHANGES}/${CI_SITE}/site       ${WORKING_DIR}/${CI_SITE_ENV}/.site
		;;
	(beta)
		echo "... in BETA environment"
		echo
		echo "copy world/${alpha_env}/.global -> ${CI_SITE_ENV}/.global"
		echo "copy world/${CI_SITE}/site -> ${CI_SITE_ENV}/.site"
		echo
		cp -a ${WORLD_CHANGES}/${alpha_env}/.global  ${WORKING_DIR}/${CI_SITE_ENV}/.global
		cp -a ${LOCAL_CHANGES}/${CI_SITE}/site       ${WORKING_DIR}/${CI_SITE_ENV}/.site
		;;
	(*)
		echo
		echo "copy world/${beta_env}/.global -> ${CI_SITE_ENV}/.global"
		echo "copy world/${beta_env}/.site -> ${CI_SITE_ENV}/.site"
		cp -a ${WORLD_CHANGES}/${beta_env}/.global   ${WORKING_DIR}/${CI_SITE_ENV}/.global
		cp -a ${WORLD_CHANGES}/${beta_env}/.site     ${WORKING_DIR}/${CI_SITE_ENV}/.site
		;;
	esac

	pushd ${WORKING_DIR}/${CI_SITE_ENV} >/dev/null
		setup
		must_be_in_an_environment

		line
		echo "Generating manifest (live.yml)..."
		echo
		set -e
		need_a_vault
		preflight_deployment
		(VAULT_ADDR= REDACT=y cmd_build live.yml)    || exit 3
		(            REDACT=  cmd_build .deploy.yml) || exit 4

		local target=$(spruce json ${DEPLOYMENT_ENV_DIR}/manifests/live.yml | jq -r '.director_uuid')
		line
		echo "Deploying to BOSH director ${target}"
		echo

		if [[ ${CI_WAIT_FOR_CLEAN_BOSH} == "true" ]]; then
			i=1
			attempts=10
			wait=10
			echo "Checking if BOSH has any tasks running... (for up to $(( $attempts * $wait )) seconds)"

			while (( $i <= $attempts ))
			do
				bosh target $(spruce json ${DEPLOYMENT_ENV_DIR}/name.yml | jq -r '.name')
				unset DIRECTOR_URL
				tasks=$(ask_bosh '/tasks?state=queued,processing,cancelling&verbose=2')
				if [[ -z "${tasks}" || $? != 0 ]]; then
					echo "FATAL: Unable to contact BOSH to find existing tasks before deploying. Cowardly refusing to deploy"
					exit 1
				fi

				running=$(echo "${tasks}" | jq -r '. | length')
				if [[ $? != 0 ]]; then
					echo "FATAL: Unexpected task output from BOSH. Cowardly refusing to deploy"
					echo "Unexpected response:"
					echo
					cat << EOF
$tasks
EOF
					exit 1
				fi

				if [[ $running == 0 ]]; then
					echo "BOSH has no tasks currently running. Starting deployment..."
					break
				fi

				echo "BOSH has tasks running, sleeping for $wait seconds"
				sleep $wait
				((i+=1))
			done

			if [[ $i -gt $attempts ]]; then
				bosh tasks --no-filter
				echo "BOSH still has running tasks.  Aborting..."
				exit 1
			fi
		fi

		unset DIRECTOR_URL
		bosh target ${target}
		bosh deployment ${DEPLOYMENT_ENV_DIR}/manifests/.deploy.yml
		bosh -n deploy

		line
		echo "Committing changes to git repository..."
		echo
		if [[ -z ${GIT_MESSAGE} ]]; then
			GIT_MESSAGE="[${CI_SITE_ENV}] deployed via pipeline"
		fi
		ci_commit "${GIT_MESSAGE}"
		set +e
	popd >/dev/null

	line
	echo "COMPLETE"

	exit 0
}

cmd_ci_stage_smoke_test() {
	if [[ -z ${WORKING_DIR} ]]; then
		echo >&2 "!! ERROR: Your Concourse Pipeline seems to be MISCONFIGURED !!"
		echo >&2
		echo >&2 "The \$WORKING_DIR environment variable was not set."
		exit 2
	fi

	echo "Setting up .bosh_config with values from ci/boshes.yml"
	echo
	cat >~/.bosh_config<<EOF
${CI_BOSHES}
EOF
	ls -l ~/.bosh_config
	echo

	local target=$(spruce json ${WORKING_DIR}/${CI_SITE_ENV}/director.yml | jq -r '.director_uuid')
	line
	echo "Targeting BOSH director ${target}"
	echo
	bosh target ${target}

	line
	pushd ${WORKING_DIR}/${CI_SITE_ENV} >/dev/null
		setup
		must_be_in_an_environment

		line
		echo "Generating manifest (live.yml)..."
		echo
		set -e
		need_a_vault
		preflight_deployment
		(VAULT_ADDR= REDACT=y cmd_build live.yml)    || exit 3
		(            REDACT=  cmd_build .deploy.yml) || exit 4

		local target=$(spruce json ${DEPLOYMENT_ENV_DIR}/manifests/live.yml | jq -r '.director_uuid')
		line
		echo "Running Errand ${ERRAND_NAME} on BOSH director ${target}"
		echo
		bosh target ${target}
		bosh deployment ${DEPLOYMENT_ENV_DIR}/manifests/.deploy.yml
		bosh -n run errand ${ERRAND_NAME}
		set +e
	popd >/dev/null
}

cmd_ci_draft_message() {
	[[ -z $1 ]] || bad_usage "ci draft-message"

	(
		echo "[${CI_SITE_ENV}] Deployment changes are ready to go!"
		echo
		echo "World:"
		echo "\`\`\`"
		(cd $WORLD_CHANGES && git log -n1)
		echo "\`\`\`"
		echo
		echo "Local:"
		echo "\`\`\`"
		(cd $LOCAL_CHANGES && git log -n1)
		echo "\`\`\`"
	)>${DRAFT_FILE}
}

cmd_ci_check() {
	[[ -z $1 ]] || bad_usage "ci check"

	ci_check_configuration
}

bad_ci() {
	local cmd=${1}
	cat >&2 <<EOF
USAGE:  genesis ci [-p pipeline] alpha [site/env]
        genesis ci [-p pipeline] beta [site/env [site/env ...]]
        genesis ci [-p pipeline] auto [site/env [site/env ...]]
        genesis ci [-p pipeline] manual [site/env [site/env ...]]
        genesis ci [-p pipeline] smoke-test <errand>
        genesis ci [-p pipeline] repipe
        genesis ci [-p pipeline] flow
        genesis ci [-p pipeline] check
EOF
	exit 1
}

: <<'dox-command:bosh'
USAGE
@~include=usage{"args":"<args...>"}

DESCRIPTION
	Run a bosh command against a freshly generated non-redacted BOSH manifest
	from the current environment directory.

	For configurations that don't make use of Vault, this is equivalent of
	building the manifest and adding '-d manifests/manifests.yml' to the BOSH
	command.  When vault operators are present in the source yml files, this is
	the only way run BOSH command using a manifest since the one built in the
	manifests directory will have all vault values redacted.

	Similarly, it provides an alternative method for running `make deploy` with
	further arguments, such as --recreate.

	All BOSH commands are available, but may not necessarily benefit from the
	manifest re-generation step.

ARGUMENTS
	The arguments expected for this command are exactly what you'd specify for a
	normal bosh CLI command, less the -d option which this adds for you.  See
	`bosh help <command>` for help on the desired bosh command.

EXAMPLES
  Rebuild the worker/1 job:
  $ genesis bosh -t prod recreate worker 1

  SSH into etcd/0 instance
  $ genesis bosh ssh etcd/0

  Dry-run of a deploy while showing all changes:
  $ genesis bosh deploy --dry-run --no-redact

SEE ALSO
@~include=related{"items":["concept:Makefiles","concept:Vault-Secrets"]}
dox-command:bosh
cmd_bosh() {
	# NOTE: cmd_bosh specifically avoids argv inspection
	must_be_in_an_environment

	case ${DEPLOYMENT_TYPE} in
	(normal)
		skip_preflight
		(REDACT= cmd_build .deploy.yml) || exit 3
		[[ -n $DEBUG_LEAVE_THE_CREDS_THERE ]] || \
			trap "rm -f ${DEPLOYMENT_ENV_DIR}/manifests/.deploy.yml" QUIT TERM INT EXIT

		bosh -d ${DEPLOYMENT_ENV_DIR}/manifests/.deploy.yml $@
		exit $?
		;;

	(bosh-init)
		echo >&2 "Please use the 'genesis bosh-init' command instead."
		exit 1
		;;
	esac
}

cmd_boshinit() {
	# NOTE: cmd_bosh specifically avoids argv inspection
	must_be_in_an_environment

	case ${DEPLOYMENT_TYPE} in
	(bosh-init)
		skip_preflight
		(REDACT= cmd_build .deploy.yml) || exit 3
		[[ -n $DEBUG_LEAVE_THE_CREDS_THERE ]] || \
			trap "rm -f ${DEPLOYMENT_ENV_DIR}/manifests/.deploy.yml" QUIT TERM INT EXIT

		bosh-init $@ ${DEPLOYMENT_ENV_DIR}/manifests/.deploy.yml

		exit $?
		;;

	(normal)
		echo >&2 "Please use the 'genesis bosh' command instead."
		exit 1
		;;
	esac

}

cmd_dump() {
	[[ -z $1 ]] || bad_usage "dump"

	setup
	printf "name: %s\n" ${DEPLOYMENT_NAME}
	printf "type: %s\n" ${DEPLOYMENT_TYPE}
	printf "root: %s\n" ${DEPLOYMENT_ROOT}
	printf "site: %s\n" ${DEPLOYMENT_SITE}
	printf "env:  %s\n" ${DEPLOYMENT_ENVIRONMENT}
	exit 0
}

checksum() {
	if [[ -z $(command -v sha1sum) ]]; then
		shasum "$@"
	else
		sha1sum "$@"
	fi
}

: <<'dox-command:help'
NAME
	help - Display help on genesis concepts and commands

USAGE
@~include=usage{"args":[" ","--topics","--<category>","[--<category>] <topic>"]}

DESCRIPTION
	Get help on how to use `genesis`.

	With no arguments, will print this help message.  By specifying a category,
	the list of topics in that category will be specified.  The available
	categories are:
@~include=categories{"leader":"    * "}

  You can also specify --topics to get a list of all topics in all categories.

	For detailed help on a given topic, you can specify that topic as an argument
	to the help command.  For topics that are composed of multiple words, do
	*not* wrap the topic in quotes.  In the rare case that the topic appears in
	multiple categories, you can specify the category type as an double-hyphenated
	option.
dox-command:help

cmd_help() {
	local category=""
	local topic=""
	while (( $# )); do
		arg="$1"; shift
		case "${arg}" in
		(--*) [[ -z "$category" ]] && category="${arg:2}" || bad_usage "Can only specify one category" ;;
		(-*) bad_usage_invalid_opt "$arg";;
		(*)  topic="${topic:+"${topic}-"}${arg}" ;;
		esac
	done

	local result=$(__dox_get_help "$category" "$topic")
	if [[ $? -ne 0 ]] ; then
		echo >&2 "ERROR: Could not fetch help - fatal internal error"
		exit 1
	fi

	local pager="cat"
	# TODO: The following pages if output is bigger than the current screen - is
	#				this a good idea?
	#local rows="$(stty -a | head -1 | tr ';' "\n" | grep rows | sed -e 's/^[^0-9]*\([0-9]\{1,\}\).*$/\1/')"
	#[[ "$rows" -gt 1 && "$(echo "$result" | wc -l)" -ge "$rows" ]] && pager="less"
	echo "$result"$'\n' | $pager
}

bad_usage() {
  local msg="${1:-bad usage}" callee=${2:-${FUNCNAME[1]}}

  local callee_bits=( ${callee//_/ } )
  local category="${callee_bits[0]}"
  local name=( "${callee_bits[@]:1}" )
  local cmd=$(IFS='-'; echo "${name[*]}")

  [[ "$category" == "cmd" ]] && category="command"
  local content="$(__dox_get_usage "$cmd" "$category")"
  local prefix="[$SCRIPT_NAME${name:+ ${name[@]}}] "
  echo >&2 $'\n'"$(__dox_reflow_text "ERROR: ${msg}" "${prefix//?/ }" "$prefix")"
  echo >&2 "$(__dox_process_content "USAGE"$'\n'"${content}")"
  echo >&2 $'\n'"For more details, run \`${SCRIPT_NAME} help <command>\` for the desired command."$'\n'
  exit 1
}
bad_usage_invalid_opt() { bad_usage "invalid option '$1'" "${FUNCNAME[1]}"; }
bad_usage_no_args()     { bad_usage "does not take any options or arguments" "${FUNCNAME[1]}"; }
bad_usage_no_opts()     { bad_usage "does not take any options" "${FUNCNAME[1]}"; }
bad_usage_missing()     { bad_usage "required argument for '$1' not provided" "${FUNCNAME[1]}"; }
bad_usage_extra()       { bad_usage "extraneous argument '${1}'${2:+"; $2 already provided as '$3'"}" "${FUNCNAME[1]}"; }

bad_usage_partial() {
	local cmd="$1" subcmd="$2"
	if [[ -n "$subcmd" ]] ; then
		bad_usage "invalid subcommand '${subcmd}'${cmd:+" for command '${cmd}'"}" "partial_${cmd}"
	else
		bad_usage "missing subcommand for '${cmd}' command" "partial_${cmd}"
	fi
}

check_opt_usage() {
	if [[ -z "$2" || "${2:0:1}" == '-' ]] ; then
		bad_usage "missing value for option $1" "${FUNCNAME[1]}"
	fi
}

__dox_get_help() {
  local category="$1" topic="$2"
	[[ -z "${topic}" && -z "${category}" ]] && { category="command"; topic="help"; }
	if [[ -z "${topic}" ]] ; then
		[[ "$category" == 'topics' ]] && { category='' ; } # --topics is a meta-topic of all topics
		IFS=$'\n' read -rd '' -a categories <<< "$(__dox_get_topics '' "$category" | sed 's/:.*//' | sort | uniq )"
		echo ""
		if [[ "${#categories[@]}" -eq 0 ]] ; then
			echo >&2 $'\n'"[$SCRIPT_NAME help] ERROR: No help category matching '$category'"
			echo >&2 $'\n''For information on available help topics, run `'"${SCRIPT_NAME}"' help --topics`'
			exit 2
		fi
		for category in "${categories[@]}" ; do
			[[ "${category}" == "partial" ]] && continue
			local _header="Available '${category}' help topics:"
			echo "${_header}"$'\n'"${_header//?/-}"
			__dox_generate_topic_includes '{"category":"'$category'","desc":"inline","leader":"  * "}'
			echo ""
		done
		exit 0
	fi

	local topic_list=( $(__dox_get_topics "$topic" "$category" ) )
	if [[ "${#topic_list[@]}" -eq 0 ]] ; then
		# Check for aliases
		if grep '^@~alias=\(.*,\)\{0,\}'"$topic"'\(,.*\)\{0,\}' $0 >/dev/null 2>&1; then
			topic_list=( $(__dox_get_topics '' "$category" '' "$topic" ) )
		fi
	fi
	if [[ ${#topic_list[@]} -eq 1 ]] ; then
		# Only one potential match
		IFS=':' read category topic <<< "${topic_list[0]}"
	elif [[ ${#topic_list[@]} -eq 0 ]] ; then
		__dox_not_found
	else
		local exact_match
		exact_match=( $(printf -- '%s\n' "${topic_list[@]}" | grep ':'"$topic"'$') )
		if [[ ${#exact_match[@]} -eq 1 ]] ; then
			IFS=':' read category topic <<< "${exact_match[0]}"
		else
			__dox_ambiguous_topic "$topic" "${topic_list[@]}"
			return 2
		fi
	fi

	if [[ "$category" == 'partial' ]] ; then
		__dox_ambiguous_topic "$topic"
		return 0
	else
		category="${category:-command}"
		local content="$(__dox_get_content "${topic}" "${category}")"
		__dox_process_content "$content"
	fi
	return 0
}
__dox_get_content() {
	#echo >&2 "======"$'\n'"DEBUG: called '${FUNCNAME[0]}' with "$'\n'" --($@)--"$'\n'"^^^^^^"
	local topic="$1" category="${2:-'command'}"
	local pattern="$(echo "dox-${category}:${topic}" | tr " " "-")"
	# Check if content is present
	if grep "^: <<'$pattern'\$" $0 >/dev/null 2>&1 && grep "^$pattern\$" $0 >/dev/null 2>&1; then
		# FIXME: changing all tabs to 2 spaces; ideally this should only change leading tabs
		local content="$(sed \
			-e 's/	/  /g;'"/^: <<'$pattern'/,/^$pattern\$/"'!d;//d' \
			-e "s:<<[S]CRIPT_NAME>>:$SCRIPT_NAME:g" \
			$0 )"

		# Process usage includes
		declare -a uses
		IFS=$'\n'	read -rd '' -a uses <<< "$(__dox_get_meta "$content" 'include' 'usage')"
		local _line
		for _line in "${uses[@]}" ; do
			local opts="${_line:5}"
			local usage="$(__dox_generate_usage "$topic" "${opts:-"{}"}" )"
			content="$( __dox_replace_line "$content" "@~include=${_line}" "$usage" )"
		done
		echo "$content"
	fi
}

__dox_get_usage() {
	local topic="$1" category="${2:-'command'}"
	local content="${3:-"$(__dox_get_content "$topic" "$category")"}"
	local usage="$(__dox_parse_section "$content" 'USAGE')"
	if [[ -z "$usage" && "$category" == "partial" ]] ; then
		usage='@~include=topic{"category":"command","desc":"usage","leader":"  ","partial":"'"${topic}"'"}'
	fi
	echo "$usage" | grep -v '^@~alias'

}

__dox_process_content() {
	local _tail=$'\n'" "
	local content="$1${_tail}"

	# Process meta details
	declare -a includes
	IFS=$'\n' read -rd '' -a includes <<< "$(__dox_get_meta "$content" include)"
	local _tag
	for _tag in "${includes[@]}"; do
		local replacement=""
		case "${_tag%\{*}" in
			(topic)      replacement="$(__dox_generate_topic_includes "${_tag:5}")" ;;
			(categories) replacement="$(__dox_generate_category_list "${_tag:10}")" ;;
      (related)    replacement="$(__dox_generate_related_list "${_tag:7}")" ;;
			(*)          replacement='' ;;
		esac
		content="$( __dox_replace_line "$content" "@~include=${_tag}" "$replacement" )"
	done
	echo $'\n'"$( __dox_trim "${content}")"$'\n'
}

__dox_replace_line() {
	# Args: content, line, replacement
	while IFS= read -r line; do
		if [[ "$line" == "$2" ]] ; then
#			[[ -z "$3" ]] && continue
			line="$3"
		fi
		echo "$line"
	done <<< "$1"
}

__dox_not_found() {
	echo >&2 $'\n'"[$SCRIPT_NAME help] ERROR: No help topic matching '${argv[@]:1}'"
	echo >&2 $'\n''For information on available help topics, run `'"${SCRIPT_NAME}"' help --topics`'
	exit 2
}

__dox_ambiguous_topic() {
	local topic=$1 ; shift
	local _args=( "$@" )
	local content="$(__dox_get_content $topic 'partial')"

	# We only use the description and usage from partials
	local _usage="$(__dox_get_usage $topic 'partial' "$content")"
	local _desc="$(__dox_parse_section "$content" DESCRIPTION)"
	[[ -n "$_desc" ]] || { _desc="  This is a partial command stub which requires further arguments." ; }

	content="$(cat<<EOF
USAGE
$_usage

DESCRIPTION
$_desc

@~include=topic{"category":"concept","desc":"block","leader":"  ","partial":"${topic}"}

COMMANDS
@~include=topic{"category":"command","desc":"inline","leader":"  ","partial":"${topic}"}

  For more details, run \`$SCRIPT_NAME help <command>\` for the desired command.
EOF)"

	__dox_process_content "$content"
}

__dox_get_meta() {
	local content="$1" key=${2:-'.*'} sep="=${3:+"${3}\\b"}" filter=${2:+"$2="}
	echo "$content" | grep '^@~'"$key$sep" | sed 's/^@~'"$filter"'//'
}

__dox_get_meta_option() {
	local meta_str="$1" option="$2"
	opt_line="$(echo "$meta_str" | sed 's/^[^{]*\(.*\)[^}]*$/\1/')"
	case "$(echo "$opt_line" | jq -r ".$option | type")" in
		(array)
			i=0; while value="$(echo "$opt_line" | jq -er ".${option}[${i}]")" ; do
				echo $value
				((i++))
			done
			;;
		(null) return 1;;
		(*)    echo "$opt_line" | jq  -er ".$option" ;;
	esac
}

__dox_get_sections() {
	echo "$1" | grep '^[A-Z][-A-Z0-1 ]*'
}

__dox_parse_section() {
	local content="$1" subject="$2"
	local output
	if [[ -n "$subject" ]] ; then
		_found=false
		_nl=""
		while IFS= read -r line; do
			[[ "${line}" =~ ^${subject} ]] && { _found=true ; continue ; }
			[[ ${_found} == true ]]  || { continue ; }
			[[ "${line}" =~ ^[^[:space:]@] ]] && { break ; }
			[[ "${line}" =~ ^$ ]] && { _nl="${_nl}"$'\n' ; continue ; }
			echo "${_nl}${line}" ; _nl=""
		done <<< "$content"
	fi
}

__dox_get_topics() {
	#echo >&2 "======"$'\n'"DEBUG: called '${FUNCNAME[0]}' with "$'\n'" --($@)--"$'\n'"^^^^^^"
	local topic="${1:-.*}" category="${2:-.*}" scope="$3" alias="$4"
	local candidates=( $(grep '^: <<'"'dox-${category}:${topic}\(-.*\)\?'\$" $0 | sed 's/.*'".dox-//;s/.\$//") )
	for candidate in "${candidates[@]}" ; do
		if [[ -n $scope ]] ; then
			IFS=':' read category topic <<< "$candidate"
			if __dox_get_content $topic $category | grep '@~scope=\(.*,\)\{0,\}'"$scope"'\(,.*\)\{0,\}' 2>&1 > /dev/null ; then
				echo $candidate
			fi
		elif [[ -n $alias ]] ; then
			IFS=':' read category topic <<< "$candidate"
			if __dox_get_content $topic $category | grep '@~alias=\(.*,\)\{0,\}'"$alias"'\(,.*\)\{0,\}' 2>&1 > /dev/null ; then
				echo $candidate
			fi
		else
			echo $candidate
		fi
	done
}

__dox_generate_topic_includes() {
	local opts="$1"
	local scope="$(__dox_get_meta_option "${opts}" scope)"
	local category="$(__dox_get_meta_option "${opts}" category)"
	local partial="$(__dox_get_meta_option "${opts}" partial)"
	local leader="$(__dox_get_meta_option "${opts}" leader)"
	local desc="$(__dox_get_meta_option "${opts}" desc)"
	local items=( $(__dox_get_topics "$partial" "$category" "$scope") )

	local item
	if [[ "${desc}" == "inline" ]] ; then
		local indent=0
		for item in "${items[@]}" ; do
			local _header="${leader}${item#*:}: "
			[[ "${indent}" -ge "${#_header}" ]] || { indent="${#_header}" ; }
		done
		local padding="$(seq -f ' ' -s '' $indent)"
	fi

	for item in "${items[@]}" ; do
		local _header="${leader}""$(echo "${item#*:}" | sed -e 's/-/ /g')"":"
		case "${desc}" in
			(inline)
				local _desc
				_desc="$( __dox_parse_section "$(__dox_get_content "${item#*:}" "${item%%:*}" )"  DESCRIPTION )"
				__dox_reflow_text "${_desc%%$'\n'$'\n'*}" "$padding" "${_header}${padding:${#_header}}"
				echo ""
				;;
			(block)
				echo "${_header}"
				local _desc
				_desc="$( __dox_parse_section "$(__dox_get_content "${item#*:}" "${item%%:*}" )"  DESCRIPTION )"
				__dox_reflow_text "${_desc%%$'\n'$'\n'*}" "${leader}  "
				echo ""
				;;
			(usage)
				_desc="$( __dox_parse_section "$( __dox_get_content "${item#*:}" "${item%%:*}" )" USAGE | grep -v '^@~')"
				while read -r line ; do echo "${leader}${line}" ; done <<< "$_desc"
				;;
			(*)
				echo "${_header/%:/}"
				;;
		esac
	done
}

__dox_generate_category_list() {
	local opts="$1"
	local leader="$( __dox_get_meta_option "${opts}" "leader" )"
	local items=("commands" "concepts") # hardcoded for now
	for category in "${items[@]}" ; do
		echo "${leader}${category}"
	done
}

__dox_generate_related_list() {
	local opts="$1"
	local desc=''
	local category
  declare -a items
	IFS=$'\n' items=( $( __dox_get_meta_option "${opts}" "items" ) )
	unset IFS
	for topic in "${items[@]}" ; do
		category="${topic%%:*}"
		if [[ "$category" == "$topic" ]] ; then
			category=""
		else
			topic="${topic#*:}"
		fi
		_desc="$( __dox_parse_section "$(__dox_get_content "$topic" "$category")" DESCRIPTION "" )"
		[[ -n "$_desc" ]] || continue
		echo "  $topic${category:+" ($category)"}:"
		__dox_reflow_text "${_desc%%$'\n'$'\n'*}" "    "
		echo ""
	done
}

__dox_generate_usage() {
	local topic="$1"
	local opts="$2"
	local args
	local leader="$(__dox_get_meta_option "${opts}" "leader" )"
	local cmd="$(__dox_get_meta_option "${opts}" "cmd" )"

	#FIXME: this doesn't allow empty strings as a valid arg, necessitating using ' ' for no args
  IFS=$'\n' read -d '' -r -a args <<<"$(__dox_get_meta_option "${opts}" "args" )"
  unset IFS
	leader="${leader:-"  "}"
	cmd="${cmd:-"$(echo "$topic" | tr "-" " ")"}"

	[[ ${#args[@]} -gt 0 ]] || args+='' # default with no arguments
	local arg_set
	for arg_set in "${args[@]}" ; do
		echo "${leader}${SCRIPT_NAME} ${cmd} ${arg_set}"
	done
}

__dox_reflow_text() {
	local content="$(echo ${1} | expand -t 2)"
	local leader="$2"
	local header="$3"
	local width=$(( 79 - ${#leader} ))
	unset IFS
	while read -r line ; do
		echo "${header:-$leader}${line}"
		header=""
	done <<< "$(set +x; echo ${content} | fold -s -w $width)"
}
__dox_trim() {
	# trims unused meta, whitespace off end and collapse inner multiple blank lines
	content="$( echo "$1" | grep -v '^@~.*')"
	i=${#content}
	while (( i-- )) ; do [[ "${content:$i:1}" =~ ^[[:space:]]$ ]] || { break ; } ; done
	echo "${content:0:$(( ++i ))}" | cat -s
}


####################################################
# multi-call interace

main() {
	unset IFS
	local cmd=${1:-info} ; shift
	case ${cmd} in
		(ping)                   exit 0 ;;
		(version)                cmd_version $* ;;
		(help)                   cmd_help $* ;;
		(info)                   cmd_help --overview genesis ;;
		(update)                 cmd_update $* ;;
		(new)
			local arg=${1:-} ; shift
			case ${arg} in
				(deployment)         cmd_new_deployment $* ;;
				(site)               cmd_new_site $* ;;
				(env|environment)    cmd_new_environment $* ;;
				(*)                  bad_usage_partial "${cmd}" ${arg} ;;
			esac
			;;
		(stemcell|stemcells)     cmd_stemcells $* ;;
		(release|releases)       cmd_releases $* ;;
		(add)
			local arg=${1:-} ; shift
			case ${arg} in
				(release)            cmd_add_release $* ;;
				(*)                  bad_usage_partial "${cmd}" ${arg} ;;
			esac
			;;
		(set)
			local arg=${1:-} ; shift
			case ${arg} in
				(release)            cmd_set_release $* ;;
				(*)                  bad_usage_partial "${cmd}" ${arg} ;;
			esac
			;;
		(use)
			local arg=${1:-} ; shift
			case ${arg} in
			(release)              cmd_use_release $* ;;
			(stemcell)             cmd_use_stemcell $* ;;
			(*)                    bad_usage_partial "${cmd}" ${arg} ;;
			esac
			;;
		(refresh)
			local arg=${1:-all} ; shift
			case ${arg} in
				(global)             cmd_refresh_global $* ;;
				(site)               cmd_refresh_site $* ;;
				(all)                cmd_refresh_all $* ;;
				(makefile|makefiles) cmd_refresh_makefile $* ;;
				(readme|readmes)     cmd_refresh_readmes $* ;;
				(*)                  bad_usage_partial "${cmd}" ${arg} ;;
			esac
			;;
		(build)                  REDACT=y cmd_build $* ;;
		(deploy)                 cmd_deploy ;;
		(embed)                  cmd_embed ;;
		(ci)
			TERM=dumb
			# Buildout command before parsing opts and args
			local ci_cmd=""
			local ci_partial=""
			while [[ $# -gt 0 && -z "$ci_cmd" ]] ; do
				potential="${potential:+"$potential "}$1"
				case "$potential" in
					(alpha|beta|auto|manual|parent|repipe|flow)   ci_cmd="$potential" ;;
					("smoke-test"|"draft-message"|stemcells)      ci_cmd="$potential" ;;
					("stage1"|"stage2"|"stage-smoke-test")        ci_cmd="$potential" ;;
					(*)
						# In future, partials may be valid commands (ie stage 1 and stage 1
						# smoke test) so if we have a partial that can also be a command,
						# check here before delaring bad usage. (also why we don't shift
						# until after we test)
						bad_usage_partial "ci${ci_partial:+ $ci_partial}" "$1"
						;;
				esac
				shift
			done
			[[ -n $ci_cmd ]] || bad_usage_partial "ci${ci_partial:+ $ci_partial}" ""

			# Check for common pipeline arg
			declare -a ci_args
			CI_PIPELINE=${CI_PIPELINE:-}
			while [[ $# -gt 0 ]]; do
				local arg=${1:-} ; shift
				case ${arg} in
					(-p|--pipeline) CI_PIPELINE="${1:-}"; shift ;;
					(*)             ci_args+=("$arg") ;;
				esac
			done
			export CI_PIPELINE
			set -- "${ci_args[@]}"

			# Process sub-commands
			$(echo "cmd_ci_${ci_cmd}" | tr "-" "_") $*
			;;
		(dump)                   cmd_dump ;;
		(bosh)                   cmd_bosh $* ;;
        (bosh-init)              cmd_boshinit $* ;;
		(*)                      bad_usage_partial "" "$cmd" ;;
	esac
}

[ -n "${CI_DEBUG}" ] && set -x
# look for some help flags
declare -a argv
while (( $# != 0 )); do
	case ${1} in
	(-h|-\?|--help) argv=( help    ${argv[@]}        ) ;;
	(-v|--version)  argv=( version ${argv[@]}        ) ;;
	(*)             argv=(         ${argv[@]} "${1}" ) ;;
	esac
	shift
done
set -- ${argv[@]}
main $@

# fin
